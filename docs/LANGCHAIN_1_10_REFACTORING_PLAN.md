# LangChain 1.10 é‡æ„è®¡åˆ’

> åŸºäº `archive/langchain` (LangChain 1.10) å’Œ `archive/deepagents` æºç åˆ†æï¼Œè¯†åˆ«é¡¹ç›®ä¸­å¯ä½¿ç”¨æ–°ç‰¹æ€§ç®€åŒ–çš„ä»£ç æ¨¡å¼ã€‚

## âœ… é‡æ„è¿›åº¦

| é¡¹ç›® | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `LLMFactory` â†’ `init_chat_model()` | âœ… å®Œæˆ | ä» ~150 è¡Œå‡å°‘åˆ° ~100 è¡Œ |
| `deep_path.py` JSON è§£æ | âœ… å®Œæˆ | åˆ é™¤ ~80 è¡Œå›é€€ä»£ç ï¼Œä½¿ç”¨ `with_structured_output()` |
| `fast_path.py` JSON è§£æ | âœ… å®Œæˆ | åˆ é™¤ ~80 è¡Œå›é€€ä»£ç ï¼Œä½¿ç”¨ `with_structured_output()` |
| æµ‹è¯•è„šæœ¬æ¸…ç† | âœ… å®Œæˆ | å·²åˆ é™¤è¿‡æ—¶çš„ scripts/test_*.py æ–‡ä»¶ |
| æ–‡æ¡£æ›´æ–° | âœ… å®Œæˆ | æ›´æ–° QUICKSTART.mdã€ä¿®å¤ prompt æ¨¡æ¿ |
| å•å…ƒæµ‹è¯•ä¿®å¤ | âœ… å®Œæˆ | 631 passed, 12 skipped |
| HITL ä¸­é—´ä»¶é‡æ„ | ğŸ”² å¾…åš | ä½¿ç”¨ `HumanInTheLoopMiddleware` |
| å·¥ä½œæµé‡æ„ | ğŸ”² å¾…åš | ä½¿ç”¨ `create_agent()` |

**æµ‹è¯•ç»“æœ (2025-11-30)**:
- âœ… 631 tests passed
- â­ï¸ 12 tests skipped (éœ€è¦ç¯å¢ƒé…ç½®)
- ğŸ”§ ä¿®å¤çš„æµ‹è¯•æ–‡ä»¶: `test_strategies.py`, `test_memory_rag.py`, `test_syslog_tool.py`, `test_workflows.py`

---

## ğŸ”„ Fallback/æ¼æ–—æœºåˆ¶åˆ†æä¸ LangChain 1.10 æ›¿ä»£æ–¹æ¡ˆ

### å½“å‰ Fallback å®ç°ç°çŠ¶

OLAV é¡¹ç›®ä¸­å­˜åœ¨å¤šç§ Fallback/æ¼æ–—æœºåˆ¶ï¼š

| ä½ç½® | å½“å‰å®ç° | é—®é¢˜ |
|------|---------|------|
| `fast_path.py` æ„å›¾åˆ†ç±» | LLM å¤±è´¥ â†’ å…³é”®è¯åŒ¹é… | æ‰‹åŠ¨ try/except |
| `fast_path.py` Schema ä¸åŒ¹é… | SuzieQ â†’ CLI â†’ NETCONF | ç¡¬ç¼–ç é“¾ |
| `deep_path.py` å·¥å…·æ‰§è¡Œ | ä¸»å·¥å…·å¤±è´¥ â†’ LLM Fallback | åˆ†æ•£çš„é”™è¯¯å¤„ç† |
| `classify_intent_async()` | LLM â†’ keyword fallback | æ— é‡è¯•æœºåˆ¶ |
| æ¨¡å‹è°ƒç”¨ | æ— ç»Ÿä¸€é‡è¯• | æ¯å¤„å•ç‹¬å¤„ç† |

### LangChain 1.10 æä¾›çš„æ›¿ä»£æ–¹æ¡ˆ

#### 1. `ModelFallbackMiddleware` - æ¨¡å‹çº§ Fallback

```python
from langchain.agents.middleware import ModelFallbackMiddleware

# æ›¿ä»£: æ‰‹åŠ¨ try/except + é™çº§é€»è¾‘
fallback = ModelFallbackMiddleware(
    "openai:gpt-4o-mini",      # ç¬¬ä¸€å¤‡é€‰
    "ollama:llama3",           # ç¬¬äºŒå¤‡é€‰
)

agent = create_agent(
    model="openai:gpt-4o",     # ä¸»æ¨¡å‹
    middleware=[fallback],
)
# å¦‚æœ gpt-4o å¤±è´¥ â†’ è‡ªåŠ¨å°è¯• gpt-4o-mini â†’ å†å°è¯• llama3
```

**é€‚ç”¨äº**: `classify_intent_async()` å’Œæ‰€æœ‰ LLM è°ƒç”¨çš„ç»Ÿä¸€å®¹é”™

#### 2. `ModelRetryMiddleware` - æ¨¡å‹è°ƒç”¨é‡è¯•

```python
from langchain.agents.middleware import ModelRetryMiddleware
from openai import APITimeoutError, RateLimitError

retry = ModelRetryMiddleware(
    max_retries=3,
    retry_on=(APITimeoutError, RateLimitError),  # ä»…é‡è¯•è¿™äº›å¼‚å¸¸
    backoff_factor=2.0,        # æŒ‡æ•°é€€é¿
    initial_delay=1.0,
    max_delay=60.0,
    jitter=True,               # é¿å…é›·ç¾¤æ•ˆåº”
    on_failure="continue",     # å¤±è´¥åç»§ç»­ (è¿”å› AIMessage é”™è¯¯)
)
```

**é€‚ç”¨äº**: æ‰€æœ‰ LLM è°ƒç”¨çš„ç¬æ€é”™è¯¯å¤„ç†

#### 3. `ToolRetryMiddleware` - å·¥å…·è°ƒç”¨é‡è¯•

```python
from langchain.agents.middleware import ToolRetryMiddleware

tool_retry = ToolRetryMiddleware(
    max_retries=2,
    tools=["suzieq_query", "cli_tool"],  # ä»…å¯¹è¿™äº›å·¥å…·é‡è¯•
    retry_on=(ConnectionError, TimeoutError),
    on_failure="continue",  # å¤±è´¥åè¿”å› ToolMessage è®© LLM å¤„ç†
)
```

**é€‚ç”¨äº**: SuzieQã€CLIã€NETCONF å·¥å…·çš„ç½‘ç»œé”™è¯¯é‡è¯•

#### 4. `LLMToolSelectorMiddleware` - åŠ¨æ€å·¥å…·é€‰æ‹©

```python
from langchain.agents.middleware import LLMToolSelectorMiddleware

# æ›¿ä»£: ç¡¬ç¼–ç çš„ FALLBACK_TOOL_CHAIN
selector = LLMToolSelectorMiddleware(
    model="openai:gpt-4o-mini",  # ä½¿ç”¨å°æ¨¡å‹åšé€‰æ‹©
    max_tools=3,                  # æœ€å¤šé€‰ 3 ä¸ªå·¥å…·
    always_include=["suzieq_schema_search"],  # å§‹ç»ˆåŒ…å«
)
```

**é€‚ç”¨äº**: æ›¿ä»£ `FALLBACK_TOOL_CHAIN` ç¡¬ç¼–ç æ˜ å°„

#### 5. ç»„åˆä¸­é—´ä»¶ - å®Œæ•´ Fallback é“¾

```python
from langchain.agents import create_agent
from langchain.agents.middleware import (
    ModelRetryMiddleware,
    ModelFallbackMiddleware,
    ToolRetryMiddleware,
    LLMToolSelectorMiddleware,
)

agent = create_agent(
    model="openai:gpt-4o",
    tools=[suzieq_query, cli_tool, netconf_tool, syslog_search],
    middleware=[
        # 1. æ¨¡å‹è°ƒç”¨é‡è¯• (ç¬æ€é”™è¯¯)
        ModelRetryMiddleware(max_retries=3),
        
        # 2. æ¨¡å‹ Fallback (ä¸»æ¨¡å‹å½»åº•å¤±è´¥)
        ModelFallbackMiddleware("openai:gpt-4o-mini", "ollama:llama3"),
        
        # 3. å·¥å…·è°ƒç”¨é‡è¯• (ç½‘ç»œé”™è¯¯)
        ToolRetryMiddleware(
            max_retries=2,
            tools=["suzieq_query", "cli_tool"],
        ),
        
        # 4. åŠ¨æ€å·¥å…·é€‰æ‹© (æ›¿ä»£ç¡¬ç¼–ç  fallback chain)
        LLMToolSelectorMiddleware(max_tools=3),
    ],
)
```

### è¿ç§»ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | æ¨¡å— | å½“å‰ä»£ç  | æ›¿ä»£æ–¹æ¡ˆ | å·¥ä½œé‡ |
|--------|------|---------|---------|--------|
| ğŸ”´ P0 | æ¨¡å‹é‡è¯• | æ—  | `ModelRetryMiddleware` | 1h |
| ğŸ”´ P0 | æ„å›¾åˆ†ç±» Fallback | æ‰‹åŠ¨ try/except | `ModelFallbackMiddleware` | 2h |
| ğŸŸ  P1 | å·¥å…·é‡è¯• | æ—  | `ToolRetryMiddleware` | 2h |
| ğŸŸ  P1 | å·¥å…·é“¾ Fallback | `FALLBACK_TOOL_CHAIN` | `LLMToolSelectorMiddleware` | 4h |
| ğŸŸ¢ P2 | Deep Path LLM Fallback | åˆ†æ•£é”™è¯¯å¤„ç† | ç»Ÿä¸€ä¸­é—´ä»¶ | 3h |

### é‡æ„ç¤ºä¾‹

#### Before (å½“å‰ä»£ç ):

```python
# fast_path.py - æ„å›¾åˆ†ç±»
async def classify_intent_async(query: str) -> tuple[str, float]:
    try:
        result = await classify_intent_with_llm(query)
        return (result.category, result.confidence)
    except Exception as e:
        logger.warning(f"LLM intent classification failed: {e}, using keyword fallback")
        return classify_intent(query)  # å…³é”®è¯åŒ¹é… fallback

# fast_path.py - Schema ä¸åŒ¹é…æ—¶çš„å·¥å…·é“¾
FALLBACK_TOOL_CHAIN = {
    "suzieq": ["cli_tool", "netconf_tool"],
    "netbox": ["suzieq_query", "cli_tool"],
    "openconfig": ["cli_tool", "netconf_tool"],
}
```

#### After (ä½¿ç”¨ LangChain 1.10 ä¸­é—´ä»¶):

```python
from langchain.agents import create_agent
from langchain.agents.middleware import (
    ModelRetryMiddleware,
    ModelFallbackMiddleware,
    ToolRetryMiddleware,
    LLMToolSelectorMiddleware,
)

# åˆ›å»º Agent æ—¶é…ç½®æ‰€æœ‰ Fallback ç­–ç•¥
agent = create_agent(
    model="openai:gpt-4o",
    tools=[
        suzieq_query,
        suzieq_schema_search,
        cli_tool,
        netconf_tool,
    ],
    system_prompt=prompt_manager.load_agent_prompt("fast_path"),
    middleware=[
        # æ„å›¾åˆ†ç±»å¤±è´¥ â†’ è‡ªåŠ¨åˆ‡æ¢æ¨¡å‹
        ModelFallbackMiddleware("openai:gpt-4o-mini"),
        
        # Rate Limit/Timeout â†’ æŒ‡æ•°é€€é¿é‡è¯•
        ModelRetryMiddleware(
            max_retries=3,
            retry_on=(RateLimitError, APITimeoutError),
        ),
        
        # å·¥å…·æ‰§è¡Œå¤±è´¥ â†’ é‡è¯•
        ToolRetryMiddleware(
            max_retries=2,
            tools=["suzieq_query", "cli_tool"],
        ),
        
        # åŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„å·¥å…· (æ›¿ä»£ FALLBACK_TOOL_CHAIN)
        LLMToolSelectorMiddleware(
            model="openai:gpt-4o-mini",
            max_tools=3,
            always_include=["suzieq_schema_search"],
        ),
    ],
)

# åˆ é™¤: classify_intent_async çš„æ‰‹åŠ¨ fallback
# åˆ é™¤: FALLBACK_TOOL_CHAIN ç¡¬ç¼–ç 
# åˆ é™¤: å„å¤„åˆ†æ•£çš„ try/except é”™è¯¯å¤„ç†
```

### æ”¶ç›Š

1. **ä»£ç ç®€åŒ–**: åˆ é™¤ ~200 è¡Œæ‰‹åŠ¨ fallback/é‡è¯•ä»£ç 
2. **ç»Ÿä¸€ç­–ç•¥**: æ‰€æœ‰å®¹é”™é€»è¾‘é›†ä¸­åœ¨ä¸­é—´ä»¶é…ç½®
3. **å¯è§‚æµ‹æ€§**: ä¸­é—´ä»¶è‡ªåŠ¨è®°å½•é‡è¯•/fallback æ—¥å¿—
4. **å¯æµ‹è¯•æ€§**: ä¸­é—´ä»¶å¯ç‹¬ç«‹å•å…ƒæµ‹è¯•
5. **çµæ´»é…ç½®**: ä¸åŒ Agent/Workflow å¯ä½¿ç”¨ä¸åŒä¸­é—´ä»¶ç»„åˆ

---

## ğŸ“‹ TODO å®æ–½è®¡åˆ’

### ğŸ”´ P0: LLM å±‚ä¸­é—´ä»¶ (llm.py)

**ç›®æ ‡**: ä¸ºæ‰€æœ‰ LLM è°ƒç”¨æ·»åŠ ç»Ÿä¸€çš„é‡è¯•å’Œé™çº§æœºåˆ¶

**ä»»åŠ¡**:
- [ ] æ·»åŠ  `ModelRetryMiddleware` é…ç½® (Rate Limit, Timeout è‡ªåŠ¨é‡è¯•)
- [ ] æ·»åŠ  `ModelFallbackMiddleware` é…ç½® (ä¸»æ¨¡å‹å¤±è´¥ â†’ é™çº§æ¨¡å‹)
- [ ] æ–°å¢ `get_resilient_chat_model()` æ–¹æ³•è¿”å›å¸¦ä¸­é—´ä»¶çš„æ¨¡å‹
- [ ] æ›´æ–° `config/settings.py` æ·»åŠ  fallback æ¨¡å‹é…ç½®

**å®ç°ä½ç½®**: `src/olav/core/llm.py`

**API ç­¾å**:
```python
ModelRetryMiddleware(
    max_retries=3,
    retry_on=(RateLimitError, APITimeoutError),
    backoff_factor=2.0,
    initial_delay=1.0,
    max_delay=60.0,
    jitter=True,
    on_failure="continue",  # è¿”å›é”™è¯¯æ¶ˆæ¯è€Œä¸æ˜¯æŠ›å¼‚å¸¸
)

ModelFallbackMiddleware(
    "openai:gpt-4o-mini",  # ç¬¬ä¸€é™çº§
    "ollama:llama3",       # ç¬¬äºŒé™çº§
)
```

### ğŸŸ  P1: å·¥å…·å±‚ä¸­é—´ä»¶ (fast_path.py)

**ç›®æ ‡**: ä¸º SuzieQ/CLI/NETCONF å·¥å…·è°ƒç”¨æ·»åŠ é‡è¯•æœºåˆ¶

**ä»»åŠ¡**:
- [ ] é›†æˆ `ToolRetryMiddleware` åˆ° FastPathStrategy
- [ ] é…ç½®ç½‘ç»œå·¥å…·çš„é‡è¯•ç­–ç•¥ (ConnectionError, TimeoutError)
- [ ] ä¿ç•™ç°æœ‰ `FALLBACK_TOOL_CHAIN` ä½œä¸ºè¯­ä¹‰çº§ fallback

**å®ç°ä½ç½®**: `src/olav/strategies/fast_path.py`

**API ç­¾å**:
```python
ToolRetryMiddleware(
    max_retries=2,
    tools=["suzieq_query", "cli_tool", "netconf_tool"],
    retry_on=(ConnectionError, TimeoutError),
    on_failure="continue",
)
```

### ğŸŸ¢ P2: é«˜çº§ä¼˜åŒ–

#### P2.1: LLMToolSelectorMiddleware è¯„ä¼°

**ç›®æ ‡**: è¯„ä¼°æ˜¯å¦ç”¨ LLM åŠ¨æ€å·¥å…·é€‰æ‹©æ›¿ä»£ `FALLBACK_TOOL_CHAIN`

**è¯„ä¼°ç‚¹**:
- [ ] æ€§èƒ½å½±å“ (é¢å¤– LLM è°ƒç”¨ vs ç¡¬ç¼–ç  fallback)
- [ ] å‡†ç¡®æ€§æå‡ (LLM é€‰æ‹© vs å…³é”®è¯åŒ¹é…)
- [ ] æˆæœ¬åˆ†æ (å°æ¨¡å‹ gpt-4o-mini æˆæœ¬)

**ç»“è®º**: æš‚æ—¶ä¿ç•™ `FALLBACK_TOOL_CHAIN`ï¼Œå› ä¸º:
1. ç½‘ç»œè¯Šæ–­ fallback æ˜¯é¢†åŸŸçŸ¥è¯† (SuzieQâ†’CLI)
2. é¢å¤– LLM è°ƒç”¨å¢åŠ å»¶è¿Ÿ
3. ç°æœ‰ fallback å·²ç¨³å®š

#### P2.2: DeepDive RAG è¯»å–åŠŸèƒ½

**ç›®æ ‡**: åœ¨ DeepDive è§„åˆ’é˜¶æ®µæŸ¥è¯¢å†å²è¯Šæ–­æ¨¡å¼

**ä»»åŠ¡**:
- [ ] åœ¨ `topology_analysis_node` æ·»åŠ  `search_episodic_memory` è°ƒç”¨
- [ ] ç”¨å†å²æˆåŠŸæ¨¡å¼æŒ‡å¯¼è¯Šæ–­è®¡åˆ’ç”Ÿæˆ
- [ ] æ·»åŠ é…ç½®å¼€å…³ `enable_deep_dive_rag_read`

**å®ç°ä½ç½®**: `src/olav/workflows/deep_dive.py`

---

## âœ… å®æ–½è¿›åº¦

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | çŠ¶æ€ | å¤‡æ³¨ |
|--------|------|------|------|
| P0 | ModelRetryMiddleware | âœ… å®Œæˆ | `LLMFactory.get_retry_middleware()` |
| P0 | ModelFallbackMiddleware | âœ… å®Œæˆ | `LLMFactory.get_fallback_middleware()` |
| P1 | ToolRetryMiddleware | âœ… å®Œæˆ | `FastPathStrategy._execute_with_retry()` |
| P2.1 | LLMToolSelectorMiddleware | âŒ æš‚ä¸å®æ–½ | ä¿ç•™ç°æœ‰ `FALLBACK_TOOL_CHAIN` |
| P2.2 | DeepDive RAG Read | âœ… å®Œæˆ | `_search_historical_diagnostics()` |

### å®æ–½è¯¦æƒ…

#### P0: LLM å±‚ä¸­é—´ä»¶ (2025-11-30)

**æ–‡ä»¶**: `src/olav/core/llm.py`

æ–°å¢æ–¹æ³•:
- `LLMFactory.get_retry_middleware()`: è¿”å› `ModelRetryMiddleware` å®ä¾‹
  - `max_retries=3`, `backoff_factor=2.0`, `jitter=True`
  - é‡è¯•å¼‚å¸¸: `RateLimitError`, `APITimeoutError`, `ConnectionError`, `TimeoutError`
- `LLMFactory.get_fallback_middleware()`: è¿”å› `ModelFallbackMiddleware` å®ä¾‹
  - è‡ªåŠ¨é™çº§åˆ° `gpt-4o-mini` æˆ– `llama3.2`
- `LLMFactory.get_middleware_stack()`: è¿”å›å®Œæ•´ä¸­é—´ä»¶æ ˆ
- `LLMFactory.reset_middleware()`: é‡ç½®ç¼“å­˜ï¼ˆæµ‹è¯•ç”¨ï¼‰

#### P1: å·¥å…·å±‚é‡è¯• (2025-11-30)

**æ–‡ä»¶**: `src/olav/strategies/fast_path.py`

æ–°å¢æ–¹æ³•:
- `FastPathStrategy._execute_with_retry()`: å®ç°å·¥å…·é‡è¯•é€»è¾‘
  - `max_retries=3`, `backoff_factor=2.0`, `jitter=True`
  - é‡è¯•å¼‚å¸¸: `ConnectionError`, `TimeoutError`, `OSError`
  - å®ç°ä¸ LangChain 1.10 `ToolRetryMiddleware` ç›¸åŒçš„æ¨¡å¼

#### P2.2: DeepDive RAG è¯»å– (2025-11-30)

**æ–‡ä»¶**: `src/olav/workflows/deep_dive.py`

æ–°å¢æ–¹æ³•:
- `DeepDiveWorkflow._search_historical_diagnostics()`: æŸ¥è¯¢å†å²è¯Šæ–­æ¨¡å¼
  - ä»…åŒ¹é… `deep_dive_workflow` æˆ– `deep_dive_funnel` çš„å†å²è®°å½•
  - ç›¸ä¼¼åº¦é˜ˆå€¼: 0.6 (Jaccard similarity)
  - è¿”å›: å†å²é—®é¢˜ã€è¯Šæ–­é˜¶æ®µæ•°ã€å‘ç°æ•°é‡ã€å—å½±å“è®¾å¤‡

ä¿®æ”¹æ–¹æ³•:
- `topology_analysis_node()`: åœ¨æ­¥éª¤ 0 è°ƒç”¨å†å²æœç´¢
  - å†å²ä¸Šä¸‹æ–‡å¢å¼º LLM prompt
  - ç”¨æˆ·æ¶ˆæ¯ä¸­æ˜¾ç¤ºå†å²å‚è€ƒä¿¡æ¯

### æµ‹è¯•ç»“æœ (2025-11-30)

```
631 passed, 12 skipped in 135.78s
```

---

## ğŸ“‹ æ¦‚è¿°

LangChain 1.10 å¼•å…¥äº†å¤šé¡¹é‡å¤§æ”¹è¿›ï¼Œå¯å¤§å¹…é™ä½ OLAV é¡¹ç›®çš„ä»£ç å¤æ‚åº¦ï¼š

- **`create_agent()` å·¥å‚å‡½æ•°**: ä¸€è¡Œä»£ç åˆ›å»ºå®Œæ•´ Agentï¼Œå†…ç½® tool loop
- **Middleware ç³»ç»Ÿ**: å¯ç»„åˆçš„ä¸­é—´ä»¶ï¼ˆHITLã€é‡è¯•ã€æ‘˜è¦ç­‰ï¼‰
- **`init_chat_model()`**: ç»Ÿä¸€çš„æ¨¡å‹åˆå§‹åŒ–æ¥å£
- **DeepAgents**: å­ä»£ç†ã€æ–‡ä»¶ç³»ç»Ÿã€TODO ç®¡ç†ç­‰é«˜çº§åŠŸèƒ½

---

## ğŸ”‘ æ ¸å¿ƒæ–°ç‰¹æ€§

### 1. `create_agent()` å·¥å‚å‡½æ•° + ä¸­é—´ä»¶ç³»ç»Ÿ

æ¥æº: `archive/langchain/libs/langchain_v1/langchain/agents/factory.py`

```python
from langchain.agents import create_agent
from langchain.agents.middleware import (
    HumanInTheLoopMiddleware,
    ModelRetryMiddleware,
    ToolRetryMiddleware,
    SummarizationMiddleware,
)

agent = create_agent(
    model="openai:gpt-4",
    tools=[suzieq_query_tool, netconf_tool],
    system_prompt="ä½ æ˜¯ OLAV ç½‘ç»œè¿ç»´ä¸“å®¶",
    middleware=[
        HumanInTheLoopMiddleware(interrupt_on={"cli_tool": True}),
        ModelRetryMiddleware(max_retries=3),
        ToolRetryMiddleware(max_retries=2),
        SummarizationMiddleware(model=model, trigger=("tokens", 8000)),
    ],
    checkpointer=checkpointer,
)
```

**ä¼˜åŠ¿**:
- è‡ªåŠ¨æ„å»º model â†’ tools â†’ model å¾ªç¯
- ä¸­é—´ä»¶å¯ç»„åˆï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™ StateGraph
- å†…ç½® HITLã€é‡è¯•ã€æ‘˜è¦ç­‰å¸¸ç”¨åŠŸèƒ½

### 2. `init_chat_model()` ç»Ÿä¸€æ¨¡å‹åˆå§‹åŒ–

æ¥æº: `archive/langchain/libs/langchain_v1/langchain/chat_models/base.py`

```python
from langchain.chat_models import init_chat_model

# ä¸€è¡Œä»£ç æ”¯æŒæ‰€æœ‰ Provider
model = init_chat_model("openai:gpt-4")
model = init_chat_model("anthropic:claude-sonnet-4-5-20250929")
model = init_chat_model("ollama:llama2")
model = init_chat_model("azure_openai:gpt-4")
```

**æ”¯æŒçš„ Provider**:
- `openai`, `anthropic`, `azure_openai`, `azure_ai`
- `google_vertexai`, `google_genai`, `bedrock`, `bedrock_converse`
- `cohere`, `fireworks`, `together`, `mistralai`
- `huggingface`, `groq`, `ollama`, `deepseek`, `xai`, `perplexity`

### 3. å†…ç½®ä¸­é—´ä»¶

æ¥æº: `archive/langchain/libs/langchain_v1/langchain/agents/middleware/`

| ä¸­é—´ä»¶ | åŠŸèƒ½ | æ–‡ä»¶ |
|--------|------|------|
| `HumanInTheLoopMiddleware` | å·¥å…·æ‰§è¡Œå®¡æ‰¹ (approve/edit/reject) | `human_in_the_loop.py` |
| `ModelRetryMiddleware` | æ¨¡å‹è°ƒç”¨è‡ªåŠ¨é‡è¯• (æŒ‡æ•°é€€é¿) | `model_retry.py` |
| `ToolRetryMiddleware` | å·¥å…·è°ƒç”¨è‡ªåŠ¨é‡è¯• | `tool_retry.py` |
| `SummarizationMiddleware` | é•¿å¯¹è¯è‡ªåŠ¨æ‘˜è¦ | `summarization.py` |
| `ModelFallbackMiddleware` | æ¨¡å‹æ•…éšœåˆ‡æ¢ | `model_fallback.py` |
| `ToolCallLimitMiddleware` | å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ | `tool_call_limit.py` |
| `ModelCallLimitMiddleware` | æ¨¡å‹è°ƒç”¨æ¬¡æ•°é™åˆ¶ | `model_call_limit.py` |
| `PIIMiddleware` | PII æ£€æµ‹ä¸è„±æ• | `pii.py` |
| `TodoListMiddleware` | TODO åˆ—è¡¨ç®¡ç† | `todo.py` |

### 4. DeepAgents æ¨¡å¼

æ¥æº: `archive/deepagents/libs/deepagents/deepagents/graph.py`

```python
from deepagents import create_deep_agent

agent = create_deep_agent(
    model=model,
    tools=network_tools,
    system_prompt="ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶",
    subagents=[
        {"name": "bgp_specialist", "prompt": "BGP ä¸“å®¶", "tools": [bgp_tool]},
        {"name": "ospf_specialist", "prompt": "OSPF ä¸“å®¶", "tools": [ospf_tool]},
    ],
    backend=StateBackend,  # æˆ– RedisBackend
    interrupt_on={"cli_tool": True, "netconf_tool": True},
)
```

**åŠŸèƒ½**:
- SubAgent å§”æ‰˜ (å¤æ‚ä»»åŠ¡åˆ†è§£)
- FilesystemMiddleware (æ–‡ä»¶è¯»å†™)
- TodoListMiddleware (ä»»åŠ¡è·Ÿè¸ª)
- SummarizationMiddleware (ä¸Šä¸‹æ–‡å‹ç¼©)

---

## ğŸ“Š é‡æ„é¡¹ç›®æ¸…å•

### 1. `src/olav/core/llm.py` â†’ ä½¿ç”¨ `init_chat_model()`

**å½“å‰ä»£ç ** (~150 è¡Œ):
```python
class LLMFactory:
    @staticmethod
    def get_chat_model(json_mode: bool = False, ...):
        if env_settings.llm_provider == "openai":
            return FixedChatOpenAI(...)
        elif env_settings.llm_provider == "ollama":
            from langchain_ollama import ChatOllama
            return ChatOllama(...)
        elif env_settings.llm_provider == "azure":
            from langchain_openai import AzureChatOpenAI
            return AzureChatOpenAI(...)
        # ... æ›´å¤šåˆ†æ”¯
```

**é‡æ„å** (~30 è¡Œ):
```python
from langchain.chat_models import init_chat_model

class LLMFactory:
    @staticmethod
    def get_chat_model(json_mode: bool = False, **kwargs):
        model_string = f"{env_settings.llm_provider}:{env_settings.llm_model_name}"
        model_kwargs = {}
        if json_mode:
            model_kwargs["response_format"] = {"type": "json_object"}
        
        return init_chat_model(
            model_string,
            temperature=LLMConfig.TEMPERATURE,
            max_tokens=LLMConfig.MAX_TOKENS,
            api_key=env_settings.llm_api_key,
            base_url=LLMConfig.BASE_URL,
            **model_kwargs,
            **kwargs,
        )
```

**æ”¶ç›Š**: åˆ é™¤ ~120 è¡Œ Provider åˆ†æ”¯ä»£ç ï¼Œç»Ÿä¸€åˆå§‹åŒ–æ¥å£

---

### 2. HITL å®ç° â†’ ä½¿ç”¨ `HumanInTheLoopMiddleware`

**å½“å‰ä»£ç ** (åˆ†æ•£åœ¨å¤šä¸ª workflow æ–‡ä»¶):
```python
# src/olav/workflows/device_execution.py
from langgraph.types import interrupt

async def plan_approval_node(state):
    approval = interrupt({"plan": state["execution_plan"]})
    if approval == "reject":
        return {"aborted": True}
    # ... æ‰‹åŠ¨å¤„ç† approve/edit/reject
```

**é‡æ„å**:
```python
from langchain.agents.middleware import HumanInTheLoopMiddleware, InterruptOnConfig

hitl_middleware = HumanInTheLoopMiddleware(
    interrupt_on={
        "cli_tool": InterruptOnConfig(
            allowed_decisions=["approve", "edit", "reject"],
            description="CLI å‘½ä»¤æ‰§è¡Œéœ€è¦å®¡æ‰¹",
        ),
        "netconf_tool": InterruptOnConfig(
            allowed_decisions=["approve", "reject"],
            description="NETCONF é…ç½®å˜æ›´éœ€è¦å®¡æ‰¹",
        ),
    }
)

agent = create_agent(
    model=model,
    tools=[cli_tool, netconf_tool],
    middleware=[hitl_middleware],
)
```

**æ”¶ç›Š**:
- åˆ é™¤ ~200 è¡Œæ‰‹åŠ¨ interrupt å¤„ç†ä»£ç 
- ç»Ÿä¸€ HITL äº¤äº’æ ¼å¼ (`HITLRequest` / `HITLResponse`)
- è‡ªåŠ¨å¤„ç† AI/Tool message å¯¹

---

### 3. `src/olav/strategies/deep_path.py` JSON è§£æ â†’ ç§»é™¤å›é€€é€»è¾‘

**å½“å‰ä»£ç ** (~80 è¡Œ):
```python
def _parse_json_response(self, content: str, model_class: type[BaseModel]) -> BaseModel | None:
    raw_content = content.strip()
    
    # Strategy 1: Clean markdown code blocks
    if "```" in raw_content:
        match = re.search(r"```(?:json)?\s*\n?(.*?)\n?```", raw_content, re.DOTALL)
        if match:
            raw_content = match.group(1).strip()
    
    # Strategy 2: Find JSON object boundaries
    # Strategy 3: Try direct Pydantic parsing
    # Strategy 4: Fix common JSON issues
    # Strategy 5: Regex extraction
    # ... çº¦ 50 è¡Œå›é€€é€»è¾‘
```

**é‡æ„å** (~10 è¡Œ):
```python
# with_structured_output å†…éƒ¨å·²å¤„ç†æ‰€æœ‰å›é€€é€»è¾‘
async def _collect_initial_observations(self, state, context):
    structured_llm = self.llm.with_structured_output(ToolCallPlanList)
    result = await structured_llm.ainvoke([SystemMessage(content=prompt)])
    # ç›´æ¥ä½¿ç”¨ resultï¼Œæ— éœ€æ‰‹åŠ¨è§£æ
```

**æ”¶ç›Š**: åˆ é™¤ ~70 è¡Œ JSON è§£æå›é€€ä»£ç 

---

### 4. Workflow å›¾æ„å»º â†’ ä½¿ç”¨ `create_agent()`

**å½“å‰ä»£ç ** (æ¯ä¸ª workflow ~100 è¡Œ):
```python
# src/olav/workflows/query_diagnostic.py
class QueryDiagnosticWorkflow(BaseWorkflow):
    def build_graph(self, checkpointer):
        graph = StateGraph(QueryState)
        graph.add_node("agent", self._agent_node)
        graph.add_node("tools", ToolNode(self.tools))
        graph.add_conditional_edges(
            "agent",
            self._should_continue,
            {"tools": "tools", "end": END}
        )
        graph.add_edge("tools", "agent")
        graph.set_entry_point("agent")
        return graph.compile(checkpointer=checkpointer)
```

**é‡æ„å** (~30 è¡Œ):
```python
from langchain.agents import create_agent

class QueryDiagnosticWorkflow(BaseWorkflow):
    def build_graph(self, checkpointer):
        return create_agent(
            model=LLMFactory.get_chat_model(),
            tools=[
                ToolRegistry.get_tool("suzieq_query"),
                ToolRegistry.get_tool("suzieq_schema_search"),
            ],
            system_prompt=prompt_manager.load_agent_prompt("query_diagnostic"),
            middleware=[
                ToolRetryMiddleware(max_retries=2),
            ],
            checkpointer=checkpointer,
        )
```

**æ”¶ç›Š**: æ¯ä¸ª workflow åˆ é™¤ ~70 è¡Œå›¾æ„å»ºä»£ç 

---

### 5. æ·»åŠ é‡è¯•ä¸­é—´ä»¶ (æ–°å¢åŠŸèƒ½)

**å½“å‰çŠ¶æ€**: æ— ç»Ÿä¸€é‡è¯•æœºåˆ¶

**æ·»åŠ **:
```python
from langchain.agents.middleware import ModelRetryMiddleware, ToolRetryMiddleware

# æ¨¡å‹è°ƒç”¨é‡è¯• (å¤„ç† Rate Limitã€Timeout ç­‰)
model_retry = ModelRetryMiddleware(
    max_retries=3,
    retry_on=(RateLimitError, APITimeoutError),
    backoff_factor=2.0,
    initial_delay=1.0,
    max_delay=60.0,
    jitter=True,
)

# å·¥å…·è°ƒç”¨é‡è¯• (å¤„ç†ç½‘ç»œé”™è¯¯ã€è®¾å¤‡è¶…æ—¶ç­‰)
tool_retry = ToolRetryMiddleware(
    max_retries=2,
    tools=["suzieq_query", "netbox_api_call", "cli_tool"],
    retry_on=(ConnectionError, TimeoutError),
)
```

**æ”¶ç›Š**: æé«˜ç³»ç»Ÿå¥å£®æ€§ï¼Œè‡ªåŠ¨å¤„ç†ç¬æ€é”™è¯¯

---

### 6. æ·»åŠ æ‘˜è¦ä¸­é—´ä»¶ (æ–°å¢åŠŸèƒ½)

**å½“å‰çŠ¶æ€**: æ— é•¿å¯¹è¯æ‘˜è¦æœºåˆ¶

**æ·»åŠ **:
```python
from langchain.agents.middleware import SummarizationMiddleware

summarization = SummarizationMiddleware(
    model=LLMFactory.get_chat_model(),
    trigger=("tokens", 8000),  # Token è¶…è¿‡ 8000 æ—¶è§¦å‘æ‘˜è¦
    keep=("messages", 20),     # ä¿ç•™æœ€è¿‘ 20 æ¡æ¶ˆæ¯
    trim_tokens_to_summarize=4000,  # æ‘˜è¦è¾“å…¥é™åˆ¶
)
```

**æ”¶ç›Š**: æ”¯æŒè¶…é•¿å¯¹è¯ï¼Œé¿å… context window æº¢å‡º

---

## ğŸ“ˆ ä¼˜å…ˆçº§ä¸å·¥ä½œé‡è¯„ä¼°

| ä¼˜å…ˆçº§ | æ¨¡å— | å½“å‰è¡Œæ•° | é¢„ä¼°æ”¹è¿›å | åˆ é™¤ä»£ç é‡ | å·¥ä½œé‡ | é£é™© |
|--------|------|---------|-----------|-----------|--------|------|
| ğŸ”´ P0 | `LLMFactory` | ~150 è¡Œ | ~30 è¡Œ | -120 è¡Œ | 2h | ä½ |
| ğŸ”´ P0 | HITL å®ç° | ~200 è¡Œ | ~30 è¡Œ | -170 è¡Œ | 4h | ä¸­ |
| ğŸŸ  P1 | `deep_path.py` JSON è§£æ | ~80 è¡Œ | ~10 è¡Œ | -70 è¡Œ | 2h | ä½ |
| ğŸŸ  P1 | Workflow å›¾æ„å»º (5ä¸ª) | 5Ã—100 è¡Œ | 5Ã—30 è¡Œ | -350 è¡Œ | 8h | ä¸­ |
| ğŸŸ¢ P2 | æ·»åŠ é‡è¯•ä¸­é—´ä»¶ | 0 | +40 è¡Œ | N/A | 2h | ä½ |
| ğŸŸ¢ P2 | æ·»åŠ æ‘˜è¦ä¸­é—´ä»¶ | 0 | +20 è¡Œ | N/A | 1h | ä½ |

**æ€»è®¡**: åˆ é™¤ ~710 è¡Œä»£ç ï¼Œæ–°å¢ ~160 è¡Œï¼Œå‡€å‡å°‘ ~550 è¡Œ

---

## ğŸš€ å®æ–½æ­¥éª¤

### Phase 1: åŸºç¡€è®¾æ–½ (1 å¤©)

1. **å‡çº§ä¾èµ–**
   ```bash
   uv add langchain@latest langgraph@latest
   uv add langchain-anthropic langchain-ollama  # å¦‚éœ€è¦
   ```

2. **é‡æ„ `LLMFactory`**
   - æ›¿æ¢ä¸º `init_chat_model()`
   - ä¿ç•™ `FixedChatOpenAI` ä½œä¸º OpenRouter å…¼å®¹å±‚ï¼ˆå¦‚éœ€è¦ï¼‰

3. **è¿è¡Œæµ‹è¯•éªŒè¯**
   ```bash
   uv run pytest tests/unit/test_llm.py -v
   ```

### Phase 2: ä¸­é—´ä»¶é›†æˆ (2 å¤©)

4. **åˆ›å»ºä¸­é—´ä»¶é…ç½®**
   ```python
   # src/olav/core/middleware.py
   from langchain.agents.middleware import (
       HumanInTheLoopMiddleware,
       ModelRetryMiddleware,
       ToolRetryMiddleware,
       SummarizationMiddleware,
   )
   
   def get_default_middleware(hitl_tools: dict = None):
       middleware = [
           ModelRetryMiddleware(max_retries=3),
           ToolRetryMiddleware(max_retries=2),
       ]
       if hitl_tools:
           middleware.append(HumanInTheLoopMiddleware(interrupt_on=hitl_tools))
       return middleware
   ```

5. **é‡æ„ HITL å®ç°**
   - ç§»é™¤æ‰‹åŠ¨ `interrupt()` è°ƒç”¨
   - ä½¿ç”¨ `HumanInTheLoopMiddleware`

### Phase 3: Workflow é‡æ„ (3 å¤©)

6. **é‡æ„ `QueryDiagnosticWorkflow`** (è¯•ç‚¹)
   - ä½¿ç”¨ `create_agent()` æ›¿æ¢ `StateGraph`
   - éªŒè¯åŠŸèƒ½ä¸€è‡´æ€§

7. **æ‰¹é‡é‡æ„å…¶ä»– Workflow**
   - `DeviceExecutionWorkflow`
   - `NetBoxManagementWorkflow`
   - `DeepDiveWorkflow`
   - `InspectionWorkflow`

### Phase 4: æ¸…ç†ä¼˜åŒ– (1 å¤©)

8. **ç§»é™¤ `deep_path.py` JSON è§£æå›é€€**

9. **æ·»åŠ æ‘˜è¦ä¸­é—´ä»¶**

10. **æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•**

---

## âš ï¸ è¿ç§»æ³¨æ„äº‹é¡¹

### å…¼å®¹æ€§

1. **ä¾èµ–ç‰ˆæœ¬**: éœ€è¦ LangChain >= 1.10
2. **State Schema**: `create_agent()` ä½¿ç”¨ `AgentState`ï¼Œä¸ç°æœ‰ `BaseWorkflowState` å¯èƒ½ä¸å…¼å®¹
3. **Checkpointer**: ç¡®ä¿ PostgresSaver ç‰ˆæœ¬å…¼å®¹

### é£é™©ç¼“è§£

1. **æ¸è¿›å¼è¿ç§»**: å…ˆä» `LLMFactory` å¼€å§‹ï¼Œé€æ­¥æ›¿æ¢
2. **åŠŸèƒ½å¼€å…³**: æ·»åŠ ç¯å¢ƒå˜é‡æ§åˆ¶æ–°æ—§å®ç°åˆ‡æ¢
   ```python
   USE_NEW_AGENT_FACTORY = os.getenv("OLAV_USE_NEW_AGENT", "false").lower() == "true"
   ```
3. **å›å½’æµ‹è¯•**: æ¯ä¸ª Phase å®Œæˆåè¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶

### ä¿ç•™é¡¹

ä»¥ä¸‹ç°æœ‰å®ç°å»ºè®®ä¿ç•™ï¼š

1. **`ToolRegistry`**: Schema-Aware å·¥å…·æ³¨å†Œæ¨¡å¼ä»ç„¶æœ‰æ•ˆ
2. **`PromptManager`**: æç¤ºè¯ç®¡ç†ä¸æ–°ç‰¹æ€§æ­£äº¤
3. **`DynamicIntentRouter`**: æ„å›¾è·¯ç”±é€»è¾‘ç‹¬ç«‹äº Agent å®ç°

---

## ğŸ“š å‚è€ƒèµ„æ–™

- LangChain 1.10 æºç : `archive/langchain/libs/langchain_v1/`
- DeepAgents æºç : `archive/deepagents/libs/deepagents/`
- LangChain Agents æ–‡æ¡£: https://docs.langchain.com/oss/python/langchain/agents
- LangChain Middleware æ–‡æ¡£: https://docs.langchain.com/oss/python/langchain/middleware

---

## ğŸ“ æ›´æ–°æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | å˜æ›´ |
|------|------|------|
| 2025-11-30 | 1.0 | åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºäº LangChain 1.10 å’Œ DeepAgents åˆ†æ |
