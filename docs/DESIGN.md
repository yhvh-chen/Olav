# OLAV (Omni-Layer Autonomous Verifier)

**Project Code:** OLAV  
**Version:** 2.0  
**Status:** Active Development

## 1. é¡¹ç›®æ¦‚è¿° (Project Overview)

OLAV æ˜¯ä¸€ä¸ªä¼ä¸šçº§ç½‘ç»œè¿ç»´ ChatOps å¹³å°ï¼Œæ—¨åœ¨é€šè¿‡æ™ºèƒ½ä½“åä½œè§£å†³å¤æ‚çš„ç½‘ç»œæ’é”™ä¸è¿ç»´ä»»åŠ¡ã€‚å®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªæ‰§è¡Œå‘½ä»¤çš„æœºå™¨äººï¼Œè€Œæ˜¯ä¸€ä¸ªå…·å¤‡æ¶æ„æ„ŸçŸ¥ (Schema-Aware)ã€è‡ªæˆ‘å­¦ä¹  (Self-Learning) å’Œå¤šå±‚çº§æ’é”™èƒ½åŠ›çš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

### æ ¸å¿ƒè®¾è®¡å“²å­¦

*   **æ¼æ–—å¼æ’é”™ (The Funnel)**: ä» SuzieQ çš„å®è§‚å†å²æ•°æ®å…¥æ‰‹ï¼Œæ”¶æ•›æ•…éšœèŒƒå›´ï¼Œå†åˆ©ç”¨ NETCONF/OpenConfig è¿›è¡Œå¾®è§‚å®æ—¶è¯Šæ–­ã€‚
*   **çŸ¥è¯†åˆ†å±‚ (Tiered Knowledge)**: å°†çŸ¥è¯†åˆ†ä¸º **Schema (çœŸç†)**ã€**Memory (ç»éªŒ)** å’Œ **Docs (æ–‡æ¡£)** ä¸‰å±‚ï¼Œé€šè¿‡ RAG 2.0 æ¶æ„è¿›è¡Œæ£€ç´¢ã€‚
*   **å®‰å…¨ç¬¬ä¸€ (Safety First)**: å®æ–½ **Human-in-the-Loop (HITL)** æœºåˆ¶ï¼Œæ‰€æœ‰å‰¯ä½œç”¨æ“ä½œï¼ˆWrite/Configï¼‰å¿…é¡»ç»è¿‡äººå·¥æ‰¹å‡†ï¼›é‡‡ç”¨æ²™ç›’éš”ç¦»æ‰§è¡Œé€»è¾‘ã€‚
*   **é«˜å†…èšä½è€¦åˆ**: ç»„ä»¶é€šè¿‡æ ‡å‡†åŒ–æ¥å£äº¤äº’ï¼Œæ”¯æŒ LLM æ¨¡å‹ï¼ˆOpenAI/Ollamaï¼‰å’Œç½‘ç»œè®¾å¤‡ï¼ˆCisco/Huawei/Aristaï¼‰çš„æ— ç¼åˆ‡æ¢ã€‚

---

## 2. ç³»ç»Ÿæ¶æ„ (System Architecture)

OLAV é‡‡ç”¨å¾®æœåŠ¡åŒ–çš„å®¹å™¨æ¶æ„ï¼ŒåŸºäº LangGraph è¿›è¡Œæ™ºèƒ½ä½“ç¼–æ’ã€‚

### æ¶æ„æ¦‚è§ˆ

```mermaid
graph TD
    subgraph "User Interface"
        CLI[Rich CLI / Terminal] <-->|Stream/Input| App_Container
    end

    subgraph "OLAV Application (Main Brain)"
        App_Container[olav-app]
        LLM_Factory[LLM Factory] -->|Invoke| App_Container
        Supervisor[Supervisor Agent] -->|Route| Workers
        
        subgraph "Workers (Agents)"
            SuzieQ_Agent[Macro Agent]
            Netconf_Agent[Micro Agent]
            NetBox_Agent[SSOT Agent]
            Doc_Agent[Doc Agent]
            Learner_Agent[Reflection Node]
        end
    end

    subgraph "Infrastructure Services"
        Redis[(Redis)] <-->|State Persistence| App_Container
        OpenSearch[(OpenSearch)] <-->|Vector Search| App_Container
        SuzieQ_Service[SuzieQ Poller] -->|Parquet| Shared_Vol[Shared Volume]
    end

    subgraph "Support Containers"
        Init_Container[olav-init] -->|ETL Schema| OpenSearch
        Embedder_Service[olav-embedder] -->|Ingest PDF/Docs| OpenSearch
        Embedder_Service <-->|API Trigger| App_Container
    end

    subgraph "External World"
        NetBox[(NetBox Source of Truth)]
        Network_Devices[Switches/Routers]
        LLM_Provider[OpenAI/Ollama/Azure]
    end

    App_Container -->|Inventory| NetBox
    App_Container -->|Nornir Execution| Network_Devices
    NetBox_Agent -->|Manage| NetBox
```

---

## 3. ç›®å½•æ¶æ„ (Directory Structure)

é¡¹ç›®åŸºäº `src` å¸ƒå±€ï¼Œä¸¥æ ¼åˆ†ç¦»æ ¸å¿ƒä¸šåŠ¡ã€å·¥å…·ã€æ‰§è¡Œå±‚å’Œè¾…åŠ©æœåŠ¡ã€‚

```text
olav/
â”œâ”€â”€ .env.example                # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml          # ç¼–æ’æ‰€æœ‰å®¹å™¨
â”œâ”€â”€ Dockerfile                  # ä¸»ç¨‹åº olav-app é•œåƒ
â”œâ”€â”€ Dockerfile.embedder         # å‘é‡åŒ–æœåŠ¡ olav-embedder é•œåƒ
â”œâ”€â”€ Makefile                    # å¼€å‘å‘½ä»¤ (test, lint, up, ingest)
â”œâ”€â”€ pyproject.toml              # ä¾èµ–ç®¡ç† (Ruff, Pytest)
â”œâ”€â”€ config/                     # å…¨å±€é…ç½®
â”‚   â”œâ”€â”€ prompts/                # LangChain æç¤ºè¯æ¨¡æ¿ (YAML)
â”‚   â”‚   â”œâ”€â”€ agents/             # Agent ç³»ç»Ÿæç¤ºè¯
â”‚   â”‚   â””â”€â”€ tools/              # Tool æè¿°æ¨¡æ¿
â”‚   â”œâ”€â”€ inventory_template.csv  # CSV è®¾å¤‡å¯¼å…¥æ¨¡æ¿
â”‚   â””â”€â”€ app_settings.template.yaml # åº”ç”¨é…ç½®æ¨¡æ¿ç¤ºä¾‹
â”œâ”€â”€ data/                       # æŒ‚è½½æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ documents/              # å¾…ä¸Šä¼ çš„ PDF/MD
â”‚   â”œâ”€â”€ suzieq-parquet/         # SuzieQ æ•°æ®
â”‚   â””â”€â”€ generated_configs/      # åŠ¨æ€ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ (suzieq_config.yml)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ olav/                   # [ä¸»ç¨‹åº] OLAV Agent
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py             # CLI å…¥å£ (Typer + Rich)
â”‚   â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¡†æ¶
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py     # âœ… Pydantic Settings (Env Loading)
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py        # âœ… TypedDict çŠ¶æ€å®šä¹‰
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py          # âœ… LLM Factory (å¤šå‚å•†æ”¯æŒ)
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py       # âœ… OpenSearch è¯»å†™å°è£…
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_manager.py # âœ… æç¤ºè¯æ¨¡æ¿ç®¡ç†å™¨
â”‚   â”‚   â”‚   â””â”€â”€ inventory_manager.py # âœ… NetBox CSV å¯¼å…¥ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ agents/             # æ™ºèƒ½ä½“ (ä¸šåŠ¡é€»è¾‘)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ root_agent.py   # âœ… Supervisor / è·¯ç”±é€»è¾‘ (create_deep_agent)
â”‚   â”‚   â”‚   â”œâ”€â”€ suzieq_agent.py # âœ… å®è§‚åˆ†æ (SubAgent Factory)
â”‚   â”‚   â”‚   â”œâ”€â”€ netconf_agent.py# âœ… å¾®è§‚è¯Šæ–­ (SubAgent Factory + HITL)
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_agent.py    # âœ… çŸ¥è¯†æ£€ç´¢ä»£ç† (SubAgent Factory)
â”‚   â”‚   â”‚   â”œâ”€â”€ learner_agent.py# âœ… è‡ªæˆ‘å­¦ä¹ /åæ€èŠ‚ç‚¹ (SubAgent Factory)
â”‚   â”‚   â”‚   â””â”€â”€ middleware/     # è‡ªå®šä¹‰ä¸­é—´ä»¶
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â””â”€â”€ network_context.py # âœ… æ³¨å…¥ç½‘ç»œä¸Šä¸‹æ–‡
â”‚   â”‚   â”œâ”€â”€ tools/              # å·¥å…·å±‚ (Interface Layer)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ opensearch_tool.py # âœ… OpenSearch ç»Ÿä¸€æ£€ç´¢æ¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ suzieq_tool.py  # âœ… SuzieQ Query Interface (Schema-Aware)
â”‚   â”‚   â”‚   â”œâ”€â”€ nornir_tool.py  # âœ… Nornir Execution Interface
â”‚   â”‚   â”‚   â”œâ”€â”€ netbox_tool.py  # âœ… NetBox API å·¥å…· (Schema-Aware)
â”‚   â”‚   â”‚   â””â”€â”€ datetime_tool.py# âœ… æ—¶é—´è§£æå·¥å…· (è‡ªç„¶è¯­è¨€ -> æ—¶é—´æˆ³)
â”‚   â”‚   â”œâ”€â”€ execution/          # æ‰§è¡Œå±‚ (Backend + Sandbox)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ backends/       # Backend å®ç°
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ protocol.py  # âœ… Backend åè®®å®šä¹‰
â”‚   â”‚   â”‚       â”œâ”€â”€ nornir_sandbox.py # âœ… Nornir æ²™ç›’ (HITL + åŠ¨æ€é…ç½®)
â”‚   â”‚   â”‚       â”œâ”€â”€ state.py     # â³ StateBackend (å¼€å‘ç¯å¢ƒ)
â”‚   â”‚   â”‚       â””â”€â”€ redis.py     # â³ RedisBackend (ç”Ÿäº§ç¯å¢ƒ)
â”‚   â”‚   â””â”€â”€ etl/                # æ•°æ®å¤„ç† (Schema + Config Generation)
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ init_postgres.py # âœ… PostgreSQL Checkpointer åˆå§‹åŒ–
â”‚   â”‚       â”œâ”€â”€ init_schema.py  # âœ… OpenConfig YANG Schema ç´¢å¼•
â”‚   â”‚       â”œâ”€â”€ suzieq_schema_etl.py # âœ… SuzieQ Avro Schema ç´¢å¼•
â”‚   â”‚       â”œâ”€â”€ netbox_schema_etl.py # âœ… NetBox OpenAPI Schema ç´¢å¼•
â”‚   â”‚       â””â”€â”€ generate_configs.py # âœ… åŠ¨æ€ç”Ÿæˆ SuzieQ é…ç½®
â”‚   â””â”€â”€ embedder/               # â³ [å¾®æœåŠ¡] æ–‡æ¡£å‘é‡åŒ–æœåŠ¡ (å¾…å®ç°)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py             # FastAPI å…¥å£
â”‚       â”œâ”€â”€ loader.py           # PDF/Text Loaders
â”‚       â””â”€â”€ vectorizer.py       # åˆ‡ç‰‡ä¸ Embedding é€»è¾‘
â””â”€â”€ tests/                      # æµ‹è¯•å¥—ä»¶
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py             # Pytest Fixtures
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ test_agents.py
    â”‚   â”œâ”€â”€ test_sandbox.py
    â”‚   â””â”€â”€ test_llm_factory.py
    â””â”€â”€ e2e/
        â””â”€â”€ test_workflow.py
```

---

## 4. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 4.1 LLM Core (`src/olav/core/llm.py`)
**èŒè´£**: ç»Ÿä¸€çš„ LLM å·¥å‚ï¼Œå±è”½ OpenAI, Azure, Ollama çš„å·®å¼‚ã€‚
*   `get_chat_model(json_mode=True)`: è·å–ä¸»æ¨¡å‹ï¼Œæ”¯æŒ JSON Modeã€‚
*   `get_vision_model()`: è·å–è§†è§‰æ¨¡å‹ï¼ˆç”¨äºæœªæ¥æ‹“æ‰‘å›¾åˆ†æï¼‰ã€‚
*   `get_embedding_model()`: è·å–å‘é‡æ¨¡å‹ï¼ˆç”¨äº RAGï¼‰ã€‚
*   **é…ç½®é©±åŠ¨**: å®Œå…¨ç”± `.env` ä¸­çš„ `LLM_PROVIDER` æ§åˆ¶ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
from config.settings import settings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.chat_models import ChatOllama

class LLMFactory:
    @staticmethod
    def get_chat_model(json_mode: bool = False):
        if settings.LLM_PROVIDER == "openai":
            return ChatOpenAI(
                model=settings.LLM_MODEL_NAME,
                api_key=settings.LLM_API_KEY,
                model_kwargs={"response_format": {"type": "json_object"}} if json_mode else {}
            )
        elif settings.LLM_PROVIDER == "ollama":
            return ChatOllama(
                model=settings.LLM_MODEL_NAME,
                base_url=settings.LLM_BASE_URL,
                format="json" if json_mode else None
            )
    
    @staticmethod
    def get_embedding_model():
        if settings.LLM_PROVIDER == "openai":
            return OpenAIEmbeddings(api_key=settings.LLM_API_KEY)
        # ... ollama embeddings
```

### 4.2 RAG Agent (`src/olav/agents/rag_agent.py`)
**èŒè´£**: çŸ¥è¯†æ£€ç´¢çš„ç»Ÿä¸€å…¥å£ï¼Œå®ç°æ™ºèƒ½æ£€ç´¢ç­–ç•¥ã€‚

**æ£€ç´¢ç­–ç•¥ (Tiered Retrieval)**:
1. **Memory First**: ä¼˜å…ˆæŸ¥è¯¢ `olav-episodic-memory` ç´¢å¼•
   - å¦‚æœç”¨æˆ·æ„å›¾ä¸å†å²æˆåŠŸæ¡ˆä¾‹ç›¸ä¼¼åº¦ > 0.85ï¼Œç›´æ¥è¿”å›ç»éªŒè·¯å¾„
   - ä¼˜åŠ¿ï¼šå¿«é€Ÿå“åº”ï¼Œé¿å…é‡å¤æ¨ç†
2. **Schema Fallback**: Memory æœªå‘½ä¸­æ—¶æŸ¥è¯¢ `openconfig-schema` ç´¢å¼•
   - åŸºäºç”¨æˆ·æ„å›¾æå–å…³é”®è¯ï¼ˆå¦‚ "BGP neighbor"ï¼‰
   - è¿”å›ç²¾ç¡®çš„ YANG XPath å’Œæ•°æ®ç±»å‹
3. **Docs Support**: éœ€è¦åè®®åŸç†æˆ–å‚å•†ç‰¹å®šä¿¡æ¯æ—¶æŸ¥è¯¢ `olav-docs` ç´¢å¼•
   - è¿”å›ç›¸å…³æ–‡æ¡£ç‰‡æ®µä¾› LLM ç†è§£ä¸Šä¸‹æ–‡

**æ¥å£è®¾è®¡**:
```python
class RAGAgent:
    def search_knowledge(
        self,
        query: str,
        knowledge_type: Literal["memory", "schema", "docs", "auto"] = "auto",
        top_k: int = 3
    ) -> List[Dict]:
        """ç»Ÿä¸€çŸ¥è¯†æ£€ç´¢æ¥å£"""
        pass
```

### 4.3 çŸ¥è¯†åº“ä¸‰å±‚ç´¢å¼• (Knowledge Base)
ç³»ç»Ÿç»´æŠ¤ä¸‰ä¸ª OpenSearch ç´¢å¼•ï¼Œå¯¹åº”ä¸‰å±‚çŸ¥è¯†:
1.  **Schema Index (`openconfig-schema`)**:
    *   æ¥æº: `olav-init` å®¹å™¨å¯åŠ¨æ—¶ä» GitHub æ‹‰å– OpenConfig YANG å¹¶è§£æã€‚
    *   ç”¨é€”: è®© Agent æŸ¥æ‰¾å‡†ç¡®çš„ XPathï¼Œé¿å…å¹»è§‰ã€‚
2.  **Docs Index (`olav-docs`)**:
    *   æ¥æº: `olav-embedder` æœåŠ¡å¼‚æ­¥æ‰«æ `data/documents/` ç›®å½•ä¸‹çš„ PDF/MDã€‚
    *   ç”¨é€”: æŸ¥è¯¢å‚å•†æ‰‹å†Œã€è®¾è®¡è§„èŒƒã€åè®®åŸç†ã€‚
3.  **Memory Index (`olav-episodic-memory`)**:
    *   æ¥æº: è¿è¡Œæ—¶ç”± `learner_agent.py` å†™å…¥ã€‚
    *   ç”¨é€”: å­˜å‚¨æˆåŠŸçš„æ’é”™è·¯å¾„ï¼ˆUser Intent -> Successful XPathï¼‰ã€‚å®ç°â€œè¶Šç”¨è¶Šå¿«â€ã€‚

### 4.4 Backend æ¶æ„ (åŸºäº DeepAgents Backend Protocol)
å— DeepAgents å¯å‘ï¼ŒOLAV å®ç°ä¸‰å±‚ Backend åè®®æ ˆï¼š

**Backend åè®®**:
```python
# src/olav/execution/backends/protocol.py
from typing import Protocol

class BackendProtocol(Protocol):
    """Backend åŸºç¡€åè®®"""
    async def read(self, path: str) -> str: ...
    async def write(self, path: str, content: str) -> None: ...
    async def ls(self, path: str) -> List[str]: ...

class SandboxBackendProtocol(BackendProtocol, Protocol):
    """æ”¯æŒå‘½ä»¤æ‰§è¡Œçš„ Sandbox Backend"""
    async def execute(
        self,
        command: str,
        background: bool = False
    ) -> ExecutionResult: ...

class StoreBackendProtocol(BackendProtocol, Protocol):
    """æ”¯æŒæŒä¹…åŒ–å­˜å‚¨çš„ Backendï¼ˆç”¨äº Memoryï¼‰"""
    async def put(self, namespace: str, key: str, value: dict) -> None: ...
    async def search(self, namespace: str, query: dict) -> List[dict]: ...
```

**Backend å®ç°**:
1.  **StateBackend**: åŸºäº LangGraph Stateï¼ˆå¼€å‘/æµ‹è¯•ç¯å¢ƒï¼‰
2.  **RedisBackend**: åŸºäº Redis + OpenSearchï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
3.  **NornirSandbox**: å®ç° `SandboxBackendProtocol`ï¼ˆç½‘ç»œè®¾å¤‡æ‰§è¡Œï¼‰

```python
# src/olav/execution/backends/nornir_sandbox.py
from deepagents.backends.protocol import SandboxBackendProtocol

class NornirSandbox(SandboxBackendProtocol):
    """Nornir æ‰§è¡Œæ²™ç›’ï¼Œå®ç° HITL å’Œå®¡è®¡"""
    
    def __init__(self, nornir_config: str):
        from olav.execution.nornir_loader import get_nornir
        self.nr = get_nornir()
        self.audit_log = []
    
    async def execute(
        self,
        command: str,  # NETCONF XML Payload
        background: bool = False,
        requires_approval: bool = True
    ) -> ExecutionResult:
        """æ‰§è¡Œ NETCONF å‘½ä»¤ï¼ˆå¸¦ HITLï¼‰"""
        
        # åˆ†ææ“ä½œç±»å‹
        is_write = self._is_write_operation(command)
        
        if is_write and requires_approval:
            # è§¦å‘ HITLï¼ˆé€šè¿‡ LangGraph interruptï¼‰
            approval = await self._request_approval(command)
            if approval.decision == "reject":
                return ExecutionResult(success=False, output="User rejected")
            elif approval.decision == "edit":
                command = approval.edited_command
        
        # è®°å½•å®¡è®¡æ—¥å¿—
        self._log_execution(command, is_write)
        
        # è°ƒç”¨ Nornir æ‰§è¡Œ
        result = self.nr.run(
            task=netconf_task,
            payload=command
        )
        
        return ExecutionResult.from_nornir(result)
```

### 4.5 æ‰§è¡Œæ²™ç›’ (`src/olav/execution/sandbox.py`)
**èŒè´£**: Backend å±‚çš„å®‰å…¨æ‰§è¡Œå™¨ã€‚
*   å®ç° `SandboxBackendProtocol` åè®®
*   æ¥æ”¶ `nornir_tool.py` ä¼ é€’çš„æŒ‡ä»¤ï¼ˆXML Payloadï¼‰
*   åˆ†ææŒ‡ä»¤ç±»å‹ï¼ˆRead vs Writeï¼‰
*   Write æ“ä½œé€šè¿‡ LangGraph `interrupt` æœºåˆ¶è§¦å‘ HITL
*   è®°å½•å®¡è®¡æ—¥å¿—åˆ° OpenSearch `olav-audit` ç´¢å¼•
*   è°ƒç”¨ Nornir æ‰§è¡Œå¹¶è¿”å›ç»“æ„åŒ–ç»“æœ

### 4.6 Middleware æ¶æ„ (LangChain Middleware Pattern)
åŸºäº **LangChain V1 Middleware** è®¾è®¡æ¨¡å¼ï¼ŒOLAV é‡‡ç”¨ä¸­é—´ä»¶æ ˆå®ç°æ¨ªåˆ‡å…³æ³¨ç‚¹ï¼š

**æ ¸å¿ƒä¸­é—´ä»¶**:
*   **TodoListMiddleware**: è‡ªåŠ¨ä»»åŠ¡åˆ†è§£ä¸è·Ÿè¸ªï¼ˆæ¥è‡ª `langchain.agents.middleware.todo`ï¼‰
*   **HumanInTheLoopMiddleware**: HITL å®¡æ‰¹æœºåˆ¶ï¼ˆé…ç½® `interrupt_on` å‚æ•°ï¼‰
*   **SummarizationMiddleware**: é•¿å¯¹è¯è‡ªåŠ¨æ‘˜è¦ï¼ˆ170K tokens é˜ˆå€¼ï¼‰
*   **AnthropicPromptCachingMiddleware**: Prompt ç¼“å­˜ä¼˜åŒ–
*   **ModelRetryMiddleware**: LLM è°ƒç”¨é‡è¯•ç­–ç•¥
*   **ToolSelectionMiddleware**: å·¥å…·é€‰æ‹©ä¼˜åŒ–

**è‡ªå®šä¹‰ä¸­é—´ä»¶**:
```python
# src/olav/agents/middleware/network_context.py
from langchain.agents.middleware import AgentMiddleware

class NetworkContextMiddleware(AgentMiddleware):
    """æ³¨å…¥ç½‘ç»œä¸Šä¸‹æ–‡ï¼ˆæ‹“æ‰‘ã€è®¾å¤‡çŠ¶æ€ï¼‰åˆ°æ¯ä¸ªè¯·æ±‚"""
    
    async def on_model_request(self, request: ModelRequest, state: AgentState):
        # ä» NetBox è·å–æ‹“æ‰‘ä¿¡æ¯
        topology = await self.get_topology_context(state.get('device'))
        request.messages.insert(0, SystemMessage(content=f"Network Context: {topology}"))
        return request
```

### 4.7 æ™ºèƒ½ä½“ç¼–æ’ (LangGraph + Deep Agents)
é‡‡ç”¨ **LangChain Deep Agents** æ¡†æ¶ï¼Œé€šè¿‡ `create_deep_agent` åˆ›å»ºï¼š

**Memory å…±äº«æœºåˆ¶** ğŸ”‘:
```python
# ä½¿ç”¨ LangGraph Checkpointer å®ç°è·¨ Agent çš„ State æŒä¹…åŒ–
from langgraph.checkpoint.postgres import PostgresSaver
import os

# åˆ›å»ºå…±äº« Checkpointerï¼ˆå¼€å‘å’Œç”Ÿäº§ç¯å¢ƒç»Ÿä¸€ä½¿ç”¨ PostgreSQLï¼‰
checkpointer = PostgresSaver.from_conn_string(
    os.getenv("POSTGRES_URI", "postgresql://olav:OlavPG123!@localhost:5432/olav")
)

# åˆå§‹åŒ– Checkpointer è¡¨ç»“æ„ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
checkpointer.setup()

agent = create_deep_agent(
    model=model,
    checkpointer=checkpointer,  # ğŸ”‘ æ‰€æœ‰ SubAgent å…±äº«æ­¤ Checkpointer
    subagents=[suzieq_subagent, nornir_subagent],
    ...
)
```

**State ä¼ é€’è§„åˆ™**:
- **Parent â†’ SubAgent**: è‡ªåŠ¨è¿‡æ»¤ `messages` å’Œ `todos` å­—æ®µï¼ˆé¿å…æ±¡æŸ“å­ä¸Šä¸‹æ–‡ï¼‰
  ```python
  # æºç : deepagents/middleware/subagents.py
  _EXCLUDED_STATE_KEYS = ("messages", "todos")
  subagent_state = {k: v for k, v in runtime.state.items() 
                    if k not in _EXCLUDED_STATE_KEYS}
  ```
- **SubAgent â†’ Parent**: åªè¿”å›æœ€åä¸€æ¡æ¶ˆæ¯ + è‡ªå®šä¹‰ State å­—æ®µ
  ```python
  return Command(
      update={
          **custom_state_fields,  # å¦‚: device_status, network_topology
          "messages": [ToolMessage(result["messages"][-1].text, ...)]
      }
  )
  ```
- **çº¿ç¨‹éš”ç¦»**: é€šè¿‡ `thread_id` éš”ç¦»ä¸åŒç”¨æˆ·ä¼šè¯
  ```python
  config = {"configurable": {"thread_id": "user-123"}}
  agent.invoke({"messages": [...]}, config=config)
  ```

**Agent è§’è‰²å®šä¹‰**:

*   **Root Agent (`root_agent.py`)**: ä½¿ç”¨ `create_deep_agent()` åˆ›å»ºä¸»ç¼–æ’å™¨
    - **å†…ç½®ä¸­é—´ä»¶**: TodoList â†’ Filesystem â†’ SubAgent â†’ Summarization â†’ HITL
    - è‡ªåŠ¨ç”Ÿæˆå¤šæ­¥éª¤æ‰§è¡Œè®¡åˆ’ï¼ˆTODO Listï¼‰
    - åŠ¨æ€è·¯ç”±åˆ°ä¸“ä¸š SubAgentï¼ˆSuzieQ/RAG/Netconfï¼‰
    - æ”¯æŒ `recursion_limit=1000` æ·±åº¦ä»»åŠ¡
    
*   **SuzieQ SubAgent**: é…ç½®ä¸ºåªè¯» SubAgentï¼ˆ**æ— éœ€æ²™ç›’ï¼Œç›´æ¥æŸ¥è¯¢ Parquet**ï¼‰
    ```python
    suzieq_subagent = SubAgent(
        name="suzieq-analyzer",
        description="æŸ¥è¯¢å†å²ç½‘ç»œæ•°æ®å’Œè¶‹åŠ¿åˆ†æï¼ˆåªè¯»ï¼Œæ— å‰¯ä½œç”¨ï¼‰",
        prompt="""ä½ æ˜¯ç½‘ç»œå¯è§‚æµ‹æ€§ä¸“å®¶ï¼Œä½¿ç”¨ SuzieQ åˆ†æå†å²æ•°æ®ã€‚
        
        SuzieQ æ˜¯åªè¯»å·¥å…·ï¼ŒæŸ¥è¯¢å­˜å‚¨åœ¨ Parquet æ–‡ä»¶ä¸­çš„å†å²æ•°æ®ã€‚
        ä½¿ç”¨ suzieq_schema_search æŸ¥è¯¢å¯ç”¨çš„è¡¨å’Œå­—æ®µã€‚
        ä½¿ç”¨ suzieq_query æ‰§è¡Œå®é™…æŸ¥è¯¢ã€‚
        """,
        tools=[suzieq_schema_search, suzieq_query, datetime_tool]
        # æ³¨æ„ï¼šä¸éœ€è¦ interrupt_onï¼Œå› ä¸ºæ˜¯åªè¯»æ“ä½œ
    )
    ```
    
*   **RAG SubAgent**: çŸ¥è¯†æ£€ç´¢ä¸“å®¶ï¼ˆä¸‰å±‚ç­–ç•¥ï¼‰
    ```python
    rag_subagent = SubAgent(
        name="knowledge-retriever",
        description="æ£€ç´¢ OpenConfig Schemaã€æ–‡æ¡£å’Œå†å²ç»éªŒ",
        prompt="æ‰§è¡Œæ™ºèƒ½çŸ¥è¯†æ£€ç´¢ï¼šMemoryä¼˜å…ˆ â†’ Schemaå›é€€ â†’ Docsè¡¥å……",
        tools=[opensearch_tool]
    )
    ```
    
*   **Netconf SubAgent**: å®æ—¶è¯Šæ–­ Agentï¼ˆå¸¦ HITLï¼‰
    ```python
    netconf_subagent = SubAgent(
        name="netconf-executor",
        description="æ‰§è¡Œ NETCONF/gNMI å®æ—¶è®¾å¤‡æ“ä½œ",
        prompt="åŸºäº OpenConfig Schema æ„å»º NETCONF Payload",
        tools=[nornir_tool],
        interrupt_on={
            "nornir_tool": {"allowed_decisions": ["approve", "edit", "reject"]}
        }
    )
    ```

#### 4.7.1 CLI/NETCONF åŒæ¨¡å¼ç­–ç•¥ï¼ˆç»Ÿä¸€ HITL æ‰§è¡Œï¼‰

**èƒŒæ™¯**: GNS3/EVE-NG ç­‰æ¨¡æ‹Ÿå™¨çš„ Cisco IOS é•œåƒé€šå¸¸ä¸æ”¯æŒ NETCONFï¼Œéœ€è¦é™çº§åˆ°ä¼ ç»Ÿ CLI æ¨¡å¼ã€‚

**è®¾è®¡åŸåˆ™** ğŸ”‘:
1. **åªè¯»åœºæ™¯**: NTC-Templates è‡ªåŠ¨è§£æ â†’ ç»“æ„åŒ– JSONï¼ˆå®Œå…¨è‡ªåŠ¨åŒ–ï¼‰
2. **é…ç½®å˜æ›´åœºæ™¯**: CLI/NETCONF åŒæ¨¡å¼ â†’ **ç»Ÿä¸€ HITL å®¡æ‰¹æµç¨‹** â†’ OLAV æ‰§è¡Œ
3. **åŒè·¯ç”±æ¶æ„**: è‡ªåŠ¨æ£€æµ‹è®¾å¤‡èƒ½åŠ› â†’ NETCONF ä¼˜å…ˆ / CLI é™çº§ï¼ˆéƒ½æ”¯æŒæ‰§è¡Œï¼‰

**åˆ†å±‚ç­–ç•¥**:
```
User Intent ("é…ç½®æ¥å£æè¿°")
    â†“
Schema-Aware Discovery (ä» ntc-schema ç´¢å¼•æŸ¥è¯¢)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NETCONF å¯ç”¨ â”‚ NETCONF ä¸å¯ç”¨â”‚
â”‚  (ç”Ÿäº§è®¾å¤‡)  â”‚   (æ¨¡æ‹Ÿå™¨)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
  ç”Ÿæˆ NETCONF RPC  ç”Ÿæˆ CLI å‘½ä»¤
  (OpenConfig YANG) (å¹³å°ç‰¹å®šè¯­æ³•)
       â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         HITL å®¡æ‰¹
    (approve/edit/reject)
              â†“
    æ‰§è¡Œé…ç½® (Nornir)
              â†“
    å®¡è®¡æ—¥å¿— + è‡ªåŠ¨éªŒè¯
```

**NTC-Templates Schema ç´¢å¼•è®¾è®¡**:

ETL è„šæœ¬ä» `archive/ntc-templates/ntc_templates/templates/` æå–å…ƒæ•°æ®ï¼š

```python
# src/olav/etl/ntc_schema_etl.py
def index_ntc_templates():
    """
    éå† ntc-templates/*.textfsm
    æå–: platform, command, fields, semantic_tags
    å†™å…¥ OpenSearch ntc-schema ç´¢å¼•
    """
    
# ç´¢å¼•æ–‡æ¡£ç»“æ„
{
    "platform": "cisco_ios",
    "command": "show interfaces",
    "parser": "cisco_ios_show_interfaces.textfsm",
    "fields": ["interface", "link_status", "protocol", "mtu", "bandwidth"],
    "semantic_tags": ["æ¥å£çŠ¶æ€", "interface status", "port info"],
    "template_path": "templates/cisco_ios_show_interfaces.textfsm",
    "is_read_only": true
}
```

**Schema-Aware å·¥å…·å‡çº§**:

```python
# src/olav/tools/nornir_tool.pyï¼ˆå‡çº§ç‰ˆï¼‰
@tool
def query_device_adaptive(
    device: str,
    intent: str,  # "è·å–æ¥å£çŠ¶æ€" / "ä¿®æ”¹æ¥å£æè¿°"
    method: Literal["netconf", "cli", "auto"] = "auto",
    config_commands: Optional[List[str]] = None,  # ğŸ”‘ é…ç½®å‘½ä»¤åˆ—è¡¨ï¼ˆè§¦å‘HITLï¼‰
    requires_approval: bool = True  # ğŸ”‘ é…ç½®å˜æ›´å¿…é¡»å®¡æ‰¹
) -> Dict:
    """
    è‡ªé€‚åº”æŸ¥è¯¢/é…ç½®å·¥å…·ï¼š
    
    åªè¯»æ¨¡å¼ (config_commands=None):
    1. auto æ¨¡å¼: è‡ªåŠ¨æ£€æµ‹è®¾å¤‡èƒ½åŠ›ï¼ˆæ¢æµ‹ TCP 830/22ï¼‰
    2. NETCONF å¯ç”¨: æ‰§è¡Œ get-config RPC
    3. NETCONF ä¸å¯ç”¨: 
       - æŸ¥è¯¢ ntc-schema è·å–åŒ¹é…å‘½ä»¤
       - æ‰§è¡Œ Netmiko å‘½ä»¤ï¼ˆuse_textfsm=Trueï¼‰
       - è¿”å›ç»“æ„åŒ– JSON
    
    é…ç½®æ¨¡å¼ (config_commands=[...]):
    1. æ£€æµ‹è®¾å¤‡èƒ½åŠ› â†’ ç”Ÿæˆ NETCONF RPC æˆ– CLI å‘½ä»¤
    2. è§¦å‘ LangGraph HITL interruptï¼ˆç­‰å¾…äººå·¥å®¡æ‰¹ï¼‰
    3. å®¡æ‰¹é€šè¿‡ â†’ æ‰§è¡Œé…ç½® â†’ è®°å½•å®¡è®¡æ—¥å¿—
    4. CLI æ¨¡å¼é¢å¤–è­¦å‘Š: æ—  NETCONF åŸå­å›æ»š
    """

@tool
def discover_commands(
    intent: str,
    platform: str = "cisco_ios"
) -> List[Dict]:
    """
    ä» ntc-schema ç´¢å¼•å‘ç°å¯ç”¨å‘½ä»¤ï¼ˆæ”¯æŒè¯­ä¹‰æœç´¢ï¼‰
    
    è¾“å…¥: intent="æ¥å£æµé‡ç»Ÿè®¡", platform="cisco_ios"
    è¾“å‡º: [
        {
            "command": "show interfaces",
            "parser": "cisco_ios_show_interfaces.textfsm",
            "fields": ["interface", "input_packets", "output_packets"],
            "is_read_only": true
        }
    ]
    """
```

**é…ç½®å˜æ›´çš„ç»Ÿä¸€æ‰§è¡Œæ¨¡å¼**:

é…ç½®å˜æ›´é€šè¿‡ `query_device_adaptive` çš„ `config_commands` å‚æ•°è§¦å‘ï¼š

```python
# Agent è°ƒç”¨ç¤ºä¾‹
result = query_device_adaptive(
    device="R1",
    intent="ä¿®æ”¹æ¥å£æè¿°ä¸º CORE-UPLINK",
    config_commands=[
        "configure terminal",
        "interface GigabitEthernet0/1",
        "description CORE-UPLINK",
        "end",
        "write memory"
    ]
)

# å·¥å…·å†…éƒ¨æµç¨‹:
# 1. æ£€æµ‹åˆ° config_commands éç©º â†’ è¿›å…¥é…ç½®æ¨¡å¼
# 2. æ£€æµ‹è®¾å¤‡ NETCONF èƒ½åŠ›
# 3. æ„å»ºå®¡æ‰¹è¯·æ±‚ï¼ˆåŒ…å«å‘½ä»¤ã€å›æ»šæ–¹æ¡ˆã€é£é™©è­¦å‘Šï¼‰
# 4. è§¦å‘ LangGraph interrupt
# 5. ç­‰å¾…ç”¨æˆ·å†³ç­–: approve/edit/reject
# 6. æ‰§è¡Œå¹¶è®°å½•å®¡è®¡æ—¥å¿—
```

**Agent Prompt æ›´æ–°ï¼ˆå¹³å°æ„ŸçŸ¥è®¾è®¡ï¼‰**:

```python
# config/prompts/agents/netconf_agent.yaml
template: |
  ä½ æ˜¯ç½‘ç»œè®¾å¤‡é…ç½®ä¸“å®¶ï¼Œè´Ÿè´£æ‰§è¡Œå®æ—¶è¯Šæ–­å’Œé…ç½®ä»»åŠ¡ã€‚
  
  å½“å‰è®¾å¤‡ä¿¡æ¯:
  - è®¾å¤‡å: {device_name}
  - å¹³å°: {device_platform}  # cisco_ios / cisco_nxos / arista_eos / juniper_junos
  - ç®¡ç†IP: {device_ip}
  - NETCONFæ”¯æŒ: {netconf_available}  # true/false
  
  å¹³å°å‘½ä»¤è¯­æ³•æ˜ å°„:
  - cisco_ios/iosxr: "configure terminal" â†’ "interface xxx" â†’ "end" â†’ "write memory"
  - cisco_nxos: "config t" â†’ "interface xxx" â†’ "copy running-config startup-config"
  - arista_eos: "configure" â†’ "interface xxx" â†’ "write memory"
  - juniper_junos: "edit" â†’ "set interfaces xxx" â†’ "commit"
  - huawei_vrp: "system-view" â†’ "interface xxx" â†’ "commit"
  
  å·¥ä½œæµç¨‹:
  
  1. **åªè¯»è¯Šæ–­ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰**:
     - ä½¿ç”¨ query_device_adaptive(device="{device_name}", intent="...", method="auto")
     - NETCONF å¯ç”¨: æ‰§è¡Œ get-config RPC
     - NETCONF ä¸å¯ç”¨: è‡ªåŠ¨é™çº§åˆ° CLI + TextFSM è§£æ
     - è¿”å›ç»“æ„åŒ– JSON
  
  2. **é…ç½®å˜æ›´ï¼ˆHITL å®¡æ‰¹æ‰§è¡Œï¼‰**:
     A. ç”Ÿæˆå¹³å°ç‰¹å®šå‘½ä»¤:
        - æ ¹æ® {device_platform} ç”Ÿæˆæ­£ç¡®è¯­æ³•
        - ä½¿ç”¨ discover_commands æŸ¥è¯¢æ¨¡æ¿
     
     B. è°ƒç”¨é…ç½®å·¥å…·:
        ```python
        query_device_adaptive(
            device="{device_name}",
            intent="ä¿®æ”¹æ¥å£æè¿°",
            config_commands=[...],  # å¹³å°ç‰¹å®šå‘½ä»¤åˆ—è¡¨
            method="auto"  # è‡ªåŠ¨é€‰æ‹© NETCONF/CLI
        )
        ```
     
     C. ç­‰å¾… HITL å®¡æ‰¹:
        - ç³»ç»Ÿè‡ªåŠ¨æš‚åœï¼Œå±•ç¤ºå®¡æ‰¹ç•Œé¢
        - CLI æ¨¡å¼æ˜¾ç¤ºè­¦å‘Š: "âš ï¸ æ—  NETCONF åŸå­å›æ»š"
        - ç”¨æˆ·é€‰æ‹©: Approve / Edit / Reject
     
     D. æ‰§è¡ŒåéªŒè¯:
        - è‡ªåŠ¨è°ƒç”¨åªè¯»å‘½ä»¤éªŒè¯æ›´æ”¹
        - å¯¹æ¯”å˜æ›´å‰åé…ç½®å·®å¼‚
```
       
       R1# configure terminal
       R1(config)# interface GigabitEthernet0/1
       R1(config-if)# description CORE-UPLINK
       R1(config-if)# end
       R1# write memory
       
       å›æ»šå‘½ä»¤ï¼ˆå¦‚éœ€æ’¤é”€ï¼‰:
       R1(config-if)# no description
       ```
     - ä¸è¦è°ƒç”¨ nornir_tool æ‰§è¡Œé…ç½®å˜æ›´ï¼ˆæ¨¡æ‹Ÿå™¨æ—  NETCONF ä¿æŠ¤ï¼‰
  
  3. **ç”Ÿäº§ç¯å¢ƒï¼ˆNETCONF å¯ç”¨ï¼‰**:
     - é…ç½®å˜æ›´é€šè¿‡ nornir_tool æ‰§è¡Œ
     - è§¦å‘ HITL å®¡æ‰¹
     - æ”¯æŒ NETCONF åŸå­å›æ»š
```

**å‚è€ƒ baseline_collector.py çš„å…³é”®åŠŸèƒ½**:

ä» `archive/baseline_collector.py` å€Ÿé‰´ä»¥ä¸‹è®¾è®¡ï¼š

1. **TemplateManager** ç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰:
   - æ‰«æ ntc-templates ç›®å½•
   - è§£æ `cisco_ios_show_*.textfsm` â†’ æå– command å’Œ fields
   - ç¼“å­˜ `platform â†’ [(command, template_path, fields)]` æ˜ å°„

2. **TextFSM è‡ªåŠ¨è§£æ**:
   ```python
   # baseline_collector ä¸­çš„æ ¸å¿ƒé€»è¾‘
   result = nr.run(
       task=netmiko_send_command,
       command_string=command,
       use_textfsm=True  # ğŸ”‘ è‡ªåŠ¨è°ƒç”¨ NTC-Templates
   )
   ```

3. **é»‘åå•æœºåˆ¶**:
   - è¿‡æ»¤å±é™©å‘½ä»¤ï¼ˆtraceroute, reloadï¼‰
   - æ”¯æŒä» `command_blacklist.txt` åŠ è½½è‡ªå®šä¹‰è§„åˆ™

**ä¸é‡‡ç”¨çš„åŠŸèƒ½**:
- âŒ é…ç½®å¤‡ä»½è‡ªåŠ¨åŒ–ï¼ˆOLAV ä¸åšå®šæ—¶ä»»åŠ¡ï¼‰
- âŒ å¤šå‘½ä»¤æ‰¹é‡æ‰§è¡Œï¼ˆé™ä½å¤æ‚åº¦ï¼‰
- âŒ Gitea é›†æˆï¼ˆOLAV ä½¿ç”¨ OpenSearch Memoryï¼‰

**ETL å®ç°ä¼˜å…ˆçº§**:

1. **é«˜ä¼˜å…ˆçº§**: `src/olav/etl/ntc_schema_etl.py`
   - è§£æ ntc-templates ç›®å½•
   - ç´¢å¼•åˆ° OpenSearch `ntc-schema`
   - æ”¯æŒè¯­ä¹‰æœç´¢ï¼ˆ"æ¥å£çŠ¶æ€" â†’ "show interfaces"ï¼‰

2. **ä¸­ä¼˜å…ˆçº§**: `src/olav/tools/config_advisor.py`
   - ç”Ÿæˆé…ç½®å‘½ä»¤å»ºè®®
   - è¿”å› rollback å‘½ä»¤
   - ä»…è¿”å›æ–‡æœ¬ï¼Œä¸æ‰§è¡Œ

3. **ä½ä¼˜å…ˆçº§**: è®¾å¤‡èƒ½åŠ›æ¢æµ‹ï¼ˆNETCONF vs CLIï¼‰
   - å¯åœ¨ `nornir_sandbox.py` ä¸­å®ç°
   - ç¼“å­˜ç»“æœåˆ° Redisï¼ˆé¿å…é‡å¤æ¢æµ‹ï¼‰

**å…¸å‹ç”¨æˆ·äº¤äº’æµç¨‹**:

```
ç”¨æˆ·: "æ£€æŸ¥ R1 çš„æ¥å£çŠ¶æ€"
OLAV: [è°ƒç”¨ query_device_adaptive(device="R1", intent="æ¥å£çŠ¶æ€", method="auto")]
      æ£€æµ‹åˆ° R1 ä¸æ”¯æŒ NETCONFï¼Œé™çº§åˆ° CLI æ¨¡å¼
      æ‰§è¡Œå‘½ä»¤: show interfaces
      [è§£æ TextFSM æ¨¡æ¿]
      
      ç»“æœ:
      {
        "GigabitEthernet0/0": {"status": "up", "protocol": "up", "mtu": 1500},
        "GigabitEthernet0/1": {"status": "down", "protocol": "down", "mtu": 1500}
      }

ç”¨æˆ·: "ä¿®æ”¹ R1 çš„ GigabitEthernet0/1 æè¿°ä¸º CORE-UPLINK"
OLAV: [æŸ¥è¯¢è®¾å¤‡å¹³å°: cisco_ios]
      [ç”Ÿæˆ CLI å‘½ä»¤åºåˆ—]
      [è°ƒç”¨ query_device_adaptive(
          device="R1",
          config_commands=["configure terminal", "interface GigabitEthernet0/1", ...]
      )]
      
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘  é…ç½®å˜æ›´å®¡æ‰¹                                   â•‘
      â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
      â•‘  è®¾å¤‡: R1 (cisco_ios)                          â•‘
      â•‘  æ¨¡å¼: CLI (âš ï¸ æ— NETCONFåŸå­å›æ»š)              â•‘
      â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
      â•‘  å¾…æ‰§è¡Œå‘½ä»¤:                                    â•‘
      â•‘  1. configure terminal                         â•‘
      â•‘  2. interface GigabitEthernet0/1               â•‘
      â•‘  3. description CORE-UPLINK                    â•‘
      â•‘  4. end                                        â•‘
      â•‘  5. write memory                               â•‘
      â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
      â•‘  [A] Approve  [E] Edit  [R] Reject            â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ç”¨æˆ·: [é€‰æ‹© A - Approve]
OLAV: æ­£åœ¨æ‰§è¡Œé…ç½®å˜æ›´...
      âœ… é…ç½®å·²åº”ç”¨
      
      éªŒè¯ç»“æœ:
      GigabitEthernet0/1:
        Description: CORE-UPLINK âœ“
        Status: down â†’ up (å·²æ¿€æ´»)
      
      å®¡è®¡æ—¥å¿—å·²è®°å½•åˆ° OpenSearch (olav-audit ç´¢å¼•)
```

**å®‰å…¨è€ƒé‡**:
- âœ… åªè¯»å‘½ä»¤ï¼ˆshow/displayï¼‰: å®Œå…¨è‡ªåŠ¨åŒ–æ‰§è¡Œ
- âš ï¸ é…ç½®å˜æ›´ï¼ˆconfig/configureï¼‰: **å¼ºåˆ¶ HITL å®¡æ‰¹ + å®¡è®¡æ—¥å¿—**
- âŒ å±é™©å‘½ä»¤ï¼ˆreload/eraseï¼‰: é»‘åå•æ‹¦æˆª
- ğŸ”’ CLI æ¨¡å¼é¢å¤–è­¦å‘Š: æ— åŸå­å›æ»šï¼Œå»ºè®®æ‰§è¡Œå‰å¤‡ä»½é…ç½®

#### 4.7.2 åŒ Agent æ¶æ„ï¼ˆé¿å…å¹»è§‰ + Token ä¼˜åŒ– + è‡ªåŠ¨é™çº§ï¼‰

**è®¾è®¡ç›®æ ‡**: 
1. **é¿å…å¹»è§‰**: é€šè¿‡èŒè´£éš”ç¦»ï¼Œé˜²æ­¢ LLM æ··æ·† NETCONF XML å’Œ CLI å‘½ä»¤è¯­æ³•
2. **Token ä¼˜åŒ–**: åˆ†ç¦» Promptï¼ŒèŠ‚çœ **~400-500 tokens/æ¬¡è°ƒç”¨**
3. **è‡ªåŠ¨é™çº§**: Root Agent å…ˆå°è¯• NETCONFï¼Œå¤±è´¥åè‡ªåŠ¨åˆ‡æ¢åˆ° CLI

**æ¶æ„è®¾è®¡ï¼ˆLangGraph è·¯ç”±æ¨¡å¼ï¼‰**:

```
Root Agent (Orchestrator)
    â†“
    è°ƒç”¨ netconf_subagent
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NETCONF SubAgent æ‰§è¡Œ     â”‚
â”‚ - å°è¯•è¿æ¥ TCP:830        â”‚
â”‚ - æ‰§è¡Œ NETCONF RPC        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ æˆåŠŸ           â”‚ å¤±è´¥ (ConnectionError)
    â†“                â†“
è¿”å›ç»“æœ          netconf_subagent è¿”å›é”™è¯¯
                     â†“
              Root Agent æ£€æµ‹åˆ° NETCONF å¤±è´¥
                     â†“
              æ›´æ–°è®¡åˆ’: "NETCONF ä¸å¯ç”¨ï¼Œé™çº§åˆ° CLI"
                     â†“
              è°ƒç”¨ cli_subagent
                     â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ CLI SubAgent æ‰§è¡Œ    â”‚
              â”‚ - è¿æ¥ SSH (TCP:22) â”‚
              â”‚ - æ‰§è¡Œ CLI å‘½ä»¤      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ç°æ–¹å¼ï¼ˆåŸºäº LangGraph State + æ¡ä»¶è·¯ç”±ï¼‰**:

```python
# src/olav/agents/root_agent.py
from deepagents import create_deep_agent, SubAgent
from olav.core.prompt_manager import prompt_manager
from olav.agents.netconf_agent import netconf_subagent
from olav.agents.cli_agent import cli_subagent

# Root Agent Prompt
root_prompt = prompt_manager.load_agent_prompt(
    "root_agent",
    network_context="Enterprise Network Operations"
)

# åˆ›å»º Root Agent (åŒ…å«ä¸¤ä¸ª SubAgent)
root_agent = create_deep_agent(
    model=LLMFactory.get_chat_model(),
    system_prompt=root_prompt + """
    
## è®¾å¤‡æ“ä½œç­–ç•¥ï¼ˆæ¼æ–—å¼é™çº§ï¼‰

å½“ç”¨æˆ·è¯·æ±‚æ“ä½œè®¾å¤‡æ—¶ï¼Œéµå¾ªä»¥ä¸‹ç­–ç•¥:

1. **ä¼˜å…ˆå°è¯• NETCONF** (ç”Ÿäº§ç¯å¢ƒæ ‡å‡†)
   - è°ƒç”¨ netconf-executor SubAgent
   - å¦‚æœæ”¶åˆ° "NETCONF connection failed" æˆ– "Port 830 unreachable"
   - åˆ™æ‰§è¡Œæ­¥éª¤ 2

2. **è‡ªåŠ¨é™çº§åˆ° CLI** (å…¼å®¹ä¼ ç»Ÿè®¾å¤‡)
   - æ›´æ–°ä½ çš„è®¡åˆ’: "NETCONF ä¸å¯ç”¨ï¼Œä½¿ç”¨ CLI æ¨¡å¼"
   - è°ƒç”¨ cli-executor SubAgent
   - âš ï¸ æé†’ç”¨æˆ·: CLI æ¨¡å¼æ— åŸå­å›æ»šèƒ½åŠ›

3. **é”™è¯¯å¤„ç†**
   - å¦‚æœ CLI ä¹Ÿå¤±è´¥ â†’ æ£€æŸ¥è®¾å¤‡å¯è¾¾æ€§
   - å¼•å¯¼ç”¨æˆ·éªŒè¯: IPã€å‡­æ®ã€é˜²ç«å¢™è§„åˆ™

ç¤ºä¾‹å¯¹è¯:
ç”¨æˆ·: "æ£€æŸ¥ R1 çš„æ¥å£çŠ¶æ€"
ä½ çš„æ€è€ƒ:
1. è°ƒç”¨ netconf-executor(device="R1", operation="get-config", xpath="/interfaces")
2. [å¦‚æœå¤±è´¥] æ›´æ–°è®¡åˆ’ â†’ è°ƒç”¨ cli-executor(device="R1", command="show ip interface brief")
""",
    subagents=[netconf_subagent, cli_subagent],  # ğŸ”‘ ä¸¤ä¸ª Agent éƒ½æ³¨å†Œ
    checkpointer=checkpointer,
)
```

**NETCONF SubAgent (å…ˆé”‹å°è¯•)**:

```python
# src/olav/agents/netconf_agent.py
from deepagents import SubAgent
from olav.tools.nornir_tool import netconf_tool

netconf_subagent = SubAgent(
    name="netconf-executor",
    description="é€šè¿‡ NETCONF/YANG æ‰§è¡Œè®¾å¤‡æ“ä½œï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰",
    prompt=prompt_manager.load_agent_prompt("netconf_agent"),
    tools=[netconf_tool],
    interrupt_on={
        "netconf_tool": {
            "condition": lambda args: args.get("operation") == "edit-config",
            "allowed_decisions": ["approve", "edit", "reject"]
        }
    }
)
```

**CLI SubAgent (é™çº§å¤‡ä»½)**:

```python
# src/olav/agents/cli_agent.py
from deepagents import SubAgent
from olav.tools.nornir_tool import cli_tool
from olav.tools.ntc_tool import discover_commands

cli_subagent = SubAgent(
    name="cli-executor",
    description="é€šè¿‡ CLI å‘½ä»¤æ‰§è¡Œè®¾å¤‡æ“ä½œï¼ˆNETCONF å¤±è´¥æ—¶ä½¿ç”¨ï¼‰",
    prompt=prompt_manager.load_agent_prompt("cli_agent"),
    tools=[cli_tool, discover_commands],
    interrupt_on={
        "cli_tool": {
            "condition": lambda args: args.get("config_commands") is not None,
            "allowed_decisions": ["approve", "edit", "reject"]
        }
    }
)
```

**å…³é”®æ”¹è¿›ç‚¹**:

1. **Root Agent æ§åˆ¶æµç¨‹** (è€Œéé¢„å…ˆæ¢æµ‹)
   - âŒ æ—§æ–¹æ¡ˆ: `if probe_netconf_port(): use_netconf else: use_cli`
   - âœ… æ–°æ–¹æ¡ˆ: `try netconf â†’ catch error â†’ fallback to cli`
   
2. **é”™è¯¯é©±åŠ¨çš„é™çº§** (æ›´ç¬¦åˆå®é™…ç½‘ç»œåœºæ™¯)
   - NETCONF å¤±è´¥ä¸ä¸€å®šæ˜¯ç«¯å£é—®é¢˜ï¼ˆå¯èƒ½æ˜¯è®¤è¯ã€åè®®ç‰ˆæœ¬ï¼‰
   - çœŸå®å°è¯•è¿æ¥ â†’ æ ¹æ®å®é™…é”™è¯¯å†³å®šæ˜¯å¦é™çº§

3. **Root Agent çš„ Prompt åŒ…å«é™çº§é€»è¾‘**
   - LLM çœ‹åˆ° "NETCONF connection failed" é”™è¯¯
   - è‡ªåŠ¨æ›´æ–°è®¡åˆ’è°ƒç”¨ cli-executor
   - æ— éœ€ç¡¬ç¼–ç  if-else é€»è¾‘

4. **ä¸¤ä¸ª SubAgent å¹³ç­‰æ³¨å†Œ**
   - `subagents=[netconf_subagent, cli_subagent]`
   - Root Agent å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡è‡ªç”±é€‰æ‹©
   - ç¬¦åˆ DeepAgents çš„è®¾è®¡å“²å­¦

**Prompt æ–‡ä»¶ç»“æ„**:

```yaml
# config/prompts/agents/netconf_agent.yamlï¼ˆNETCONF Agent ä¸“ç”¨ï¼‰
_type: prompt
input_variables: []
template: |
  ä½ æ˜¯ OLAV çš„ **NETCONF æ‰§è¡Œä»£ç†** (ä¸“æ³¨äº NETCONF åè®®æ“ä½œ)ã€‚
  
  ## ä½ çš„èŒè´£
  1. **æŸ¥è¯¢æ“ä½œ** (`<get-config>`)
     - æ„é€  NETCONF RPC è¯·æ±‚
     - ä½¿ç”¨ XPath è¿‡æ»¤å™¨ç²¾å‡†æŸ¥è¯¢
     - ä¼˜å…ˆæŸ¥è¯¢ openconfig-schema ç´¢å¼•è·å–æ­£ç¡®çš„ YANG è·¯å¾„
  
  2. **é…ç½®æ“ä½œ** (`<edit-config>`)
     - æ„é€ ç¬¦åˆ OpenConfig è§„èŒƒçš„ XML Payload
     - **å¿…é¡»äººå·¥å®¡æ‰¹** (è§¦å‘ HITL ä¸­æ–­)
     - åˆ©ç”¨ NETCONF åŸå­å›æ»šèƒ½åŠ›
  
  3. **é”™è¯¯å¤„ç† (å…³é”®)**
     - å¦‚æœæ”¶åˆ° **"Connection refused"** æˆ– **"Port 830 unreachable"**
     - è¿”å›æ˜ç¡®é”™è¯¯: "NETCONF connection failed: {åŸå› }"
     - **è®© Root Agent å†³å®šæ˜¯å¦é™çº§åˆ° CLI**
  
  ## å·¥å…·ä½¿ç”¨
  - `netconf_tool(device, operation, xpath, payload)`
    - device: è®¾å¤‡åç§° (ä» Root Agent ä¼ é€’)
    - operation: "get-config" | "edit-config"
    - xpath: XPath è¿‡æ»¤å™¨ (æŸ¥è¯¢æ—¶ä½¿ç”¨)
    - payload: XML å­—ç¬¦ä¸² (é…ç½®æ—¶ä½¿ç”¨)
  
  ## ç¤ºä¾‹å¯¹è¯
  ç”¨æˆ·: "æ£€æŸ¥è®¾å¤‡çš„æ¥å£çŠ¶æ€"
  ä½ çš„æ‰§è¡Œ:
  1. æŸ¥è¯¢ openconfig-schema: "interface state"
  2. è·å– XPath: `/interfaces/interface/state`
  3. è°ƒç”¨: netconf_tool(device="...", operation="get-config", xpath="/interfaces/interface/state")
  
  å¦‚æœè¿æ¥å¤±è´¥:
  è¿”å›: "NETCONF connection failed: Connection refused on port 830. è®¾å¤‡å¯èƒ½ä¸æ”¯æŒ NETCONFã€‚"
  (Root Agent ä¼šè‡ªåŠ¨åˆ‡æ¢åˆ° CLI æ¨¡å¼)
  
  ## æ³¨æ„äº‹é¡¹
  - **ç»ä¸ä½¿ç”¨ CLI å‘½ä»¤è¯­æ³•** (å¦‚ `show ip bgp`)
  - **ç»ä¸å°è¯•ç”Ÿæˆ CLI å‘½ä»¤** (è¿™æ˜¯ cli-executor çš„èŒè´£)
  - æ‰€æœ‰é…ç½®éµå¾ª YANG Schema çº¦æŸ
  - è¿æ¥å¤±è´¥æ—¶è¿”å›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯ (ä¸è¦è‡ªå·±å°è¯•é™çº§)
```

```yaml
# config/prompts/agents/cli_agent.yamlï¼ˆCLI Agent ä¸“ç”¨ï¼‰
_type: prompt
input_variables: []
template: |
  ä½ æ˜¯ OLAV çš„ **CLI æ‰§è¡Œä»£ç†** (ä¸“æ³¨äºä¼ ç»Ÿ CLI å‘½ä»¤æ“ä½œ)ã€‚
  
  ## å¹³å°å‘½ä»¤æ˜ å°„ (æ ¹æ®è®¾å¤‡å¹³å°æ¨æ–­è¯­æ³•)
  | å¹³å° | æŸ¥çœ‹æ¥å£ | æŸ¥çœ‹ BGP | é…ç½®æ¥å£ MTU |
  |------|---------|---------|--------------|
  | cisco_ios | `show ip interface brief` | `show ip bgp summary` | `interface Gi0/0` + `mtu 9000` |
  | cisco_nxos | `show interface brief` | `show bgp ipv4 unicast summary` | `interface Eth1/1` + `mtu 9000` |
  | cisco_iosxr | `show ipv4 interface brief` | `show bgp summary` | `interface Gi0/0/0/0` + `mtu 9000` |
  | arista_eos | `show ip interface brief` | `show ip bgp summary` | `interface Ethernet1` + `mtu 9000` |
  | juniper_junos | `show interfaces terse` | `show bgp summary` | `set interfaces ge-0/0/0 mtu 9000` |
  | huawei_vrp | `display ip interface brief` | `display bgp peer` | `interface Gi0/0/0` + `mtu 9000` |
  
  ## ä½ çš„èŒè´£
  1. **æŸ¥è¯¢æ“ä½œ** (åªè¯»å‘½ä»¤)
     - ä½¿ç”¨ discover_commands æŸ¥è¯¢å¯ç”¨å‘½ä»¤
     - æ ¹æ®è®¾å¤‡å¹³å°æ¨æ–­æ­£ç¡®è¯­æ³•
     - è¾“å‡ºè‡ªåŠ¨é€šè¿‡ TextFSM è§£æä¸ºç»“æ„åŒ–æ•°æ®
  
  2. **é…ç½®æ“ä½œ** (å†™å‘½ä»¤)
     - ç”Ÿæˆé…ç½®å‘½ä»¤åºåˆ— (åŸºäºå¹³å°è¯­æ³•)
     - **å¿…é¡»äººå·¥å®¡æ‰¹** (è§¦å‘ HITL ä¸­æ–­)
     - âš ï¸ è­¦å‘Š: CLI æ¨¡å¼æ— åŸå­å›æ»š
  
  3. **æ•…éšœæ’æŸ¥**
     - è§£æå‘½ä»¤è¾“å‡ºä¸­çš„é”™è¯¯ä¿¡æ¯
     - å¼•å¯¼ç”¨æˆ·æ£€æŸ¥æƒé™ã€è¯­æ³•ã€è®¾å¤‡çŠ¶æ€
  
  ## å·¥å…·ä½¿ç”¨
  - `cli_tool(device, command, config_commands)`
    - device: è®¾å¤‡åç§° (ä» Root Agent ä¼ é€’)
    - command: æŸ¥è¯¢å‘½ä»¤ (åªè¯»)
    - config_commands: é…ç½®å‘½ä»¤åˆ—è¡¨ (å†™æ“ä½œ)
  
  - `discover_commands(platform, intent)` (å¯é€‰)
    - platform: è®¾å¤‡å¹³å° (cisco_ios, arista_eos, etc.)
    - intent: æŸ¥è¯¢æ„å›¾ ("æŸ¥çœ‹æ¥å£çŠ¶æ€", "é…ç½® BGP")
  
  ## ç¤ºä¾‹å¯¹è¯
  ç”¨æˆ·: "æ£€æŸ¥è®¾å¤‡çš„æ¥å£çŠ¶æ€"
  ä½ çš„æ‰§è¡Œ:
  1. [å¯é€‰] discover_commands(platform="cisco_ios", intent="æŸ¥çœ‹æ¥å£")
  2. è°ƒç”¨: cli_tool(device="...", command="show ip interface brief")
  3. è¿”å› TextFSM è§£æåçš„ç»“æ„åŒ–æ•°æ®
  
  ç”¨æˆ·: "ä¿®æ”¹è®¾å¤‡çš„ GigabitEthernet0/0 MTU ä¸º 9000"
  ä½ çš„æ‰§è¡Œ:
  1. æ ¹æ®å¹³å°ç”Ÿæˆå‘½ä»¤: ["interface GigabitEthernet0/0", "mtu 9000"]
  2. è°ƒç”¨: cli_tool(device="...", config_commands=["interface GigabitEthernet0/0", "mtu 9000"])
  3. âš ï¸ è§¦å‘ HITL - ç­‰å¾…ç”¨æˆ·æ‰¹å‡†
  4. æé†’ç”¨æˆ·ä¿å­˜é…ç½®
  
  ## æ³¨æ„äº‹é¡¹
  - **ç»ä¸ä½¿ç”¨ NETCONF/YANG æœ¯è¯­** (å¦‚ XPathã€RPCã€Payload)
  - **ç»ä¸å°è¯•æ„é€  XML** (è¿™æ˜¯ netconf-executor çš„èŒè´£)
  - ä¸¥æ ¼éµå®ˆå¹³å°å‘½ä»¤è¯­æ³• (å‚è€ƒä¸Šè¡¨)
  - âš ï¸ æé†’ç”¨æˆ·: CLI æ¨¡å¼æ— è‡ªåŠ¨å›æ»š - å»ºè®®å…ˆåœ¨æµ‹è¯•è®¾å¤‡éªŒè¯
```

**åŒ Agent æ¶æ„ä¼˜åŠ¿ (é”™è¯¯é©±åŠ¨é™çº§)**:

| ç»´åº¦ | é¢„å…ˆæ¢æµ‹æ¨¡å¼ | é”™è¯¯é©±åŠ¨é™çº§ | æ”¹è¿› |
|------|------------|------------|------|
| **å¹»è§‰é£é™©** | Agent éœ€è¦åŒæ—¶ç†è§£ä¸¤ç§è¯­æ³• | æ¯ä¸ª Agent åªä¸“æ³¨ä¸€ç§è¯­æ³• | **èŒè´£éš”ç¦»** |
| **è·¯ç”±å‡†ç¡®æ€§** | ç«¯å£æ¢æµ‹å¯èƒ½è¯¯åˆ¤ (é˜²ç«å¢™/è¶…æ—¶) | çœŸå®è¿æ¥å°è¯•ï¼ŒåŸºäºå®é™…é”™è¯¯ | **æ›´å¯é ** |
| **Token æ¶ˆè€—** | å• Prompt ~800 tokens | åˆ†ç¦» Prompt ~300-400 | **50-62% èŠ‚çœ** |
| **é™çº§çµæ´»æ€§** | ç¡¬ç¼–ç  if-else | LLM æ ¹æ®é”™è¯¯ä¿¡æ¯è‡ªä¸»å†³å®š | **æ™ºèƒ½é™çº§** |
| **é”™è¯¯è¯Šæ–­** | æ— æ³•åŒºåˆ†ä¸åŒå¤±è´¥åŸå›  | æ¸…æ™°é”™è¯¯ä¿¡æ¯ (è®¤è¯ vs åè®® vs ç«¯å£) | **æ›´å¥½æ’éšœ** |
| **Root Agent è´Ÿæ‹…** | éœ€è¦è®¾å¤‡æ¢æµ‹é€»è¾‘ | åªéœ€è°ƒç”¨ SubAgent + é”™è¯¯å¤„ç† | **ç®€åŒ–ç¼–æ’** |

**é¿å…å¹»è§‰çš„å…³é”®è®¾è®¡**:

1. **å·¥å…·éš”ç¦»**:
   - NETCONF Agent: ä»…èƒ½è®¿é—® `netconf_tool` (å‘é€ RPC)
   - CLI Agent: ä»…èƒ½è®¿é—® `cli_tool` + `discover_commands`
   - **ç‰©ç†éš”ç¦»** â†’ LLM æ— æ³•è°ƒç”¨é”™è¯¯å·¥å…·

2. **Prompt ä¸“æ³¨**:
   - NETCONF Prompt: å¼ºè°ƒ "ç»ä¸ä½¿ç”¨ CLI å‘½ä»¤"
   - CLI Prompt: å¼ºè°ƒ "ç»ä¸ä½¿ç”¨ NETCONF/YANG æœ¯è¯­"
   - **æ˜ç¡®ç¦æ­¢** â†’ å‡å°‘è·¨ç•Œå¹»è§‰

3. **ç¤ºä¾‹å¯¹è¯**:
   - æ¯ä¸ª Prompt åŒ…å« 2 ä¸ªå…¸å‹åœºæ™¯ï¼ˆæŸ¥è¯¢ + é…ç½®ï¼‰
   - ä½¿ç”¨å®é™…è®¾å¤‡å¹³å°çš„çœŸå®å‘½ä»¤
   - **Few-Shot Learning** â†’ å¼•å¯¼æ­£ç¡®æ¨¡å¼

**æˆæœ¬ä¼˜åŒ–ï¼ˆPrompt Cachingï¼‰**:

```python
# ä½¿ç”¨ Anthropic Prompt Caching
from langchain.agents.middleware import AnthropicPromptCachingMiddleware

agent = create_deep_agent(
    model=LLMFactory.get_chat_model(),
    middleware=[
        AnthropicPromptCachingMiddleware(
            cache_system_prompts=True,  # ç¼“å­˜ System Prompt
            cache_tools=True             # ç¼“å­˜ Tool Descriptions
        )
    ],
    ...
)
```

**ç¼“å­˜æ•ˆæœ**:
- ç¬¬ 1 æ¬¡è°ƒç”¨: 400 tokens (å†™å…¥ç¼“å­˜)
- ç¬¬ 2-N æ¬¡è°ƒç”¨: 40 tokens (è¯»å–ç¼“å­˜ï¼Œ90% æŠ˜æ‰£)
- 5 åˆ†é’Ÿç¼“å­˜çª—å£å†…é‡å¤è°ƒç”¨æ¥è¿‘å…è´¹

    
*   **NetBox SubAgent (SSOT Manager)**: è®¾å¤‡å’Œç«™ç‚¹çš„å•ä¸€çœŸç†æºç®¡ç†
    ```python
    netbox_subagent = SubAgent(
        name="netbox-manager",
        description="ç®¡ç† NetBox ä¸­çš„è®¾å¤‡å’Œç«™ç‚¹ä¿¡æ¯",
        prompt="""
        ä½ æ˜¯ç½‘ç»œèµ„äº§ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ç»´æŠ¤ NetBox ä¸­çš„è®¾å¤‡å’Œç«™ç‚¹ä¿¡æ¯ã€‚
        
        æ‰€æœ‰æ“ä½œå¿…é¡»ç¡®ä¿ä¾èµ–å…³ç³»å®Œæ•´ï¼Œå¦‚ï¼š
        - Site å¿…é¡»å­˜åœ¨
        - Manufacturer å¿…é¡»å­˜åœ¨
        """,
        tools=[
            netbox_schema_search,  # æœç´¢ API ç«¯ç‚¹
            netbox_api_call,       # æ‰§è¡Œ API è°ƒç”¨
            inventory_import,      # CSV å¯¼å…¥
            sync_configs            # åŒæ­¥é…ç½®
        ]
    )
    ```
    
*   **Learner Agent (`learner_agent.py`)**: åå¤„ç†èŠ‚ç‚¹
    - LangGraph å›¾çš„æœ€ç»ˆèŠ‚ç‚¹ï¼ˆå¯¹è¯ç»“æŸæ—¶è§¦å‘ï¼‰
    - åˆ†ææˆåŠŸè·¯å¾„å¹¶å‘é‡åŒ–å­˜å…¥ `olav-episodic-memory`
    - ä½¿ç”¨ `LLMFactory.get_embedding_model()`

**æ·±åº¦ä»£ç†åˆ›å»ºç¤ºä¾‹**:
```python
# root_agent.py
from deepagents import create_deep_agent
from langchain.agents.middleware import TodoListMiddleware

agent = create_deep_agent(
    model=LLMFactory.get_chat_model(),
    system_prompt="""ä½ æ˜¯ä¼ä¸šç½‘ç»œè¿ç»´ä¸“å®¶ OLAVã€‚
    
å·¥ä½œæµç¨‹:
1. ä½¿ç”¨ rag_agent æ£€ç´¢ Schema/Docs/Memory
2. ä½¿ç”¨ suzieq_agent è¿›è¡Œå®è§‚å†å²åˆ†æ
3. ä½¿ç”¨ netconf_agent è¿›è¡Œå®æ—¶å¾®è§‚è¯Šæ–­
4. æ‰€æœ‰ Write æ“ä½œå¿…é¡»ç­‰å¾…äººå·¥æ‰¹å‡†
""",
    subagents=[suzieq_subagent, rag_subagent, netconf_subagent],
    middleware=[
        NetworkContextMiddleware(),  # è‡ªå®šä¹‰ä¸­é—´ä»¶
    ],
    checkpointer=RedisCheckpointer(settings.REDIS_URL),
    interrupt_on={
        "nornir_tool": {"allowed_decisions": ["approve", "edit", "reject"]}
    }
).with_config({"recursion_limit": 1000})
```

**å…¸å‹å·¥ä½œæµ**:
```mermaid
graph LR
    User -->|"æŸ¥è¯¢ BGP çŠ¶æ€"| Supervisor
    Supervisor -->|"éœ€è¦å®æ—¶æ•°æ®"| Netconf
    Netconf -->|"è¯·æ±‚ Schema"| RAG[RAG Agent]
    RAG -->|"1. æŸ¥ Memory"| Memory[(Memory Index)]
    RAG -->|"2. æŸ¥ Schema"| Schema[(Schema Index)]
    RAG -->|"è¿”å› XPath"| Netconf
    Netconf -->|"æ„å»º Payload"| Sandbox
    Sandbox -->|"NETCONF RPC"| Device[Network Device]
```

---

## 5. åŸºç¡€è®¾æ–½é…ç½® (Docker Compose)

### æœåŠ¡æ¦‚è§ˆ

*   **opensearch**: å‘é‡æ•°æ®åº“,å­˜å‚¨ Schemaã€æ–‡æ¡£å’Œè®°å¿†ã€‚
*   **redis**: çŠ¶æ€å­˜å‚¨,ç”¨äº LangGraph çš„ Checkpointã€‚
*   **olav-init**: Schema åˆå§‹åŒ–å™¨ (ä¸€æ¬¡æ€§ä»»åŠ¡),è§£æ YANG æ¨¡å‹ã€‚
*   **olav-embedder**: æ–‡æ¡£å‘é‡åŒ–æœåŠ¡ (å¸¸é©»/æŒ‰éœ€),å¤„ç† PDF/MDã€‚
*   **suzieq**: å¯è§‚æµ‹æ€§å¹³å°,æä¾›å®è§‚ç½‘ç»œæ•°æ®ã€‚
*   **olav-app**: ä¸»ç¨‹åº (Agent CLI),æŒ‚è½½æºç è¿›è¡Œçƒ­é‡è½½å¼€å‘ã€‚

### docker-compose.yml é…ç½®

```yaml
version: '3.8'

services:
  # 1. å‘é‡æ•°æ®åº“ (OpenSearch)
  opensearch:
    image: opensearchproject/opensearch:latest
    environment:
      - discovery.type=single-node
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ports: ["9200:9200"]
    volumes: ["opensearch-data:/usr/share/opensearch/data"]

  # 2. å…³ç³»æ•°æ®åº“ (PostgreSQL - LangGraph Checkpointer)
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: olav
      POSTGRES_USER: olav
      POSTGRES_PASSWORD: OlavPG123!
    ports: ["5432:5432"]
    volumes: ["postgres-data:/var/lib/postgresql/data"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U olav"]
      interval: 5s
      timeout: 5s
      retries: 5

  # 3. çŠ¶æ€å­˜å‚¨ (Redis)
  redis:
    image: redis:alpine
    ports: ["6379:6379"]

  # 4. åˆå§‹åŒ–å®¹å™¨ (Run-once)
  # è´Ÿè´£åˆå§‹åŒ–æ‰€æœ‰ Schema: OpenConfig YANG + SuzieQ Avro Schema + PostgreSQL Tables
  olav-init:
    build:
      context: .
      dockerfile: Dockerfile
    command: |
      bash -c '
        echo "=== Starting Initialization Pipeline ==="
        python -m olav.etl.init_postgres &&
        python -m olav.etl.init_schema && 
        python -m olav.etl.suzieq_schema_etl &&
        echo "âœ… All schemas and tables initialized successfully"
      '
    env_file: .env
    depends_on:
      opensearch:
        condition: service_started
      postgres:
        condition: service_healthy
    profiles: ["init"] # ä»…åœ¨æ˜¾å¼è°ƒç”¨æ—¶è¿è¡Œ: docker-compose --profile init up

  # 5. æ–‡æ¡£å‘é‡åŒ–æœåŠ¡ (Service)
  # å¸¸é©»åå°,æä¾› API è§¦å‘æ–‡æ¡£é‡ç´¢å¼•
  olav-embedder:
    build:
      context: .
      dockerfile: Dockerfile.embedder
    env_file: .env
    ports: ["8001:8000"]
    volumes:
      - ./data/documents:/app/data/documents
      - ./src:/app/src
    depends_on:
      opensearch:
        condition: service_started
      postgres:
        condition: service_healthy

  # 6. å¯è§‚æµ‹æ€§ (SuzieQ)
  suzieq:
    image: netenglabs/suzieq:latest
    volumes:
      - ./data/suzieq-parquet:/suzieq/parquet
    command: sq-rest-server

  # 7. OLAV ä¸»ç¨‹åº (CLI/Agent)
  olav-app:
    build: .
    image: olav:latest
    env_file: .env
    volumes:
      - ./src:/app/src      # æºç çƒ­é‡è½½
      - ./config:/app/config
    depends_on:
      opensearch:
        condition: service_started
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      suzieq:
        condition: service_started
    # ä¿æŒè¿è¡Œ,é€šè¿‡ docker exec è¿›å…¥ CLI
    command: tail -f /dev/null

volumes:
  opensearch-data:
  postgres-data:
```

### ç¯å¢ƒå˜é‡é…ç½® (.env.example)

```bash
# LLM Configuration
LLM_PROVIDER=openai              # openai, ollama, azure
LLM_API_KEY=sk-...
LLM_MODEL_NAME=gpt-4-turbo
LLM_BASE_URL=                    # Optional for Azure/Ollama

# Infrastructure
OPENSEARCH_URL=http://opensearch:9200
POSTGRES_URI=postgresql://olav:OlavPG123!@postgres:5432/olav
REDIS_URL=redis://redis:6379
SUZIEQ_URL=http://suzieq:8000

# NetBox (Single Source of Truth)
NETBOX_URL=https://netbox.example.com
NETBOX_TOKEN=your-token-here

# Device Credentials (for Nornir/SuzieQ)
DEVICE_USERNAME=admin
DEVICE_PASSWORD=your-secure-password  # ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ Vault

# OpenConfig Schema Repository
OPENCONFIG_REPO_URL=https://github.com/openconfig/public.git
OPENCONFIG_REPO_BRANCH=master
```

---

## 6. å¿«é€Ÿå¼€å§‹ (Quick Start)

### å‰ç½®è¦æ±‚

*   Docker & Docker Compose
*   Python 3.11+ (æœ¬åœ°å¼€å‘)
*   uv (æ¨èçš„åŒ…ç®¡ç†å™¨)

### æ­¥éª¤ 1: åˆå§‹åŒ–é¡¹ç›®

```bash
# å…‹éš†ä»“åº“
git clone <repository-url> olav
cd olav

# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env
# ç¼–è¾‘ .env å¡«å…¥ä½ çš„ API Keys
```

### æ­¥éª¤ 2: å¯åŠ¨åŸºç¡€è®¾æ–½

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# åˆå§‹åŒ–æ‰€æœ‰ Schema (ä¸€æ¬¡æ€§ä»»åŠ¡)
# è¿™ä¼šæ‰§è¡Œä¸‰ä¸ªåˆå§‹åŒ–æµç¨‹ï¼š
#   1. PostgreSQL Checkpointer è¡¨ â†’ checkpoints, checkpoint_writes
#   2. OpenConfig YANG Schema â†’ openconfig-schema ç´¢å¼•
#   3. SuzieQ Avro Schema â†’ suzieq-schema ç´¢å¼•
docker-compose --profile init up olav-init

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# éªŒè¯ OpenSearch ç´¢å¼•
curl http://localhost:9200/_cat/indices?v | grep schema
# åº”è¯¥çœ‹åˆ°: openconfig-schema, suzieq-schema

# éªŒè¯ PostgreSQL Checkpointer è¡¨
docker-compose exec postgres psql -U olav -d olav -c "\dt"
# åº”è¯¥çœ‹åˆ°: checkpoints, checkpoint_writes, checkpoint_migrations

# éªŒè¯ OpenSearch ç´¢å¼•
curl http://localhost:9200/_cat/indices?v | grep schema
# åº”è¯¥çœ‹åˆ°: openconfig-schema, suzieq-schema

# éªŒè¯ PostgreSQL Checkpointer è¡¨
docker-compose exec postgres psql -U olav -d olav -c "\dt"
# åº”è¯¥çœ‹åˆ°: checkpoints, checkpoint_writes, checkpoint_migrations
```

### æ­¥éª¤ 3: é…ç½® NetBox è¿æ¥

OLAV ä½¿ç”¨ **NetBox ä½œä¸ºå”¯ä¸€çš„ Inventory æ¥æº**ï¼ˆSSOTï¼‰ï¼Œæ— éœ€ç»´æŠ¤é™æ€é…ç½®æ–‡ä»¶ã€‚

```bash
# 1. é…ç½®ç¯å¢ƒå˜é‡ï¼ˆ.env æ–‡ä»¶ï¼‰
cat > .env <<EOF
# NetBox SSOT Configuration
NETBOX_URL=https://netbox.example.com
NETBOX_TOKEN=your_netbox_api_token_here

# Device Credentials (å¯é€‰ï¼Œå¦‚æœ NetBox æœªå­˜å‚¨)
DEVICE_USERNAME=admin
DEVICE_PASSWORD=secure_password
EOF

# 2. å¯åŠ¨ olav-init å®¹å™¨ï¼ˆè‡ªåŠ¨ç”Ÿæˆ SuzieQ é…ç½®ï¼‰
docker-compose --profile init up olav-init

# 3. éªŒè¯é…ç½®ç”Ÿæˆ
cat data/generated_configs/suzieq_config.yml
# åº”è¯¥çœ‹åˆ°ä» .env è¯»å–çš„ NETBOX_URL å’Œ NETBOX_TOKEN

# 4. é‡å¯ SuzieQ ä»¥åŠ è½½ç”Ÿæˆçš„é…ç½®
docker-compose restart suzieq

# 5. éªŒè¯è®¾å¤‡åŒæ­¥
docker exec -it suzieq sq device show
```

**è¯´æ˜**: 
- **Nornir**: ä½¿ç”¨ä»£ç ä¸­çš„ `InitNornir()` åŠ¨æ€é…ç½®ï¼Œæ— éœ€ YAML æ–‡ä»¶
- **SuzieQ**: é…ç½®ç”± `generate_configs.py` åœ¨åˆå§‹åŒ–æ—¶ç”Ÿæˆåˆ° `data/generated_configs/`
- **å‡­æ®ç®¡ç†**: æ‰€æœ‰æ•æ„Ÿä¿¡æ¯ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œç¬¦åˆ 12-Factor App åŸåˆ™

### æ­¥éª¤ 4: è¿›å…¥ OLAV CLI

```bash
# è¿›å…¥ä¸»å®¹å™¨
docker exec -it olav-app bash

# å¯åŠ¨äº¤äº’å¼ CLI
python -m olav.main chat
```

### æ­¥éª¤ 5: ä¸Šä¼ æ–‡æ¡£ (å¯é€‰)

```bash
# å°† PDF æ–‡æ¡£æ”¾å…¥ data/documents/
cp your-manual.pdf data/documents/

# è§¦å‘å‘é‡åŒ–æœåŠ¡
curl -X POST http://localhost:8001/ingest
```

### å¼€å‘æ¨¡å¼

```bash
# æœ¬åœ°è¿è¡Œ (ä¸ä½¿ç”¨ Docker)
uv sync
uv run python -m olav.main chat

# è¿è¡Œæµ‹è¯•
uv run pytest

# ä»£ç æ£€æŸ¥
uv run ruff check .
```

---

## 7. é¡¹ç›®è„šæ‰‹æ¶ç”Ÿæˆ (Scaffolding)

ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å¿«é€Ÿç”Ÿæˆå®Œæ•´çš„ç›®å½•ç»“æ„:

```bash
#!/bin/bash
# init_olav.sh

PROJECT="olav"
echo "ğŸ—ï¸  Scaffolding Project OLAV..."

# 1. åˆ›å»ºæ ¹ç›®å½•æ–‡ä»¶
mkdir -p $PROJECT
cd $PROJECT
touch .env.example .gitignore uv.lock pyproject.toml docker-compose.yml Dockerfile Dockerfile.embedder Makefile README.md

# 2. åˆ›å»º Archive å’Œ Data
mkdir -p archive
touch archive/.gitkeep
mkdir -p data/{documents,suzieq-parquet}

# 3. åˆ›å»º Config
mkdir -p config/prompts/{agents,tools}
touch config/inventory_template.csv
touch config/app_settings.template.yaml

# 4. åˆ›å»º SRC æ ¸å¿ƒç»“æ„
SRC="src/olav"
mkdir -p $SRC/{core,agents,tools,execution,etl}
touch $SRC/__init__.py
touch $SRC/main.py

# Core
touch $SRC/core/{__init__.py,settings.py,state.py,llm.py,memory.py,prompt_manager.py,inventory_manager.py}

# Agents
mkdir -p $SRC/agents/middleware
touch $SRC/agents/{__init__.py,root_agent.py,suzieq_agent.py,netconf_agent.py,rag_agent.py,learner_agent.py}
touch $SRC/agents/middleware/{__init__.py,network_context.py}

# Tools
touch $SRC/tools/{__init__.py,opensearch_tool.py,suzieq_tool.py,nornir_tool.py,netbox_tool.py,datetime_tool.py}

# Execution
mkdir -p $SRC/execution/backends
touch $SRC/execution/__init__.py
touch $SRC/execution/backends/{__init__.py,protocol.py,nornir_sandbox.py,state.py,redis.py}

# ETL
touch $SRC/etl/{__init__.py,init_postgres.py,init_schema.py,suzieq_schema_etl.py,netbox_schema_etl.py,generate_configs.py}

# 5. åˆ›å»º Embedder æœåŠ¡
SVC="src/embedder"
mkdir -p $SVC
touch $SVC/{__init__.py,main.py,loader.py,vectorizer.py}

# 6. åˆ›å»º Tests
mkdir -p tests/{unit,e2e}
touch tests/{__init__.py,conftest.py}
touch tests/unit/{test_agents.py,test_sandbox.py,test_llm_factory.py}
touch tests/e2e/test_workflow.py

echo "âœ… OLAV structure created successfully in ./$PROJECT"
```

è¿è¡Œè„šæœ¬:

```bash
chmod +x init_olav.sh
./init_olav.sh
```

---



### å½“å‰è¿›åº¦ï¼ˆ2025-11-23ï¼‰
- Deep Dive Workflow é€’å½’ä¸å¹¶è¡Œæ‰¹é‡æ‰§è¡Œå·²å®ç°å¹¶é€šè¿‡å…¨éƒ¨æµ‹è¯•
- ç›¸å…³æ–‡æ¡£ä¸ TODO å·²åŒæ­¥æ›´æ–°
- ä¸‹ä¸€æ­¥ï¼šå¤šå¤±è´¥é€’å½’å¢å¼ºã€Checkpointer æ¢å¤æµ‹è¯•ã€æ€§èƒ½è°ƒä¼˜

### å½“å‰è¿›åº¦ï¼ˆ2025-11-23ï¼‰
- Deep Dive Workflow é€’å½’ä¸å¹¶è¡Œæ‰¹é‡æ‰§è¡Œå·²å®ç°å¹¶é€šè¿‡å…¨éƒ¨æµ‹è¯•
- ç›¸å…³æ–‡æ¡£ä¸ TODO å·²åŒæ­¥æ›´æ–°
- ä¸‹ä¸€æ­¥ï¼šå¤šå¤±è´¥é€’å½’å¢å¼ºã€Checkpointer æ¢å¤æµ‹è¯•ã€æ€§èƒ½è°ƒä¼˜

### Phase 1: åŸºç¡€å»ºè®¾ (Day 1-3)
*   **ç›®æ ‡**: è·‘é€š `docker-compose`ï¼Œæ‰€æœ‰æœåŠ¡æ˜¾ç¤º Healthyã€‚
*   **ä»»åŠ¡**:
    *   ç¼–å†™ Dockerfile å’Œ `docker-compose.yml`ã€‚
    *   å®ç° `src/config/settings.py`ã€‚
    *   å®ç° `olav-init`ï¼Œæ‹‰å– OpenConfig å¹¶å­˜å…¥ OpenSearchã€‚

### Phase 2: æ ¸å¿ƒ Agent ä¸å·¥å…· (Day 4-7)
*   **ç›®æ ‡**: Agent å¯ä»¥è°ƒç”¨å·¥å…·æŸ¥è¯¢æ•°æ®ã€‚
*   **ä»»åŠ¡**:
    *   å®ç° `src/olav/core/llm.py` (LLM Factory)ã€‚
    *   å°è£… `opensearch_tool.py` å’Œ `netbox_tool.py`ã€‚
    *   å®ç° `src/olav/agents/rag_agent.py` - ç»Ÿä¸€çŸ¥è¯†æ£€ç´¢å…¥å£ã€‚
    *   ç¼–å†™ `src/olav/agents/root_agent.py` å®ç°åŸºç¡€è·¯ç”±ã€‚

### Phase 3: æ‰§è¡Œå±‚ä¸å®‰å…¨æ€§ (Day 8-10)
*   **ç›®æ ‡**: å®ç° Nornir è°ƒç”¨å’Œ HITLã€‚
*   **ä»»åŠ¡**:
    *   å®ç° `src/olav/execution/sandbox.py`ã€‚
    *   é›†æˆ Rich CLIï¼Œå®ç°æ¼‚äº®çš„ Spinner å’Œ Confirm Promptã€‚
    *   Test: ç¼–å†™ `tests/unit/test_sandbox.py` ç¡®ä¿å®¡æ‰¹é€»è¾‘ç”Ÿæ•ˆã€‚

### Phase 4: è¿›é˜¶èƒ½åŠ› (Day 11-14)
*   **ç›®æ ‡**: è‡ªæˆ‘å­¦ä¹ ä¸æ–‡æ¡£æ£€ç´¢ã€‚
*   **ä»»åŠ¡**:
    *   å®ç° `olav-embedder` æœåŠ¡ï¼Œæ”¯æŒ PDF ä¸Šä¼ ã€‚
    *   å®ç° LangGraph ä¸­çš„ `learner_agent.py` èŠ‚ç‚¹ã€‚
    *   å®Œå–„ `rag_agent.py` çš„ä¸‰å±‚æ£€ç´¢é€»è¾‘ï¼ˆMemory -> Schema -> Docsï¼‰ã€‚
    *   å®ç° RAG Agent çš„ç¼“å­˜æœºåˆ¶ï¼Œæå‡æ£€ç´¢æ€§èƒ½ã€‚
    *   Deep Dive Workflow é€’å½’ä¸å¹¶è¡Œæ‰¹é‡æ‰§è¡Œï¼ˆå·²å®ç°ï¼Œè¯¦è§ç›¸å…³æµ‹è¯•ä¸ä»£ç æ³¨é‡Šï¼‰

### Phase 5: æµ‹è¯•ä¸å‘å¸ƒ
*   **ä»»åŠ¡**:
    *   è¿è¡Œ E2E æµ‹è¯•ã€‚
    *   ç¼–å†™ä½¿ç”¨æ‰‹å†Œã€‚
    *   Deep Dive Workflow å¹¶è¡Œ/é€’å½’æµ‹è¯•å·²å…¨éƒ¨é€šè¿‡ï¼ˆè¯¦è§ tests/unit/test_deep_dive_workflow.pyï¼‰

---

## 9. é…ç½®ç®¡ç† (Configuration)

### settings.py (config/settings.py)

ä½¿ç”¨ Pydantic Settings åŠ è½½ `.env`:

```python
from pydantic_settings import BaseSettings
from typing import Literal, Optional

class Settings(BaseSettings):
    # LLM é…ç½®
    LLM_PROVIDER: Literal["openai", "ollama", "azure"] = "openai"
    LLM_API_KEY: str
    LLM_MODEL_NAME: str = "gpt-4-turbo"
    LLM_BASE_URL: Optional[str] = None

    # åŸºç¡€è®¾æ–½
    OPENSEARCH_URL: str = "http://opensearch:9200"
    REDIS_URL: str = "redis://redis:6379"
    SUZIEQ_URL: str = "http://suzieq:8000"
    
    # NetBox (Single Source of Truth)
    NETBOX_URL: str
    NETBOX_TOKEN: str
    
    # è®¾å¤‡è®¤è¯
    DEVICE_USERNAME: str = "admin"
    DEVICE_PASSWORD: str
    
    # OpenConfig Schema ä»“åº“
    OPENCONFIG_REPO_URL: str = "https://github.com/openconfig/public.git"
    OPENCONFIG_REPO_BRANCH: str = "master"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()
```

**æ³¨æ„**: Nornir å’Œ SuzieQ çš„é…ç½®ç°åœ¨é€šè¿‡**ä»£ç åŠ¨æ€ç”Ÿæˆ**æˆ–**å†…åµŒé…ç½®å­—å…¸**å®ç°ï¼Œä¸å†ä¾èµ–é™æ€ YAML æ–‡ä»¶ã€‚è¯¦è§ä¸‹æ–‡ã€‚

---

## 11. Inventory ç®¡ç† (NetBox Integration)

### NetBox ä½œä¸ºå•ä¸€ä¿¡ä»»æº

OLAV ä½¿ç”¨ NetBox ä½œä¸ºå”¯ä¸€çš„è®¾å¤‡æ¸…å•æ¥æºï¼Œé¿å…é…ç½®æ¼‚ç§»ã€‚SuzieQ å’Œ Nornir éƒ½é€šè¿‡å„è‡ªçš„é…ç½®æ–‡ä»¶ç›´æ¥ä» NetBox åŒæ­¥è®¾å¤‡ã€‚

### Nornir NetBox é…ç½®

### Nornir åŠ¨æ€é…ç½® (æ— é™æ€æ–‡ä»¶)

**å½“å‰å®ç°**: Nornir é€šè¿‡ä»£ç ç›´æ¥åˆå§‹åŒ–ï¼Œæ— éœ€ `nornir_config.yml`ï¼š

```python
# src/olav/execution/backends/nornir_sandbox.py
from nornir import InitNornir
from olav.core.settings import settings

nr = InitNornir(
    runner={
        "plugin": "threaded",
        "options": {"num_workers": 100},
    },
    inventory={
        "plugin": "NetBoxInventory2",
        "options": {
            "url": settings.netbox_url,
            "token": settings.netbox_token,
            "ssl_verify": False,
        },
    },
)

if __name__ == "__main__":
    print(f"âœ… Loaded {len(nr.inventory.hosts)} hosts from NetBox")
    for hostname, host in nr.inventory.hosts.items():
        print(f"  - {hostname}: {host.platform}")
```

**ä¼˜åŠ¿**: é…ç½®é›†ä¸­åœ¨ `settings.py`ï¼Œæ— é™æ€æ–‡ä»¶ç»´æŠ¤è´Ÿæ‹…ï¼Œç¬¦åˆ 12-Factor App åŸåˆ™ã€‚

### SuzieQ åŠ¨æ€é…ç½®

**å½“å‰å®ç°**: `olav-init` å®¹å™¨å¯åŠ¨æ—¶åŠ¨æ€ç”Ÿæˆé…ç½®åˆ° `data/generated_configs/suzieq_config.yml`ï¼š

```python
# src/olav/etl/generate_configs.py
import os
import yaml
from olav.core.settings import settings

config_dir = "data/generated_configs"
os.makedirs(config_dir, exist_ok=True)

suzieq_config = {
    "sources": [{
        "name": "netbox",
        "type": "netbox",
        "url": settings.netbox_url,
        "token": settings.netbox_token,
        "tag": "suzieq"
    }]
}

with open(f"{config_dir}/suzieq_config.yml", "w") as f:
    yaml.dump(suzieq_config, f)
```

åœ¨ `docker-compose.yml` ä¸­æŒ‚è½½ç”Ÿæˆçš„é…ç½®ï¼š

```yaml
suzieq:
  image: netenglabs/suzieq:latest
  volumes:
    - ./data/suzieq-parquet:/suzieq/parquet
    - ./data/generated_configs:/suzieq/config:ro
  depends_on:
    olav-init:
      condition: service_completed_successfully
```

**ä¼˜åŠ¿**: é…ç½®ç”± ETL ç®¡é“è‡ªåŠ¨ç”Ÿæˆï¼Œæ¶ˆé™¤æ‰‹å·¥ç»´æŠ¤å’Œç¯å¢ƒå˜é‡æ›¿æ¢çš„å¤æ‚æ€§ã€‚

### CSV æ‰¹é‡å¯¼å…¥è®¾å¤‡

ä½¿ç”¨ `InventoryManager` å°† CSV è®¾å¤‡æ¸…å•å¯¼å…¥ NetBoxï¼š

```python
# ç¤ºä¾‹ä½¿ç”¨
from olav.core.inventory_manager import InventoryManager

manager = InventoryManager()
with open("config/inventory_template.csv") as f:
    csv_content = f.read()

results = manager.import_from_csv(csv_content)
print(f"âœ… æˆåŠŸ: {results['success']}, âŒ å¤±è´¥: {results['failed']}")
```

å¯¼å…¥åï¼ŒNornir å’Œ SuzieQ è‡ªåŠ¨ä» NetBox åŒæ­¥æ–°è®¾å¤‡ï¼Œæ— éœ€æ‰‹åŠ¨æ›´æ–°é…ç½®æ–‡ä»¶ã€‚

---

## 12. æ ¸å¿ƒå·¥å…·å®ç°

### datetime_tool.py - æ—¶é—´è§£æå·¥å…·
    period: 60
    
    # ä¼ è¾“åè®®
    transport: ssh
    
    # è®¾å¤‡è®¤è¯ï¼ˆä» NetBox Custom Fields è¯»å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    username: "${DEVICE_USERNAME}"
    password: "${DEVICE_PASSWORD}"
```

#### SuzieQ å¯åŠ¨é…ç½®

åœ¨ `docker-compose.yml` ä¸­æŒ‚è½½ç”Ÿæˆçš„é…ç½®ï¼š

```yaml
suzieq:
  image: netenglabs/suzieq:latest
  volumes:
    - ./data/suzieq-parquet:/suzieq/parquet
    - ./data/generated_configs:/suzieq/config:ro
  depends_on:
    olav-init:
      condition: service_completed_successfully
```

**ä¼˜åŠ¿**: é…ç½®ç”± ETL ç®¡é“è‡ªåŠ¨ç”Ÿæˆï¼Œæ¶ˆé™¤æ‰‹å·¥ç»´æŠ¤å’Œç¯å¢ƒå˜é‡æ›¿æ¢çš„å¤æ‚æ€§ã€‚

### CSV æ‰¹é‡å¯¼å…¥è®¾å¤‡

ä½¿ç”¨ `InventoryManager` å°† CSV è®¾å¤‡æ¸…å•å¯¼å…¥ NetBoxï¼š

```python
# ç¤ºä¾‹ä½¿ç”¨
from olav.core.inventory_manager import InventoryManager

manager = InventoryManager()
with open("config/inventory_template.csv") as f:
    csv_content = f.read()

results = manager.import_from_csv(csv_content)
print(f"âœ… æˆåŠŸ: {results['success']}, âŒ å¤±è´¥: {results['failed']}")
```

å¯¼å…¥åï¼ŒNornir å’Œ SuzieQ è‡ªåŠ¨ä» NetBox åŒæ­¥æ–°è®¾å¤‡ï¼Œæ— éœ€æ‰‹åŠ¨æ›´æ–°é…ç½®æ–‡ä»¶ã€‚

---

## 12. æ ¸å¿ƒå·¥å…·å®ç°

### datetime_tool.py - æ—¶é—´è§£æå·¥å…·

```python
# src/olav/tools/datetime_tool.py
from datetime import datetime, timedelta
from typing import Tuple
from langchain.tools import tool

@tool
def parse_time_range(natural_text: str, timezone: str = "UTC") -> Tuple[str, str]:
    """
    å°†è‡ªç„¶è¯­è¨€æ—¶é—´æè¿°è½¬æ¢ä¸ºæ—¶é—´æˆ³èŒƒå›´
    
    Args:
        natural_text: è‡ªç„¶è¯­è¨€æ—¶é—´æè¿°ï¼Œå¦‚ "æ˜¨æ™š", "è¿‡å»2å°æ—¶", "ä¸Šå‘¨äº”"
        timezone: æ—¶åŒºï¼Œé»˜è®¤ UTC
    
    Returns:
        (start_time, end_time) ISO 8601 æ ¼å¼å­—ç¬¦ä¸²
    
    Examples:
        >>> parse_time_range("æ˜¨æ™š")
        ('2025-11-20T18:00:00Z', '2025-11-21T06:00:00Z')
    """
    now = datetime.now()
    
    if "æ˜¨æ™š" in natural_text or "last night" in natural_text.lower():
        start = (now - timedelta(days=1)).replace(hour=18, minute=0, second=0)
        end = now.replace(hour=6, minute=0, second=0)
    elif "è¿‡å»" in natural_text and "å°æ—¶" in natural_text:
        hours = int(''.join(filter(str.isdigit, natural_text)))
        start = now - timedelta(hours=hours)
        end = now
    elif "ä¸Šå‘¨" in natural_text:
        start = now - timedelta(days=7)
        end = now - timedelta(days=1)
    else:
        # é»˜è®¤è¿‡å»24å°æ—¶
        start = now - timedelta(days=1)
        end = now
    
    return start.isoformat() + 'Z', end.isoformat() + 'Z'
```

### suzieq_tool.py - Schema-Aware è®¾è®¡ï¼ˆé¿å…ç»´æŠ¤å¤§é‡å·¥å…·ï¼‰

**è®¾è®¡åŸåˆ™**: ä¸ä¸ºæ¯ä¸ªèµ„æºç±»å‹åˆ›å»ºç‹¬ç«‹å·¥å…·ï¼Œè€Œæ˜¯è®© LLM é€šè¿‡ **SuzieQ Schema ç´¢å¼•** åŠ¨æ€æŸ¥è¯¢å¯ç”¨çš„è¡¨å’Œå­—æ®µã€‚

**æ¶æ„**:
1. **Schema ç´¢å¼•åŒ–**: å°† SuzieQ çš„æ‰€æœ‰ `.avsc` Schema æ–‡ä»¶è§£æå¹¶å­˜å…¥ OpenSearch `suzieq-schema` ç´¢å¼•
2. **å•ä¸€æŸ¥è¯¢å·¥å…·**: æä¾›ä¸€ä¸ªé€šç”¨çš„ `suzieq_query` å·¥å…·ï¼Œæ¥å— `table_name`, `method`, `filters` å‚æ•°
3. **Schema æ£€ç´¢å·¥å…·**: æä¾› `suzieq_schema_search` å·¥å…·ï¼Œè®© LLM æŸ¥è¯¢å“ªäº›è¡¨/å­—æ®µå¯ç”¨

```python
# src/olav/tools/suzieq_tool.py
from suzieq.sqobjects import get_sqobject, get_tables
from suzieq.shared.context import SqContext
from suzieq.shared.schema import Schema
from suzieq.shared.utils import load_sq_config
from langchain.tools import tool
import pandas as pd
from typing import List, Dict, Literal

class SuzieQSchemaAwareTool:
    """Schema-Aware SuzieQ å·¥å…·ï¼Œé¿å…ä¸ºæ¯ä¸ªèµ„æºåˆ›å»ºç‹¬ç«‹å·¥å…·"""
    
    def __init__(self, config_file: str = None):
        # åˆå§‹åŒ– SuzieQ Context
        cfg = load_sq_config(validate=True, config_file=config_file)
        self.ctxt = SqContext(cfg=cfg, engine='pandas')
        
        # åŠ è½½ Schemaï¼ˆç”¨äºå…ƒæ•°æ®æŸ¥è¯¢ï¼‰
        self.schema = Schema(cfg['schema-directory'])
    
    @tool
    def suzieq_query(
        self,
        table: str,
        method: Literal['get', 'summarize', 'unique', 'aver'] = 'get',
        **filters
    ) -> pd.DataFrame:
        """
        é€šç”¨ SuzieQ æŸ¥è¯¢å·¥å…·ï¼ˆSchema-Awareï¼‰
        
        ä½¿ç”¨å‰å»ºè®®å…ˆè°ƒç”¨ suzieq_schema_search æŸ¥è¯¢å¯ç”¨çš„è¡¨å’Œå­—æ®µã€‚
        
        Args:
            table: è¡¨åï¼Œå¦‚ 'interfaces', 'bgp', 'routes' ç­‰
                  å¯ç”¨è¡¨åˆ—è¡¨ï¼šé€šè¿‡ suzieq_schema_search(query='list all tables') è·å–
            method: æŸ¥è¯¢æ–¹æ³•
                - 'get': è·å–åŸå§‹æ•°æ®ï¼ˆæ”¯æŒæ—¶é—´èŒƒå›´ã€è¿‡æ»¤å™¨ï¼‰
                - 'summarize': èšåˆç»Ÿè®¡
                - 'unique': å»é‡æŸ¥è¯¢
                - 'aver': å¹³å‡å€¼ç»Ÿè®¡
            **filters: è¿‡æ»¤æ¡ä»¶ï¼Œå¸¸ç”¨å‚æ•°ï¼š
                - hostname: è®¾å¤‡åï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
                - namespace: å‘½åç©ºé—´åˆ—è¡¨
                - start_time: å¼€å§‹æ—¶é—´ï¼ˆISO 8601ï¼‰
                - end_time: ç»“æŸæ—¶é—´ï¼ˆISO 8601ï¼‰
                - columns: è¿”å›å­—æ®µåˆ—è¡¨ï¼ˆ['default'] æˆ– ['all'] æˆ–å…·ä½“å­—æ®µåï¼‰
                - view: 'latest'ï¼ˆæœ€æ–°ï¼‰/ 'all'ï¼ˆæ—¶é—´åºåˆ—ï¼‰/ 'changes'ï¼ˆå˜åŒ–è®°å½•ï¼‰
                - å…¶ä»–è¡¨ç‰¹å®šå­—æ®µï¼ˆå¦‚ state, vrf, peer ç­‰ï¼‰
        
        Returns:
            Pandas DataFrame
        
        Examples:
            # æŸ¥è¯¢æ¥å£çŠ¶æ€
            >>> suzieq_query(
                    table='interfaces',
                    method='get',
                    hostname='R1',
                    state='down',
                    columns=['ifname', 'state', 'reason']
                )
            
            # æŸ¥è¯¢ BGP ä¼šè¯æ‘˜è¦
            >>> suzieq_query(table='bgp', method='summarize', namespace=['prod'])
            
            # æŸ¥è¯¢å”¯ä¸€è·¯ç”±å‰ç¼€
            >>> suzieq_query(table='routes', method='unique', columns=['prefix'])
        """
        # åŠ¨æ€è·å– SqObject
        sq_obj = get_sqobject(table)(context=self.ctxt)
        
        # è°ƒç”¨å¯¹åº”æ–¹æ³•
        if method == 'get':
            return sq_obj.get(**filters)
        elif method == 'summarize':
            return sq_obj.summarize(**filters)
        elif method == 'unique':
            return sq_obj.unique(**filters)
        elif method == 'aver':
            return sq_obj.aver(**filters)
        else:
            raise ValueError(f"Unsupported method: {method}")
    
    @tool
    def suzieq_schema_search(self, query: str) -> Dict:
        """
        æŸ¥è¯¢ SuzieQ Schema ä¿¡æ¯ï¼ˆæ£€ç´¢å¯ç”¨çš„è¡¨å’Œå­—æ®µï¼‰
        
        è¿™æ˜¯ä¸€ä¸ª Schema-Aware å·¥å…·ï¼Œç”¨äºæŸ¥è¯¢ï¼š
        - å“ªäº›è¡¨ï¼ˆtableï¼‰å¯ç”¨ï¼Ÿ
        - æŸä¸ªè¡¨æœ‰å“ªäº›å­—æ®µï¼ˆfieldsï¼‰ï¼Ÿ
        - æŸä¸ªå­—æ®µçš„ç±»å‹å’Œæè¿°æ˜¯ä»€ä¹ˆï¼Ÿ
        
        Args:
            query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œä¾‹å¦‚ï¼š
                - "list all tables"
                - "show fields for interfaces table"
                - "what fields are available for bgp table"
                - "show key fields for routes table"
        
        Returns:
            Dict with schema information
        
        Examples:
            >>> suzieq_schema_search("list all tables")
            {
                "tables": ["interfaces", "bgp", "routes", "ospf", ...],
                "total": 30
            }
            
            >>> suzieq_schema_search("show fields for interfaces table")
            {
                "table": "interfaces",
                "fields": [
                    {"name": "ifname", "type": "string", "description": "...", "key": 3},
                    {"name": "state", "type": "string", "description": "..."},
                    ...
                ],
                "key_fields": ["namespace", "hostname", "ifname"],
                "display_fields": ["namespace", "hostname", "ifname", "state", "type"]
            }
        """
        # è§£æ query æ„å›¾
        query_lower = query.lower()
        
        if 'list' in query_lower and 'table' in query_lower:
            # è¿”å›æ‰€æœ‰è¡¨
            tables = self.schema.tables()
            return {
                "tables": sorted(tables),
                "total": len(tables),
                "note": "Use 'suzieq_query(table=TABLE_NAME, ...)' to query these tables"
            }
        
        # æå–è¡¨å
        for table in self.schema.tables():
            if table in query_lower:
                # è¿”å›è¡¨çš„å­—æ®µä¿¡æ¯
                fields = self.schema.get_raw_schema(table)
                key_fields = self.schema.key_fields_for_table(table)
                display_fields = self.schema.sorted_display_fields_for_table(table)
                
                return {
                    "table": table,
                    "fields": [
                        {
                            "name": f['name'],
                            "type": self._simplify_type(f['type']),
                            "description": f.get('description', ''),
                            "key": f.get('key'),
                            "display": f.get('display')
                        }
                        for f in fields
                        if not f.get('suppress', False)
                    ],
                    "key_fields": key_fields,
                    "display_fields": display_fields,
                    "note": f"Key fields identify unique records. Display fields are shown by default."
                }
        
        # é»˜è®¤è¿”å›è¡¨åˆ—è¡¨
        return {
            "error": "Could not parse query. Try 'list all tables' or 'show fields for TABLE_NAME table'",
            "available_tables": self.schema.tables()[:10]  # å‰10ä¸ªä½œä¸ºæç¤º
        }
    
    def _simplify_type(self, type_def):
        """ç®€åŒ–å¤æ‚ç±»å‹å®šä¹‰ä¸ºå­—ç¬¦ä¸²"""
        if isinstance(type_def, str):
            return type_def
        elif isinstance(type_def, dict):
            if type_def.get('type') == 'array':
                item_type = type_def.get('items', {}).get('type', 'unknown')
                return f"array<{item_type}>"
            return type_def.get('type', 'complex')
        return 'unknown'
```

**æ ¸å¿ƒä¼˜åŠ¿**:
1. **é›¶å·¥å…·ç»´æŠ¤**: ä¸éœ€è¦ä¸ºæ¯ä¸ªèµ„æºï¼ˆinterface/bgp/routeï¼‰åˆ›å»ºå·¥å…·
2. **è‡ªæè¿°**: LLM å¯ä»¥åŠ¨æ€æŸ¥è¯¢å¯ç”¨çš„è¡¨å’Œå­—æ®µ
3. **çµæ´»æ€§**: æ–°å¢ SuzieQ è¡¨æ—¶è‡ªåŠ¨æ”¯æŒï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
4. **åªè¯»å®‰å…¨**: SuzieQ åªæŸ¥è¯¢ Parquet å†å²æ•°æ®ï¼Œ**æ— å‰¯ä½œç”¨ï¼Œä¸éœ€è¦æ²™ç›’éš”ç¦»**

**ä¸ Nornir çš„å¯¹æ¯”**:
| ç»´åº¦ | SuzieQ (Macro Agent) | Nornir (Micro Agent) |
|------|---------------------|---------------------|
| **æ“ä½œç±»å‹** | åªè¯»æŸ¥è¯¢ï¼ˆParquet æ•°æ®ï¼‰ | è¯»å†™æ“ä½œï¼ˆNETCONF/gNMIï¼‰ |
| **æ˜¯å¦éœ€è¦æ²™ç›’** | âŒ å¦ï¼ˆæ— å‰¯ä½œç”¨ï¼‰ | âœ… æ˜¯ï¼ˆNornirSandbox + HITLï¼‰ |
| **Schema æ¥æº** | Avro Schema (.avsc) | YANG Models |
| **æŸ¥è¯¢æ–¹å¼** | `suzieq_query(table, method, filters)` | `nornir_tool(device, xpath, operation)` |
| **å®‰å…¨é£é™©** | æ— é£é™©ï¼ˆåªè¯»ï¼‰ | é«˜é£é™©ï¼ˆå¯ä¿®æ”¹è®¾å¤‡é…ç½®ï¼‰ |

---

## 13. ETL æµç¨‹è¯¦è§£ (åˆå§‹åŒ–æµç¨‹)

**ç»Ÿä¸€åˆå§‹åŒ–å®¹å™¨**: `olav-init` å®¹å™¨åœ¨å¯åŠ¨æ—¶ä¾æ¬¡æ‰§è¡Œä¸‰ä¸ªåˆå§‹åŒ–æµç¨‹ï¼š

1. **PostgreSQL åˆå§‹åŒ–** (`init_postgres.py`): åˆ›å»º Checkpointer è¡¨ç»“æ„
2. **OpenConfig Schema ETL** (`init_schema.py`): è§£æ YANG æ¨¡å‹ â†’ `openconfig-schema` ç´¢å¼•
3. **SuzieQ Schema ETL** (`suzieq_schema_etl.py`): è§£æ Avro Schema â†’ `suzieq-schema` ç´¢å¼•

### PostgreSQL Checkpointer åˆå§‹åŒ– (init_postgres.py)

**åŠŸèƒ½**: åˆ›å»º LangGraph Checkpointer æ‰€éœ€çš„è¡¨ç»“æ„ã€‚

```python
# src/olav/etl/init_postgres.py
from langgraph.checkpoint.postgres import PostgresSaver
import os
import logging

logger = logging.getLogger(__name__)

def init_postgres_checkpointer():
    """åˆå§‹åŒ– PostgreSQL Checkpointer è¡¨ç»“æ„"""
    postgres_uri = os.getenv(
        "POSTGRES_URI",
        "postgresql://olav:OlavPG123!@postgres:5432/olav"
    )
    
    logger.info(f"Initializing PostgreSQL Checkpointer: {postgres_uri}")
    
    with PostgresSaver.from_conn_string(postgres_uri) as checkpointer:
        checkpointer.setup()
        logger.info("âœ… Checkpointer tables created successfully")
        logger.info("   - checkpoints")
        logger.info("   - checkpoint_writes")
        logger.info("   - checkpoint_migrations")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    init_postgres_checkpointer()
```

**åˆ›å»ºçš„è¡¨**:
- `checkpoints`: å­˜å‚¨ Agent State å¿«ç…§
- `checkpoint_writes`: å­˜å‚¨å¾…å†™å…¥çš„ State æ›´æ–°
- `checkpoint_migrations`: è·Ÿè¸ª Schema ç‰ˆæœ¬

### SuzieQ Schema ç´¢å¼•åŒ– (suzieq_schema_etl.py)

**èŒè´£**: å°† SuzieQ çš„æ‰€æœ‰ Schema å®šä¹‰è§£æå¹¶å­˜å…¥ OpenSearchï¼Œä¾› LLM åŠ¨æ€æŸ¥è¯¢ã€‚

```python
# src/olav/etl/suzieq_schema_etl.py
import json
from pathlib import Path
from suzieq.shared.schema import Schema
from suzieq.shared.utils import load_sq_config
from olav.tools.opensearch_tool import OpenSearchTool

def index_suzieq_schemas():
    """
    å°† SuzieQ Schema ç´¢å¼•åŒ–åˆ° OpenSearch
    
    åˆ›å»ºç´¢å¼•: suzieq-schema
    æ–‡æ¡£ç»“æ„:
    {
        "table": "interfaces",
        "fields": [
            {
                "name": "ifname",
                "type": "string",
                "description": "Interface name",
                "key": 3,
                "display": 3
            },
            ...
        ],
        "key_fields": ["namespace", "hostname", "ifname"],
        "display_fields": ["namespace", "hostname", "ifname", "state", "type"],
        "table_type": "record"  # counter/record/derived
    }
    """
    print("=== Starting SuzieQ Schema ETL ===")
    
    # 1. åŠ è½½ SuzieQ Schema
    cfg = load_sq_config(validate=True)
    schema = Schema(cfg['schema-directory'])
    
    # 2. è§£ææ‰€æœ‰è¡¨çš„ Schema
    documents = []
    for table in schema.tables():
        raw_schema = schema.get_raw_schema(table)
        
        # æå–å­—æ®µä¿¡æ¯
        fields = []
        for field in raw_schema:
            if field.get('suppress', False):
                continue  # è·³è¿‡å†…éƒ¨å­—æ®µ
            
            fields.append({
                "name": field['name'],
                "type": _simplify_type(field['type']),
                "description": field.get('description', ''),
                "key": field.get('key'),
                "display": field.get('display'),
                "partition": field.get('partition')
            })
        
        # æ„å»ºæ–‡æ¡£
        doc = {
            "table": table,
            "fields": fields,
            "key_fields": schema.key_fields_for_table(table),
            "display_fields": schema.sorted_display_fields_for_table(table),
            "table_type": schema.type_for_table(table),
            "field_count": len(fields)
        }
        documents.append(doc)
    
    # 3. å†™å…¥ OpenSearch
    os_tool = OpenSearchTool()
    os_tool.create_index(
        index_name="suzieq-schema",
        mappings={
            "properties": {
                "table": {"type": "keyword"},
                "fields": {
                    "type": "nested",
                    "properties": {
                        "name": {"type": "keyword"},
                        "type": {"type": "keyword"},
                        "description": {"type": "text"},
                        "key": {"type": "integer"},
                        "display": {"type": "integer"}
                    }
                },
                "key_fields": {"type": "keyword"},
                "display_fields": {"type": "keyword"},
                "table_type": {"type": "keyword"}
            }
        }
    )
    
    os_tool.bulk_index(
        index_name="suzieq-schema",
        documents=documents
    )
    
    print(f"âœ… Indexed {len(documents)} SuzieQ table schemas")
    print(f"Available tables: {', '.join([d['table'] for d in documents])}")

def _simplify_type(type_def):
    """ç®€åŒ–ç±»å‹å®šä¹‰"""
    if isinstance(type_def, str):
        return type_def
    elif isinstance(type_def, dict):
        if type_def.get('type') == 'array':
            item_type = type_def.get('items', {}).get('type', 'unknown')
            return f"array<{item_type}>"
        return type_def.get('type', 'complex')
    return 'unknown'

if __name__ == "__main__":
    index_suzieq_schemas()
```

### NTC-Templates Schema ç´¢å¼•åŒ– (ntc_schema_etl.py)

**èŒè´£**: è§£æ NTC-Templates çš„ TextFSM æ¨¡æ¿ï¼Œæå–å‘½ä»¤å…ƒæ•°æ®å¹¶ç´¢å¼•åˆ° OpenSearchï¼Œæ”¯æŒ CLI é™çº§æ¨¡å¼ã€‚

**è®¾è®¡è¦ç‚¹**:
1. **è½»é‡çº§è§£æ**: ä»…æå–æ¨¡æ¿å¤´éƒ¨ `Value` å®šä¹‰ï¼ˆå­—æ®µåå’Œç±»å‹ï¼‰ï¼Œä¸ä½¿ç”¨å®Œæ•´ pyang è§£æå™¨
2. **è¯­ä¹‰æ˜ å°„**: å°†å‘½ä»¤æ˜ å°„åˆ°å¸¸è§è¿ç»´æ„å›¾ï¼ˆ"æ¥å£çŠ¶æ€" â†’ "show interfaces"ï¼‰
3. **é»‘åå•è¿‡æ»¤**: æ’é™¤å±é™©å‘½ä»¤ï¼ˆreload, tracerouteï¼‰

```python
# src/olav/etl/ntc_schema_etl.py
import re
from pathlib import Path
from typing import List, Dict, Optional
from opensearchpy import OpenSearch, helpers
import os

# æ­£åˆ™æå– TextFSM æ¨¡æ¿ä¸­çš„å­—æ®µå®šä¹‰
VALUE_RE = re.compile(r'^Value\s+(?P<name>\w+)\s+\((?P<regex>.+?)\)', re.MULTILINE)

# è¯­ä¹‰æ˜ å°„è¡¨ï¼ˆå‘½ä»¤ â†’ è¿ç»´æ„å›¾ï¼‰
SEMANTIC_MAP = {
    "show interfaces": ["æ¥å£çŠ¶æ€", "interface status", "port info", "link state"],
    "show ip route": ["è·¯ç”±è¡¨", "routing table", "ip routes"],
    "show ip bgp summary": ["BGP é‚»å±…", "bgp neighbors", "bgp peers"],
    "show version": ["è®¾å¤‡ç‰ˆæœ¬", "device version", "system info"],
    "show running-config": ["è¿è¡Œé…ç½®", "running config", "current config"],
    "show inventory": ["ç¡¬ä»¶æ¸…å•", "hardware inventory", "chassis info"],
}

# å±é™©å‘½ä»¤é»‘åå•
BLACKLIST = {"reload", "traceroute", "write erase", "format", "delete"}

class NTCSchemaETL:
    def __init__(self, templates_dir: str = "archive/ntc-templates/ntc_templates/templates"):
        self.templates_dir = Path(templates_dir)
        self.client = OpenSearch(
            hosts=[os.getenv("OPENSEARCH_URL", "http://localhost:9200")],
            http_auth=None,
            use_ssl=False,
            verify_certs=False
        )
        self.index_name = "ntc-schema"
    
    def parse_template_metadata(self, template_path: Path) -> Optional[Dict]:
        """è§£æ TextFSM æ¨¡æ¿å¤´éƒ¨ï¼Œæå–å­—æ®µå®šä¹‰"""
        # ... (å®ç°ç•¥ï¼Œæå– Value å®šä¹‰)
    
    def extract_command_from_filename(self, filename: str) -> Optional[str]:
        """ä»æ¨¡æ¿æ–‡ä»¶åæå–å‘½ä»¤"""
        # ... (å®ç°ç•¥)
    
    def index_templates(self):
        """ç´¢å¼•æ‰€æœ‰ NTC-Templates åˆ° OpenSearch ntc-schema ç´¢å¼•"""
        # ... (å®ç°ç•¥)
```

**ç´¢å¼•æ–‡æ¡£ç»“æ„**:
```json
{
    "platform": "cisco_ios",
    "command": "show interfaces",
    "parser": "cisco_ios_show_interfaces.textfsm",
    "fields": ["interface", "link_status", "protocol", "mtu", "bandwidth"],
    "field_types": {"interface": "string", "link_status": "enum", "protocol": "enum"},
    "field_count": 5,
    "semantic_tags": ["æ¥å£çŠ¶æ€", "interface status", "port info"],
    "template_path": "templates/cisco_ios_show_interfaces.textfsm",
    "is_read_only": true,
    "is_dangerous": false
}
```

**ä¸ baseline_collector.py çš„å¯¹æ¯”**:

| åŠŸèƒ½ | baseline_collector | ntc_schema_etl (OLAV) |
|------|-------------------|----------------|
| æ¨¡æ¿æ‰«æ | âœ… .backup.textfsm | âœ… æ‰€æœ‰ .textfsm |
| å­—æ®µæå– | âœ… TextFSM è§£æ | âœ… æ­£åˆ™æå– Value |
| å‘½ä»¤é»‘åå• | âœ… command_blacklist.txt | âœ… å†…ç½® BLACKLIST |
| è‡ªåŠ¨æ‰§è¡Œ | âœ… Nornir æ‰¹é‡æ‰§è¡Œ | âŒ ä»…ç´¢å¼•å…ƒæ•°æ® |
| é…ç½®å¤‡ä»½ | âœ… backups/ ç›®å½• | âŒ ä¸æ‰§è¡Œå¤‡ä»½ |
| Gitea é›†æˆ | âœ… Git ç‰ˆæœ¬æ§åˆ¶ | âŒ OpenSearch |
| è¯­ä¹‰æœç´¢ | âŒ æ—  | âœ… semantic_tags |
| Schema ç´¢å¼• | âŒ æ—  | âœ… ntc-schema |

**OLAV é‡‡ç”¨çš„è®¾è®¡**:
- âœ… **åªç´¢å¼• Schema**: ä¸æ‰§è¡Œå‘½ä»¤ï¼Œä»…æä¾›å…ƒæ•°æ®ç»™ LLM
- âœ… **è¯­ä¹‰æœç´¢**: æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ ("æ¥å£çŠ¶æ€" â†’ "show interfaces")
- âœ… **å®‰å…¨æ ‡è®°**: `is_read_only`, `is_dangerous` å­—æ®µè¾…åŠ©å†³ç­–
- âŒ **ä¸åšå¤‡ä»½**: å¤‡ä»½ä»»åŠ¡ç”±ä¸“ç”¨å·¥å…·ï¼ˆbaseline_collectorï¼‰æˆ–å®šæ—¶ä»»åŠ¡å¤„ç†

---

### YANG æ¨¡å‹è½¬æ¢ (init_schema.py)

```python
# src/olav/etl/init_schema.py
import git
import os
from pathlib import Path
from config.settings import settings
from olav.etl.yang_parser import YANGParser
from olav.tools.opensearch_tool import OpenSearchTool

def clone_openconfig_repo():
    """å…‹éš† OpenConfig ä»“åº“"""
    repo_dir = Path("/tmp/openconfig")
    
    if repo_dir.exists():
        print("OpenConfig repo already exists, pulling latest...")
        repo = git.Repo(repo_dir)
        repo.remotes.origin.pull()
    else:
        print(f"Cloning {settings.OPENCONFIG_REPO_URL}...")
        git.Repo.clone_from(
            settings.OPENCONFIG_REPO_URL,
            repo_dir,
            branch=settings.OPENCONFIG_REPO_BRANCH
        )
    
    return repo_dir

def main():
    """Schema ETL ä¸»æµç¨‹"""
    print("=== Starting OpenConfig Schema ETL ===")
    
    # 1. å…‹éš†ä»“åº“
    repo_dir = clone_openconfig_repo()
    
    # 2. è§£æ YANG æ¨¡å‹
    parser = YANGParser()
    yang_files = list(repo_dir.glob("release/models/**/*.yang"))
    
    print(f"Found {len(yang_files)} YANG files")
    
    schemas = []
    for yang_file in yang_files:
        try:
            schema_data = parser.parse(yang_file)
            schemas.extend(schema_data)
        except Exception as e:
            print(f"Error parsing {yang_file}: {e}")
    
    # 3. å†™å…¥ OpenSearch
    os_tool = OpenSearchTool()
    os_tool.bulk_index(
        index_name="openconfig-schema",
        documents=schemas
    )
    
    print(f"âœ… Indexed {len(schemas)} schema entries")

if __name__ == "__main__":
    main()
```

### YANG è§£æå™¨ (yang_parser.py)

```python
# src/olav/etl/yang_parser.py
from pyang import repository, context
from pyang.statements import Statement
from typing import List, Dict

class YANGParser:
    def parse(self, yang_file: Path) -> List[Dict]:
        """
        è§£æ YANG æ–‡ä»¶å¹¶æå–å¯æ£€ç´¢çš„ XPath
        
        Returns:
            [
                {
                    "xpath": "/interfaces/interface/state/counters/in-errors",
                    "module": "openconfig-interfaces",
                    "type": "uint64",
                    "description": "Number of input errors"
                },
                ...
            ]
        """
        repos = repository.FileRepository(str(yang_file.parent))
        ctx = context.Context(repos)
        
        with open(yang_file) as f:
            module = ctx.add_module(yang_file.name, f.read())
        
        if module is None:
            raise ValueError(f"Failed to parse {yang_file}")
        
        schemas = []
        self._extract_paths(module, "", schemas)
        return schemas
    
    def _extract_paths(self, stmt: Statement, path: str, schemas: List[Dict]):
        """é€’å½’æå– XPath"""
        if stmt.keyword in ['container', 'list', 'leaf', 'leaf-list']:
            current_path = f"{path}/{stmt.arg}"
            
            if stmt.keyword in ['leaf', 'leaf-list']:
                schemas.append({
                    "xpath": current_path,
                    "module": stmt.top.arg,
                    "type": stmt.search_one('type').arg if stmt.search_one('type') else None,
                    "description": stmt.search_one('description').arg if stmt.search_one('description') else ""
                })
            
            for child in stmt.substmts:
                self._extract_paths(child, current_path, schemas)
```

---

## 14. Learner Agent å‘é‡åŒ–å­˜å‚¨

```python
# src/olav/agents/learner_agent.py
from langchain.schema import Document
from olav.core.llm import LLMFactory
from olav.tools.opensearch_tool import OpenSearchTool

class LearnerAgent:
    def __init__(self):
        self.embedding_model = LLMFactory.get_embedding_model()
        self.os_tool = OpenSearchTool()
    
    def store_episode(
        self,
        user_intent: str,
        solution: str,
        device: str,
        success: bool = True
    ):
        """
        å‘é‡åŒ–å­˜å‚¨æˆåŠŸçš„æ•…éšœè¯Šæ–­ç»éªŒ
        
        Args:
            user_intent: ç”¨æˆ·åŸå§‹é—®é¢˜
            solution: è§£å†³æ–¹æ¡ˆï¼ˆåŒ…å« XPathã€å‘½ä»¤ç­‰ï¼‰
            device: è®¾å¤‡åç§°
            success: æ˜¯å¦æˆåŠŸè§£å†³
        """
        if not success:
            return  # åªå­˜å‚¨æˆåŠŸæ¡ˆä¾‹
        
        # æ„å»ºæ–‡æ¡£
        doc = Document(
            page_content=f"é—®é¢˜: {user_intent}\nè§£å†³æ–¹æ¡ˆ: {solution}",
            metadata={
                "device": device,
                "intent": user_intent,
                "solution": solution,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # ç”Ÿæˆå‘é‡
        embedding = self.embedding_model.embed_query(doc.page_content)
        
        # å­˜å‚¨åˆ° OpenSearch
        self.os_tool.index_document(
            index_name="olav-episodic-memory",
            document={
                "content": doc.page_content,
                "embedding": embedding,
                **doc.metadata
            }
        )
        
        print(f"âœ… Stored episode to memory: {user_intent[:50]}...")
```

---

## 15. Prompt ç®¡ç†ç³»ç»Ÿ (LangChain Prompt Templates)

**è®¾è®¡åŸåˆ™**: æ‰€æœ‰ Prompt ä½¿ç”¨ **é…ç½®æ–‡ä»¶** ç®¡ç†ï¼Œé¿å…ç¡¬ç¼–ç åœ¨ Python ä»£ç ä¸­ã€‚

### Prompt ç›®å½•ç»“æ„

```
config/prompts/
â”œâ”€â”€ agents/              # Agent System Prompts
â”‚   â”œâ”€â”€ root_agent.yaml
â”‚   â”œâ”€â”€ rag_agent.yaml
â”‚   â”œâ”€â”€ suzieq_agent.yaml
â”‚   â””â”€â”€ netconf_agent.yaml
â”œâ”€â”€ tools/               # Tool Descriptions  
â”‚   â”œâ”€â”€ nornir_tool.yaml
â”‚   â”œâ”€â”€ suzieq_query.yaml
â”‚   â””â”€â”€ opensearch_tool.yaml
â””â”€â”€ rag/                 # RAG Query Templates
    â”œâ”€â”€ schema_search.yaml
    â”œâ”€â”€ memory_search.yaml
    â””â”€â”€ docs_search.yaml
```

### Prompt æ¨¡æ¿ç¤ºä¾‹

**Agent System Prompt** (`config/prompts/agents/root_agent.yaml`):
```yaml
_type: prompt
input_variables:
  - user_name
  - network_context
template: |
  ä½ æ˜¯ä¼ä¸šç½‘ç»œè¿ç»´ä¸“å®¶ OLAV (OpenConfig LLM-Assisted Validator)ã€‚
  
  å½“å‰æ“ä½œå‘˜: {user_name}
  ç½‘ç»œä¸Šä¸‹æ–‡: {network_context}
  
  å·¥ä½œæµç¨‹:
  1. ä½¿ç”¨ rag_agent æ£€ç´¢ Schema/Docs/Memory
  2. ä½¿ç”¨ suzieq_agent è¿›è¡Œå®è§‚å†å²åˆ†æ
  3. ä½¿ç”¨ netconf_agent æ‰§è¡Œå®æ—¶è¯Šæ–­å’Œé…ç½®å˜æ›´
  
  æ ¸å¿ƒåŸåˆ™:
  - é…ç½®å˜æ›´å¿…é¡»ç»è¿‡ HITL å®¡æ‰¹
  - ä¼˜å…ˆä½¿ç”¨ OpenConfig æ ‡å‡†åŒ–è·¯å¾„
  - æ‰€æœ‰æ“ä½œè®°å½•å®¡è®¡æ—¥å¿—
  - ä¸ç¡®å®šæ—¶ä¸»åŠ¨è¯¢é—®ç”¨æˆ·
```

**Tool Description** (`config/prompts/tools/suzieq_query.yaml`):
```yaml
_type: prompt
input_variables:
  - available_tables
  - example_usage
template: |
  Query SuzieQ historical network data using schema-aware approach.
  
  Available Tables: {available_tables}
  
  Parameters:
    - table: Table name (e.g., 'interfaces', 'bgp', 'routes')
    - method: Query method ('get', 'summarize', 'unique', 'aver')
    - filters: Dict of field filters (e.g., hostname='router1', state='up')
  
  Example Usage:
  {example_usage}
  
  Note: This is a READ-ONLY tool. All data is queried from Parquet files.
```

**è‡ªå®šä¹‰ä¸­é—´ä»¶**:
```python
# src/olav/agents/middleware/network_context.py
from langchain.agents.middleware import AgentMiddleware

class NetworkContextMiddleware(AgentMiddleware):
    """æ³¨å…¥ç½‘ç»œä¸Šä¸‹æ–‡ï¼ˆæ‹“æ‰‘ã€è®¾å¤‡çŠ¶æ€ï¼‰åˆ°æ¯ä¸ªè¯·æ±‚"""
    
    async def on_model_request(self, request: ModelRequest, state: AgentState):
        # ä» NetBox è·å–æ‹“æ‰‘ä¿¡æ¯
        topology = await self.get_topology_context(state.get('device'))
        request.messages.insert(0, SystemMessage(content=f"Network Context: {topology}"))
        return request
```

### Prompt åŠ è½½å™¨å®ç°

**Prompt Manager** (`src/olav/core/prompt_manager.py`):
```python
from pathlib import Path
from langchain.prompts import load_prompt
from typing import Dict
import logging

logger = logging.getLogger(__name__)

class PromptManager:
    """ç»Ÿä¸€ Prompt ç®¡ç†å™¨ï¼Œä½¿ç”¨ LangChain PromptTemplate"""
    
    def __init__(self, prompts_dir: Path = None):
        self.prompts_dir = prompts_dir or Path("config/prompts")
        self._cache: Dict[str, Any] = {}
    
    def load_prompt(self, category: str, name: str, **kwargs) -> str:
        """
        åŠ è½½å¹¶æ¸²æŸ“ Prompt æ¨¡æ¿
        
        Args:
            category: 'agents', 'tools', 'rag'
            name: prompt æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
            **kwargs: æ¨¡æ¿å˜é‡
        
        Returns:
            æ¸²æŸ“åçš„ Prompt å­—ç¬¦ä¸²
        """
        cache_key = f"{category}/{name}"
        
        if cache_key not in self._cache:
            prompt_path = self.prompts_dir / category / f"{name}.yaml"
            
            if not prompt_path.exists():
                raise FileNotFoundError(f"Prompt not found: {prompt_path}")
            
            # ä½¿ç”¨ LangChain çš„ load_prompt
            self._cache[cache_key] = load_prompt(str(prompt_path))
            logger.info(f"Loaded prompt: {cache_key}")
        
        template = self._cache[cache_key]
        return template.format(**kwargs)
    
    def load_agent_prompt(self, agent_name: str, **context) -> str:
        """å¿«æ·æ–¹æ³•ï¼šåŠ è½½ Agent System Prompt"""
        return self.load_prompt("agents", agent_name, **context)
    
    def reload(self):
        """æ¸…ç©ºç¼“å­˜ï¼Œé‡æ–°åŠ è½½æ‰€æœ‰ Promptsï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰"""
        self._cache.clear()

# å…¨å±€å•ä¾‹
prompt_manager = PromptManager()
```

### ä½¿ç”¨ç¤ºä¾‹

**åœ¨ Agent ä¸­ä½¿ç”¨**:
```python
# src/olav/agents/root_agent.py
from olav.core.prompt_manager import prompt_manager
from deepagents import create_deep_agent

# åŠ è½½ System Promptï¼ˆæ”¯æŒåŠ¨æ€å˜é‡æ³¨å…¥ï¼‰
system_prompt = prompt_manager.load_agent_prompt(
    "root_agent",
    user_name=current_user.name,
    network_context=get_network_context()
)

agent = create_deep_agent(
    model=model,
    system_prompt=system_prompt,  # ä»é…ç½®æ–‡ä»¶åŠ è½½
    subagents=[...],
)
```

**åœ¨ Tool ä¸­ä½¿ç”¨**:
```python
# src/olav/tools/suzieq_tool.py
from olav.core.prompt_manager import prompt_manager

# åŠ¨æ€åŠ è½½ Tool Description
available_tables = schema.tables()
tool_description = prompt_manager.load_tool_description(
    "suzieq_query",
    available_tables=", ".join(available_tables),
    example_usage="suzieq_query(table='bgp', method='summarize')"
)

suzieq_query_tool = StructuredTool.from_function(
    name="suzieq_query",
    func=suzieq_query,
    description=tool_description  # ä»é…ç½®æ–‡ä»¶åŠ è½½
)
```

### ä¼˜åŠ¿æ€»ç»“

| ç‰¹æ€§ | ä¼ ç»Ÿç¡¬ç¼–ç  | LangChain Prompt ç®¡ç† |
|------|-----------|----------------------|
| **å¯ç»´æŠ¤æ€§** | ä»£ç ä¸­ä¿®æ”¹ Prompt | é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹ |
| **ç‰ˆæœ¬æ§åˆ¶** | æ··æ‚åœ¨ä»£ç ä¸­ | ç‹¬ç«‹ YAML æ–‡ä»¶ |
| **åŠ¨æ€æ³¨å…¥** | æ‰‹åŠ¨å­—ç¬¦ä¸²æ‹¼æ¥ | PromptTemplate è‡ªåŠ¨æ¸²æŸ“ |
| **å¤šè¯­è¨€æ”¯æŒ** | éœ€è¦é‡å†™ä»£ç  | åˆ‡æ¢é…ç½®æ–‡ä»¶ |
| **A/B æµ‹è¯•** | å›°éš¾ | è½»æ¾åˆ‡æ¢ä¸åŒç‰ˆæœ¬ |
| **çƒ­æ›´æ–°** | éœ€é‡å¯æœåŠ¡ | `prompt_manager.reload()` |

---

## 16. æ¶æ„ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºæºç åˆ†æï¼‰

åŸºäºå¯¹ **DeepAgents**, **LangChain V1**, **LangGraph**, **SuzieQ** æºä»£ç çš„åˆ†æï¼Œä»¥ä¸‹æ˜¯å…³é”®æ¶æ„æ”¹è¿›å»ºè®®ï¼š

### 15.1 ç›´æ¥ä½¿ç”¨ DeepAgents æ¡†æ¶

**å‘ç°**: DeepAgents å·²ç»å®ç°äº† OLAV éœ€è¦çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
*   **TodoListMiddleware**: è‡ªåŠ¨ä»»åŠ¡åˆ†è§£ä¸è·Ÿè¸ª
*   **SubAgentMiddleware**: å­ä»£ç†å§”æ‰˜æœºåˆ¶
*   **HumanInTheLoopMiddleware**: HITL å®¡æ‰¹æµç¨‹
*   **SummarizationMiddleware**: é•¿å¯¹è¯è‡ªåŠ¨æ‘˜è¦
*   **FilesystemMiddleware**: æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼ˆå¯é€‚é…ä¸ºé…ç½®æ–‡ä»¶è¯»å†™ï¼‰

**å»ºè®®**:
```python
# ç›´æ¥ä½¿ç”¨ create_deep_agent è€Œéè‡ªå·±å®ç°
from deepagents import create_deep_agent, SubAgent

# ä¸éœ€è¦è‡ªå·±å†™ root_agent.py çš„ LangGraph ç¼–æ’
# DeepAgents å·²å†…ç½® TodoList, Subagent, HITL æœºåˆ¶
agent = create_deep_agent(
    model=LLMFactory.get_chat_model(),
    system_prompt="""ä½ æ˜¯ä¼ä¸šç½‘ç»œè¿ç»´ä¸“å®¶ OLAVã€‚
    
å·¥ä½œæµç¨‹:
1. ä½¿ç”¨ rag_agent æ£€ç´¢ Schema/Docs/Memory
2. ä½¿ç”¨ suzieq_agent è¿›è¡Œå®è§‚å†å²åˆ†æ
3. ä½¿ç”¨ netconf_agent è¿›è¡Œå®æ—¶å¾®è§‚è¯Šæ–­
4. æ‰€æœ‰ Write æ“ä½œå¿…é¡»ç­‰å¾…äººå·¥æ‰¹å‡†
""",
    subagents=[suzieq_subagent, rag_subagent, netconf_subagent],
    middleware=[
        NetworkContextMiddleware(),  # è‡ªå®šä¹‰ä¸­é—´ä»¶
    ],
    checkpointer=RedisCheckpointer(settings.REDIS_URL),
    interrupt_on={
        "nornir_tool": {"allowed_decisions": ["approve", "edit", "reject"]}
    }
).with_config({"recursion_limit": 1000})
```

**ä¼˜åŠ¿**:
- å‡å°‘ 500+ è¡Œè‡ªå®šä¹‰ LangGraph ç¼–æ’ä»£ç 
- å†…ç½® `recursion_limit=1000` æ”¯æŒæ·±åº¦ä»»åŠ¡
- è‡ªåŠ¨é›†æˆ Anthropic Prompt Caching
- ç¤¾åŒºç»´æŠ¤ï¼ŒæŒç»­æ›´æ–°

### 15.2 åˆ©ç”¨ SuzieQ åŸç”Ÿ SqObject API

**å‘ç°**: SuzieQ ä½¿ç”¨æ’ä»¶æ¨¡å¼ï¼Œæ‰€æœ‰æŸ¥è¯¢é€šè¿‡ `get_sqobject()` å·¥å‚å‡½æ•°è¿”å›æ ‡å‡†åŒ–å¯¹è±¡ï¼š

```python
from suzieq.sqobjects import get_sqobject

# æ”¯æŒ 30+ ç§ç½‘ç»œèµ„æºç±»å‹
iface_obj = get_sqobject('interface')  # InterfaceObj
bgp_obj = get_sqobject('bgp')          # BgpObj
route_obj = get_sqobject('routes')     # RouteObj

# æ‰€æœ‰å¯¹è±¡ç»Ÿä¸€ API

df = iface_obj.get(hostname='R1', start_time=t1, end_time=t2)
summary = bgp_obj.summarize(namespace='prod')
unique = route_obj.unique(columns=['prefix'])
```

**å»ºè®®**:
*   **ä¸éœ€è¦** å°è£… `suzieq_tool.py` ä¸ºå•ç‹¬çš„å·¥å…·
*   ç›´æ¥ä½¿ç”¨ `SqObject` çš„ `get()`, `summarize()`, `unique()` æ–¹æ³•
*   LLM å¯ä»¥ç›´æ¥å­¦ä¼š SuzieQ çš„ æ ‡å‡† APIï¼ˆç®€åŒ– Promptï¼‰

### 15.3 é‡‡ç”¨ LangGraph Checkpointer æ¨¡å¼

**å‘ç°**: LangGraph æœ‰å®Œå–„çš„ Checkpoint ä½“ç³»ï¼š
*   `checkpoint-postgres`: PostgreSQL æŒä¹…åŒ–
*   `checkpoint-sqlite`: SQLite æœ¬åœ°å­˜å‚¨
*   `langgraph.checkpoint.memory.MemorySaver`: å†…å­˜æ¨¡å¼ï¼ˆæµ‹è¯•ï¼‰

**å½“å‰è®¾è®¡é—®é¢˜**: ç›´æ¥ä½¿ç”¨ Redis å­˜å‚¨ Stateï¼Œæœªéµå¾ª LangGraph çš„ Checkpointer åè®®ã€‚

**å»ºè®®**:
```python
from langgraph.checkpoint.postgres import PostgresSaver

# ä½¿ç”¨æ ‡å‡† Checkpointer
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@postgres:5432/olav"
)

agent = create_deep_agent(
    ...,
    checkpointer=checkpointer  # è‡ªåŠ¨æŒä¹…åŒ–çŠ¶æ€
)

# æ”¯æŒæ–­ç‚¹ç»­ä¼ 
config = {"configurable": {"thread_id": "user-123"}}
result = agent.invoke({"messages": [...]}, config=config)
```

### 15.4 Backend åè®®å±‚ï¼ˆå€Ÿé‰´ DeepAgentsï¼‰

**å‘ç°**: DeepAgents å®šä¹‰äº†æ¸…æ™°çš„ Backend åè®®æ ï¼š
*   `BackendProtocol`: åŸºç¡€ CRUD
*   `SandboxBackendProtocol`: æ”¯æŒå‘½ä»¤æ‰§è¡Œ
*   `StoreBackendProtocol`: æŒä¹…åŒ–å­˜å‚¨

**OLAV åº”ç”¨**:
```python
# src/olav/execution/backends/nornir_sandbox.py
from deepagents.backends.protocol import SandboxBackendProtocol

class NornirSandbox(SandboxBackendProtocol):
    async def execute(self, command: str, background: bool = False):
        # å®ç° NETCONF æ‰§è¡Œé€»è¾‘
        pass

# ä½¿ç”¨
agent = create_deep_agent(
    backend=lambda rt: NornirSandbox(rt),
    ...
)
```

### 15.5 ä¸­é—´ä»¶æ‰©å±•æ¨¡å¼

**å‘ç°**: LangChain V1 ä¸­é—´ä»¶æ”¯æŒ 30+ ç§å†…ç½®ç±»å‹ï¼š
*   `tool_retry.py`: å·¥å…·è°ƒç”¨é‡è¯•
*   `model_fallback.py`: LLM é™çº§æœºåˆ¶
*   `pii.py`: PII æ•°æ®ç¼–ç 
*   `summarization.py`: å¯¹è¯æ‘˜è¦

**OLAV è‡ªå®šä¹‰ä¸­é—´ä»¶**:
```python
# src/olav/agents/middleware/network_context.py
from langchain.agents.middleware import AgentMiddleware

class NetworkContextMiddleware(AgentMiddleware):
    """NetBox ä¸Šä¸‹æ–‡æ³¨å…¥"""
    
    async def on_model_request(self, request, state):
        # ä» NetBox è·å–æ‹“æ‰‘ä¿¡æ¯
        device = state.get('device_name')
        if device:
            topology = await self.netbox.get_topology(device)
            request.messages.insert(0, 
                SystemMessage(content=f"Network Context: {topology}")
            )
        return request
```

### 15.6 ä¾èµ–åŒ…è°ƒæ•´

**å½“å‰ `pyproject.toml` è¡¥å……**:
```toml
[tool.uv.dependencies]
# æ ¸å¿ƒæ¡†æ¶
deepagents = "^0.2.0"              # æ›¿ä»£è‡ªå·±å®ç°çš„ LangGraph ç¼–æ’
langchain = "^0.3.20"             # LangChain V1 ä¸­é—´ä»¶æ”¯æŒ
langgraph = "^0.2.65"             # StateGraph åŸºç¡€
langgraph-checkpoint-postgres = "^1.0.0"  # Checkpoint æŒä¹…åŒ–

# LLM Providers
langchain-openai = "^0.3.0"
langchain-anthropic = "^0.3.0"
langchain-ollama = "^0.2.0"

# ç½‘ç»œå·¥å…·
suzieq = "^0.23.0"                # ä½¿ç”¨åŸç”Ÿ API
nornir = "^3.4.0"
nornir-netbox = "^1.1.0"         # NetBox æ’ä»¶
nornir-scrapli = "^2024.1.30"    # NETCONF è¿æ¥

# å‘é‡æ•°æ®åº“
opensearch-py = "^2.7.1"

# Web æ¡†æ¶
fastapi = "^0.115.0"
uvicorn = "^0.32.0"

# CLI
typer = "^0.15.0"
rich = "^13.9.0"
```

### 15.7 æ¶æ„è°ƒæ•´æ¸…å•

**éœ€è¦åˆ é™¤/ç®€åŒ–çš„æ¨¡å—**:
- â˜ `src/olav/core/graph.py` â†’ ç”¨ `create_deep_agent()` æ›¿ä»£
- â˜ `src/olav/agents/root_agent.py` â†’ ç®€åŒ–ä¸º SubAgent é…ç½®æ–‡ä»¶
- â˜ è‡ªå·±å®ç°çš„ TodoList é€»è¾‘ â†’ ä½¿ç”¨ `TodoListMiddleware`

**éœ€è¦æ–°å¢çš„æ¨¡å—**:
- â˜‘ `src/olav/agents/middleware/network_context.py`
- â˜‘ `src/olav/execution/backends/protocol.py`
- â˜‘ `src/olav/execution/backends/nornir_sandbox.py`

**é…ç½®æ–‡ä»¶è°ƒæ•´**:
```yaml
# config/agents.yml - SubAgent é…ç½®
subagents:
  - name: suzieq-analyzer
    description: æŸ¥è¯¢å†å²ç½‘ç»œæ•°æ®å’Œè¶‹åŠ¿åˆ†æ
    prompt: |
      ä½ æ˜¯ç½‘ç»œå¯è§‚æµ‹æ€§ä¸“å®¶ï¼Œä½¿ç”¨ SuzieQ API åˆ†æå†å²æ•°æ®ã€‚
      
      å¯ç”¨ API:
      - get_sqobject('interface').get(hostname, start_time, end_time)
      - get_sqobject('bgp').summarize(namespace)
      - get_sqobject('routes').unique(columns=['prefix'])
    tools:
      - suzieq_toolkit
      - datetime_tool
  
  - name: knowledge-retriever
    description: æ£€ç´¢ OpenConfig Schemaã€æ–‡æ¡£å’Œå†å²ç»éªŒ
    prompt: |
      æ‰§è¡Œæ™ºèƒ½çŸ¥è¯†æ£€ç´¢ï¼š
      1. Memory ä¼˜å…ˆï¼šæŸ¥æ‰¾å†å²æˆåŠŸæ¡ˆä¾‹
      2. Schema å›é€€ï¼šæŸ¥è¯¢ OpenConfig XPath
      3. Docs è¡¥å……ï¼šæœç´¢ç›¸å…³æ–‡æ¡£
    tools:
      - opensearch_tool
  
  - name: netconf-executor
    description: æ‰§è¡Œ NETCONF/gNMI å®æ—¶è®¾å¤‡æ“ä½œ
    prompt: åŸºäº OpenConfig Schema æ„å»º NETCONF Payload
    tools:
      - nornir_tool
    interrupt_on:
      nornir_tool:
        allowed_decisions: [approve, edit, reject]
    
  - name: netbox-manager
    description: ç®¡ç† NetBox ä¸­çš„è®¾å¤‡å’Œç«™ç‚¹ä¿¡æ¯
    prompt: |
      ä½ æ˜¯ç½‘ç»œèµ„äº§ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ç»´æŠ¤ NetBox ä¸­çš„è®¾å¤‡å’Œç«™ç‚¹ä¿¡æ¯ã€‚
      
      æ‰€æœ‰æ“ä½œå¿…é¡»ç¡®ä¿ä¾èµ–å…³ç³»å®Œæ•´ï¼Œå¦‚ï¼š
      - Site å¿…é¡»å­˜åœ¨
      - Manufacturer å¿…é¡»å­˜åœ¨
    tools:
      - netbox_schema_search
      - netbox_api_call
      - inventory_import
      - sync_configs
```

### 15.8 æœ€ç»ˆæ¶æ„ç¤ºæ„å›¾

```mermaid
graph TD
    subgraph "User Interface"
        CLI[Rich CLI / Terminal] <-->|Stream/Input| App_Container
    end

    subgraph "OLAV Application (Main Brain)"
        App_Container[olav-app]
        LLM_Factory[LLM Factory] -->|Invoke| App_Container
        Supervisor[Supervisor Agent] -->|Route| Workers
        
        subgraph "Workers (Agents)"
            SuzieQ_Agent[Macro Agent]
            Netconf_Agent[Micro Agent]
            NetBox_Agent[SSOT Agent]
            Doc_Agent[Doc Agent]
            Learner_Agent[Reflection Node]
        end
    end

    subgraph "Infrastructure Services"
        Redis[(Redis)] <-->|State Persistence| App_Container
        OpenSearch[(OpenSearch)] <-->|Vector Search| App_Container
        SuzieQ_Service[SuzieQ Poller] -->|Parquet| Shared_Vol[Shared Volume]
    end

    subgraph "Support Containers"
        Init_Container[olav-init] -->|ETL Schema| OpenSearch
        Embedder_Service[olav-embedder] -->|Ingest PDF/Docs| OpenSearch
        Embedder_Service <-->|API Trigger| App_Container
    end

    subgraph "External World"
        NetBox[(NetBox Source of Truth)]
        Network_Devices[Switches/Routers]
        LLM_Provider[OpenAI/Ollama/Azure]
    end

    App_Container -->|Inventory| NetBox
    App_Container -->|Nornir Execution| Network_Devices
    NetBox_Agent -->|Manage| NetBox
```

**æ ¸å¿ƒä¼˜åŠ¿**:
- **ä»£ç é‡å‡å°‘ 60%**ï¼šä¸éœ€è¦è‡ªå·±å®ç° LangGraph ç¼–æ’ã€TodoListã€HITL
- **æ ‡å‡†åŒ–**ï¼šéµå¾ª LangChain/LangGraph/DeepAgents å®˜æ–¹æ¨¡å¼
- **å¯ç»´æŠ¤æ€§**ï¼šç¤¾åŒºé©±åŠ¨ï¼ŒæŒç»­æ›´æ–°
- **å­¦ä¹ æˆæœ¬ä½**ï¼šå¼€å‘è€…å¯ç›´æ¥æŸ¥é˜… DeepAgents å®˜æ–¹æ–‡æ¡£

*   **å•å…ƒæµ‹è¯• (Unit Tests)**: é’ˆå¯¹ Agent é€»è¾‘å’Œå·¥å…·ç±»ã€‚ä½¿ç”¨ `unittest.mock` æ¨¡æ‹Ÿ LLM è¿”å›å’Œç½‘ç»œè®¾å¤‡å“åº”ã€‚
*   **é›†æˆæµ‹è¯• (Integration Tests)**: æµ‹è¯• OpenSearch è¿æ¥ã€NetBox API è°ƒç”¨ã€‚
*   **E2E æµ‹è¯•**: åœ¨ Docker ç¯å¢ƒä¸­æ¨¡æ‹Ÿå®Œæ•´å¯¹è¯æµç¨‹ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿè®¾å¤‡æˆ– Lab ç¯å¢ƒï¼‰ã€‚
*   **å·¥å…·é“¾**: `pytest` (æµ‹è¯•æ¡†æ¶), `ruff` (ä»£ç é£æ ¼æ£€æŸ¥)ã€‚
