"""OLAV CLI - Enterprise Network Operations ChatOps Platform."""

import asyncio
import logging
import json
from pathlib import Path
import selectors
import sys
import time
from typing import Any

import typer
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel

from olav import __version__
# Agent imports moved to runtime (dynamic import based on --agent-mode)
from olav.tools.suzieq_parquet_tool import suzieq_query  # Direct tool access for one-shot timing
from olav.core.settings import settings
from olav.core.logging_config import setup_logging
from olav.ui import ChatUI
from config.settings import AgentConfig

logger = logging.getLogger("olav.main")
console = Console()

app = typer.Typer(
    name="olav",
    help="OLAV - Omni-Layer Autonomous Verifier: Enterprise Network Operations ChatOps Platform",
    add_completion=False,
)


@app.command()
def chat(
    query: str | None = typer.Argument(None, help="Single query to execute (non-interactive mode)"),
    expert: bool = typer.Option(False, "--expert", "-e", help="Enable Expert Mode (Deep Dive Workflow)"),
    thread_id: str | None = typer.Option(None, help="Conversation thread ID (for resuming sessions)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="Show detailed logs and timestamps"),
) -> None:
    """Start interactive chat session with OLAV agent.
    
    Architecture: Workflows Orchestrator (Modular multi-workflow system)
    
    Mode Selection:
        - Normal Mode (default): 3 workflows for standard operations
          â€¢ QueryDiagnosticWorkflow: Macro (SuzieQ) â†’ Micro (NETCONF) funnel analysis
          â€¢ DeviceExecutionWorkflow: Config changes with HITL approval
          â€¢ NetBoxManagementWorkflow: Device inventory management
        
        - Expert Mode (-e/--expert): Enables DeepDiveWorkflow for complex tasks
          â€¢ Automatic task decomposition (Todo List generation)
          â€¢ Recursive diagnostics (max 3 levels)
          â€¢ Batch audits (30+ devices parallel execution)
          â€¢ Progress tracking with Checkpointer (resume on interruption)
    
    Examples:
        # Normal mode - Interactive
        uv run olav.py
        
        # Normal mode - Single query
        uv run olav.py "æŸ¥è¯¢è®¾å¤‡ R1 çš„æŽ¥å£çŠ¶æ€"
        
        # Expert mode - Complex diagnostics
        uv run olav.py -e "å®¡è®¡æ‰€æœ‰è¾¹ç•Œè·¯ç”±å™¨çš„ BGP å®‰å…¨é…ç½®"
        uv run olav.py --expert "ä¸ºä»€ä¹ˆæ•°æ®ä¸­å¿ƒ A æ— æ³•è®¿é—®æ•°æ®ä¸­å¿ƒ Bï¼Ÿ"
        
        # Verbose mode (show detailed logs)
        uv run olav.py "æŸ¥è¯¢ R1" --verbose
        
        # Resume previous conversation
        uv run olav.py --thread-id "session-123"
    
    Note: ReAct, Legacy, Structured, and Simple agent modes have been deprecated (2025-11-23).
          See archive/deprecated_agents/README.md for migration details.
    """
    # Setup logging first
    setup_logging(verbose)
    
    # Determine mode
    mode_name = "Expert Mode (Deep Dive)" if expert else "Normal Mode"
    
    console.print(f"[bold green]OLAV v{__version__}[/bold green] - Network Operations ChatOps")
    console.print(f"LLM: {settings.llm_provider} ({settings.llm_model_name})")
    console.print(f"Architecture: Workflows Orchestrator")
    console.print(f"Mode: {mode_name}")
    console.print(f"HITL: {'Enabled' if AgentConfig.ENABLE_HITL else 'Disabled'}")
    
    # Windows: Use SelectorEventLoop for psycopg async compatibility
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    if query:
        # Single query mode (non-interactive)
        asyncio.run(_run_single_query(query, expert, thread_id))
    else:
        # Interactive chat mode
        console.print("\nType 'exit' or 'quit' to end session")
        console.print("Type 'help' for available commands\n")
        asyncio.run(_run_interactive_chat(expert, thread_id))


async def _run_single_query(query: str, expert: bool = False, thread_id: str | None = None) -> None:
    """Execute single query and exit.
    
    Args:
        query: User query to execute
        expert: Enable Expert Mode (Deep Dive Workflow)
        thread_id: Optional thread ID for conversation context
    """
    ui = ChatUI(console)
    
    try:
        # Import Workflows Orchestrator
        from olav.agents.root_agent_orchestrator import create_workflow_orchestrator
        orchestrator, agent, checkpointer_ctx = await create_workflow_orchestrator(expert_mode=expert)
        
        logger.debug(f"Workflows Orchestrator initialized successfully (expert_mode={expert})")
        
        # Generate thread ID if not provided
        if not thread_id:
            import time
            thread_id = f"cli-single-{int(time.time())}"
        
        config = {"configurable": {"thread_id": thread_id}}
        
        # Show user query
        console.print()
        ui.show_user_message(query)
        
        # First, route via orchestrator directly to obtain structured plan (needed for task descriptions)
        route_result = await orchestrator.route(query, thread_id)
        
        # If interrupted, use route_result directly (contains execution_plan & todos)
        if route_result.get("interrupted"):
            console.print("\n[bold yellow]â¸ï¸  æ‰§è¡Œå·²æš‚åœï¼Œç­‰å¾…ç”¨æˆ·å®¡æ‰¹[/bold yellow]")
            execution_plan = route_result.get("execution_plan", {})
            todos = route_result.get("todos", [])
            # Build a mapping from id -> task text for display
            task_map = {t.get("id"): t.get("task") for t in todos if isinstance(t, dict)}
            
            # Display execution plan
            console.print("\n" + "="*60)
            console.print("[bold cyan]ðŸ“‹ æ‰§è¡Œè®¡åˆ’ï¼ˆSchema è°ƒç ”ç»“æžœï¼‰[/bold cyan]")
            console.print("="*60)
            
            feasible = execution_plan.get("feasible_tasks", [])
            uncertain = execution_plan.get("uncertain_tasks", [])
            infeasible = execution_plan.get("infeasible_tasks", [])
            
            if feasible:
                console.print(f"\n[green]âœ… å¯æ‰§è¡Œä»»åŠ¡ ({len(feasible)} ä¸ª):[/green]")
                for task_id in feasible:
                    desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                    console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")
            
            if uncertain:
                console.print(f"\n[yellow]âš ï¸  ä¸ç¡®å®šä»»åŠ¡ ({len(uncertain)} ä¸ª):[/yellow]")
                for task_id in uncertain:
                    desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                    console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")
                    recs = execution_plan.get("recommendations", {})
                    if task_id in recs:
                        console.print(f"    å»ºè®®: {recs[task_id]}")
            
            if infeasible:
                console.print(f"\n[red]âŒ æ— æ³•æ‰§è¡Œä»»åŠ¡ ({len(infeasible)} ä¸ª):[/red]")
                for task_id in infeasible:
                    desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                    console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")
            
            console.print("\n" + "="*60)
            console.print("[bold]è¯·é€‰æ‹©æ“ä½œ:[/bold]")
            console.print("  [green]Y[/green] - æ‰¹å‡†æ‰§è¡Œå¯è¡Œä»»åŠ¡")
            console.print("  [red]N[/red] - ä¸­æ­¢æ‰§è¡Œ")
            console.print("  [cyan]å…¶ä»–[/cyan] - è¾“å…¥ä¿®æ”¹è¯·æ±‚ï¼ˆä¾‹å¦‚ï¼š'è·³è¿‡ä»»åŠ¡2ï¼Œä½¿ç”¨bgpè¡¨æ‰§è¡Œä»»åŠ¡5'ï¼‰")
            console.print("="*60)
            
            # Enter approval loop
            while True:
                user_input = input("\næ‚¨çš„å†³å®š: ").strip()
                
                if not user_input:
                    console.print("[yellow]è¯·è¾“å…¥æœ‰æ•ˆé€‰æ‹© (Y/N/ä¿®æ”¹è¯·æ±‚)[/yellow]")
                    continue
                
                # Resume execution with user input
                console.print(f"\n[dim]å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}[/dim]")
                
                # Convert workflow_type string to enum
                from olav.workflows.base import WorkflowType
                workflow_enum = WorkflowType[route_result["workflow_type"].upper()]
                
                resume_result = await orchestrator.resume(
                    thread_id=thread_id,
                    user_input=user_input,
                    workflow_type=workflow_enum
                )
                
                # Check if resume resulted in another interrupt (modified plan needs re-approval)
                if resume_result.get("interrupted"):
                    console.print("\n[yellow]â¸ï¸  è®¡åˆ’å·²ä¿®æ”¹ï¼Œéœ€è¦é‡æ–°å®¡æ‰¹[/yellow]")
                    execution_plan = resume_result.get("execution_plan", {})
                    todos = resume_result.get("todos", todos)
                    task_map = {t.get("id"): t.get("task") for t in todos if isinstance(t, dict)}
                    # Re-display updated execution plan for re-approval
                    feasible = execution_plan.get("feasible_tasks", [])
                    uncertain = execution_plan.get("uncertain_tasks", [])
                    infeasible = execution_plan.get("infeasible_tasks", [])

                    console.print("\n" + "="*60)
                    console.print("[bold]ðŸ—‚ï¸ æ›´æ–°åŽçš„æ‰§è¡Œè®¡åˆ’[/bold]")
                    console.print("="*60)
                    summary = execution_plan.get("summary") or execution_plan.get("plan_summary")
                    if summary:
                        console.print(summary)
                        console.print("-"*60)

                    if feasible:
                        console.print(f"[green]âœ… å¯æ‰§è¡Œä»»åŠ¡ ({len(feasible)} ä¸ª):[/green]")
                        for task_id in feasible:
                            desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                            console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")
                            recs = execution_plan.get("recommendations", {})
                            if task_id in recs:
                                console.print(f"    å»ºè®®: {recs[task_id]}")

                    if uncertain:
                        console.print(f"\n[yellow]âš ï¸  éœ€è¿›ä¸€æ­¥ç¡®è®¤çš„ä»»åŠ¡ ({len(uncertain)} ä¸ª):[/yellow]")
                        for task_id in uncertain:
                            desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                            console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")
                            recs = execution_plan.get("recommendations", {})
                            if task_id in recs:
                                console.print(f"    å»ºè®®: {recs[task_id]}")

                    if infeasible:
                        console.print(f"\n[red]âŒ æ— æ³•æ‰§è¡Œä»»åŠ¡ ({len(infeasible)} ä¸ª):[/red]")
                        for task_id in infeasible:
                            desc = task_map.get(task_id, "(æè¿°ç¼ºå¤±)")
                            console.print(f"  - ä»»åŠ¡ {task_id}: {desc}")

                    console.print("\n" + "="*60)
                    console.print("[bold]è¯·é€‰æ‹©æ“ä½œ:[/bold]")
                    console.print("  [green]Y[/green] - æ‰¹å‡†æ‰§è¡Œå¯è¡Œä»»åŠ¡")
                    console.print("  [red]N[/red] - ä¸­æ­¢æ‰§è¡Œ")
                    console.print("  [cyan]å…¶ä»–[/cyan] - è¾“å…¥è¿›ä¸€æ­¥ä¿®æ”¹è¯·æ±‚")
                    console.print("="*60)
                    continue
                
                # Execution completed or aborted
                if resume_result.get("content"):
                    ui.show_agent_response(
                        resume_result["content"],
                        metadata={
                            "tools_used": resume_result.get("tools_used", []),
                            "data_source": resume_result.get("data_source"),
                        }
                    )
                break
        
        else:
            # Fallback to streaming standard response if no interrupt
            stream_result = await _stream_agent_response(
                agent=agent,
                query=query,
                config=config,
                ui=ui,
            )
            if stream_result.get("content"):
                ui.show_agent_response(
                    stream_result["content"],
                    metadata={
                        "tools_used": stream_result.get("tools_used", []),
                        "data_source": stream_result.get("data_source"),
                        "timings": stream_result.get("timings", []),
                    }
                )
            else:
                ui.show_warning("æœªæ”¶åˆ° Agent å“åº”")
        
        # Cleanup checkpointer
        await checkpointer_ctx.__aexit__(None, None, None)
            
    except KeyboardInterrupt:
        ui.show_warning("æŸ¥è¯¢å·²ä¸­æ–­")
    except Exception as e:
        logger.error(f"Failed to execute query: {e}", exc_info=True)
        ui.show_error(str(e))
        raise typer.Exit(1)


async def _stream_agent_response(
    agent: Any,
    query: str,
    config: dict,
    ui: ChatUI,
) -> dict[str, Any]:
    """Stream agent response with thinking process visualization.
    
    Args:
        agent: Agent instance
        query: User query
        config: LangGraph config
        ui: ChatUI instance
        
    Returns:
        Dict with 'content', 'tools_used', and 'data_source'
    """
    response_content = ""
    tools_used = []
    tool_timings: list[dict[str, Any]] = []
    thinking_tree = ui.create_thinking_tree()
    current_nodes = {}  # Map tool call IDs to tree nodes
    tool_start_times = {}  # Map tool call IDs to start timestamps
    
    hitl_enabled = AgentConfig.ENABLE_HITL
    # Tools requiring HITL approval before execution (write/sensitive ops)
    hitl_required_tools = {"cli_tool", "netconf_tool", "nornir_tool", "netbox_api_call"}

    with ui.create_thinking_context() as live:
        seen_tool_ids = set()  # Track processed tool calls
        
        async for chunk in agent.astream(
            {"messages": [HumanMessage(content=query)]},
            config=config,
            stream_mode="values"  # Get full state each update
        ):
            if not isinstance(chunk, dict) or "messages" not in chunk:
                continue
            
            messages = chunk["messages"]
            if not isinstance(messages, list):
                continue
            
            # Process only recent messages (last 10 to catch SubAgent internal calls)
            for msg in messages[-10:]:
                # Detect tool calls
                if isinstance(msg, AIMessage) and hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tool_call in msg.tool_calls:
                        tool_name = tool_call.get("name")
                        tool_args = tool_call.get("args", {})
                        tool_id = tool_call.get("id")

                        if tool_name and tool_id and tool_id not in seen_tool_ids:
                            seen_tool_ids.add(tool_id)
                            
                            # For SubAgent task wrapper, map to actual tool names
                            display_tool_name = tool_name
                            if tool_name == "task" and isinstance(tool_args, dict):
                                # Use subagent_type to determine tool category
                                subagent_type = tool_args.get("subagent_type", "")
                                description = tool_args.get("description", "").lower()
                                
                                # Map SubAgent types to actual tool names (matching ChatUI tool_names)
                                if subagent_type == "suzieq-analyzer":
                                    # Infer specific tool from description
                                    if any(kw in description for kw in ["schema", "å­—æ®µ", "è¡¨ç»“æž„", "available", "fields"]):
                                        display_tool_name = "suzieq_schema_search"
                                    else:
                                        display_tool_name = "suzieq_query"
                                elif subagent_type == "netconf-executor":
                                    display_tool_name = "netconf_tool"
                                elif subagent_type == "rag-helper":
                                    display_tool_name = "rag_search"
                                else:
                                    # Keep subagent_type as fallback
                                    display_tool_name = subagent_type if subagent_type else tool_name
                            
                            # Determine if this invocation is potentially write/high-risk
                            requires_gate = False
                            risk_note = "read"
                            op_lower = json.dumps(tool_args, ensure_ascii=False).lower()
                            if tool_name == "netconf_tool" and "edit-config" in op_lower:
                                requires_gate = True
                                risk_note = "netconf-edit"
                            elif tool_name == "cli_tool" and "config_commands" in op_lower:
                                requires_gate = True
                                risk_note = "cli-config"
                            elif tool_name == "netbox_api_call" and any(tag in op_lower for tag in ["\"method\":\"post\"", "\"method\":\"put\"", "\"method\":\"patch\"", "\"method\":\"delete\""]):
                                requires_gate = True
                                risk_note = "netbox-write"

                            if hitl_enabled and tool_name in hitl_required_tools and requires_gate:
                                console.print("\n[bold yellow]ðŸ”” HITL å®¡æ‰¹è¯·æ±‚[/bold yellow]")
                                console.print(f"å·¥å…·: [cyan]{tool_name}[/cyan]")
                                console.print(f"é£Žé™©ç±»åž‹: [magenta]{risk_note}[/magenta]")
                                console.print(f"å‚æ•°: [dim]{tool_args}[/dim]")
                                decision = input("æ‰¹å‡†æ­¤æ“ä½œ? [Y/n/i(è¯¦æƒ…)]: ").strip().lower()
                                if decision == "i":
                                    console.print("\n[bold]è¯¦ç»†å‚æ•° (JSON):[/bold]")
                                    try:
                                        console.print(json.dumps(tool_args, indent=2, ensure_ascii=False))
                                    except Exception:
                                        console.print(str(tool_args))
                                    decision = input("æ‰¹å‡†æ­¤æ“ä½œ? [Y/n]: ").strip().lower()
                                if decision in {"n", "no"}:
                                    console.print("[red]âŒ æ“ä½œå·²æ‹’ç»ï¼Œç»ˆæ­¢æ‰§è¡Œæµ[/red]")
                                    return {
                                        "content": "æ“ä½œè¢«äººå·¥æ‹’ç»ï¼Œå·²å®‰å…¨ä¸­æ­¢ã€‚",
                                        "tools_used": tools_used,
                                        "data_source": None,
                                        "timings": tool_timings,
                                    }
                                else:
                                    console.print("[green]âœ… å·²æ‰¹å‡†ï¼Œç»§ç»­æ‰§è¡Œ...[/green]")

                            # Add tool node after approval
                            node = ui.add_tool_call(thinking_tree, display_tool_name, tool_args)
                            current_nodes[tool_id] = (node, display_tool_name)  # Store display name
                            tool_start_times[tool_id] = time.perf_counter()
                            tools_used.append(display_tool_name)
                            live.update(thinking_tree)
                
                # Detect tool responses
                elif isinstance(msg, ToolMessage):
                    tool_id = getattr(msg, "tool_call_id", None)
                    if tool_id and tool_id in current_nodes:
                        node, tool_name = current_nodes[tool_id]  # tool_name is already the display name
                        ui.mark_tool_complete(node, tool_name, success=True)
                        
                        # Calculate elapsed time
                        if tool_id in tool_start_times:
                            elapsed = time.perf_counter() - tool_start_times[tool_id]
                            tool_timings.append({
                                "tool": tool_name,
                                "elapsed_sec": elapsed,
                            })
                        
                        live.update(thinking_tree)
                
                # Capture AI response content
                elif isinstance(msg, AIMessage) and hasattr(msg, "content") and msg.content:
                    # Only capture if no tool calls (final response)
                    if not (hasattr(msg, "tool_calls") and msg.tool_calls):
                        response_content = msg.content
                        logger.debug(f"Captured response_content (length={len(response_content)})")

    
    # If no response content captured during streaming, get final state
    if not response_content:
        logger.debug("No response content from stream, checking final state...")
        try:
            final_state = await agent.aget_state(config)
            if final_state and hasattr(final_state, 'values') and 'messages' in final_state.values:
                final_messages = final_state.values['messages']
                # Get last AIMessage
                for msg in reversed(final_messages):
                    if isinstance(msg, AIMessage) and hasattr(msg, 'content') and msg.content:
                        response_content = msg.content
                        logger.debug(f"Got response from final state (length={len(response_content)})")
                        break
        except Exception as e:
            logger.debug(f"Failed to get final state: {e}")
    
    # Determine data source from tools used
    data_source = None
    if any("suzieq" in t for t in tools_used):
        data_source = "SuzieQ åŽ†å²æ•°æ®"
    elif any("netconf" in t or "nornir" in t for t in tools_used):
        data_source = "è®¾å¤‡å®žæ—¶æŸ¥è¯¢"
    elif any("cli" in t for t in tools_used):
        data_source = "CLI å‘½ä»¤æ‰§è¡Œ"
    
    # Check for HITL interrupt in final state
    interrupted = chunk.get("interrupted", False) if isinstance(chunk, dict) else False
    execution_plan = chunk.get("execution_plan") if isinstance(chunk, dict) else None
    workflow_type = chunk.get("workflow_type") if isinstance(chunk, dict) else None
    
    return {
        "content": response_content,
        "tools_used": list(set(tools_used)),  # Remove duplicates
        "data_source": data_source,
        "timings": tool_timings,
        "interrupted": interrupted,
        "execution_plan": execution_plan,
        "workflow_type": workflow_type,
    }


async def _run_interactive_chat(expert: bool = False, thread_id: str | None = None) -> None:
    """Run interactive chat loop.
    
    Args:
        expert: Enable Expert Mode (Deep Dive Workflow)
        thread_id: Optional thread ID for conversation context
    """
    ui = ChatUI(console)
    
    try:
        # Import Workflows Orchestrator
        from olav.agents.root_agent_orchestrator import create_workflow_orchestrator
        orchestrator, agent, checkpointer_ctx = await create_workflow_orchestrator(expert_mode=expert)
        
        logger.debug(f"Workflows Orchestrator initialized successfully (expert_mode={expert})")
        
        # Generate thread ID if not provided
        if not thread_id:
            import time
            thread_id = f"cli-interactive-{int(time.time())}"
        
        config = {"configurable": {"thread_id": thread_id}}
        console.print(f"[dim]Session ID: {thread_id}[/dim]\n")
        
        try:
            while True:
                try:
                    # Get user input
                    user_input = console.input("[bold cyan]You:[/bold cyan] ").strip()
                    
                    if not user_input:
                        continue
                        
                    # Handle special commands
                    if user_input.lower() in ["exit", "quit", "q"]:
                        console.print("[green]ðŸ‘‹ å†è§![/green]")
                        break
                    elif user_input.lower() == "help":
                        _show_help()
                        continue
                    elif user_input.lower() == "clear":
                        console.clear()
                        continue
                    elif user_input.lower() == "status":
                        _show_status()
                        continue
                    
                    # Process query
                    console.print()
                    result = await _stream_agent_response(
                        agent=agent,
                        query=user_input,
                        config=config,
                        ui=ui,
                    )
                    
                    # Display response
                    if result["content"]:
                        ui.show_agent_response(
                            result["content"],
                            metadata={
                                "tools_used": result.get("tools_used", []),
                                "data_source": result.get("data_source"),
                                "timings": result.get("timings", []),
                            }
                        )
                    else:
                        ui.show_warning("æœªæ”¶åˆ°å“åº”")
                        
                except KeyboardInterrupt:
                    console.print("\n[yellow]ä½¿ç”¨ 'exit' é€€å‡ºä¼šè¯[/yellow]\n")
                    continue
                except EOFError:
                    console.print("\n[green]ðŸ‘‹ å†è§![/green]")
                    break
        finally:
            # Cleanup checkpointer
            await checkpointer_ctx.__aexit__(None, None, None)
                
    except Exception as e:
        logger.error(f"Failed to initialize chat session: {e}", exc_info=True)
        ui.show_error(str(e))
        raise typer.Exit(1)


def _show_help() -> None:
    """Display help message."""
    help_text = """
[bold]Available Commands:[/bold]

â€¢ [cyan]help[/cyan]     - Show this help message
â€¢ [cyan]clear[/cyan]    - Clear the screen
â€¢ [cyan]status[/cyan]   - Show current configuration
â€¢ [cyan]exit[/cyan]     - Exit the chat session
â€¢ [cyan]quit[/cyan]     - Exit the chat session

[bold]Example Queries:[/bold]

â€¢ "æŸ¥è¯¢è®¾å¤‡ R1 çš„æŽ¥å£çŠ¶æ€"
â€¢ "æ£€æŸ¥ç½‘ç»œä¸­æ˜¯å¦æœ‰ BGP é—®é¢˜"
â€¢ "æ˜¾ç¤ºè®¾å¤‡ R2 çš„é…ç½®"
â€¢ "åˆ†æžå…¨ç½‘æŽ¥å£é”™è¯¯"
"""
    console.print(Panel(help_text, title="[bold]OLAV Help[/bold]", border_style="blue"))


def _show_status() -> None:
    """Display current configuration status."""
    status_text = f"""
[bold]Current Configuration:[/bold]

â€¢ LLM Provider: [cyan]{settings.llm_provider}[/cyan]
â€¢ Model: [cyan]{settings.llm_model_name}[/cyan]
â€¢ HITL: [cyan]{'Enabled' if AgentConfig.ENABLE_HITL else 'Disabled'}[/cyan]
â€¢ NetBox: [cyan]{settings.netbox_url}[/cyan]
â€¢ Max Iterations: [cyan]{AgentConfig.MAX_ITERATIONS}[/cyan]
"""
    console.print(Panel(status_text, title="[bold]Status[/bold]", border_style="blue"))


@app.command()
def suzieq(
    table: str = typer.Argument(..., help="SuzieQ table name (e.g., bgp, interfaces)"),
    method: str = typer.Option("get", "--method", "-m", help="Query method: get|summarize"),
    filter: list[str] = typer.Option([], "--filter", "-f", help="Filter in key=value form; repeatable"),
) -> None:
    """Direct one-shot SuzieQ parquet query (non-interactive) with timing output.

    Examples:
        olav suzieq bgp --method get
        olav suzieq bgp --method summarize
        olav suzieq interfaces -f hostname=r1 -f state=up
    """
    # Build filters dict
    filters_dict: dict[str, Any] = {}
    for item in filter:
        if "=" in item:
            k, v = item.split("=", 1)
            filters_dict[k.strip()] = v.strip()
    # Invoke tool
    try:
        result = asyncio.run(suzieq_query.ainvoke({"table": table, "method": method, **filters_dict}))
    except Exception as e:  # pragma: no cover - defensive
        console.print(f"[red]Query failed: {e}[/red]")
        raise typer.Exit(1)

    # Pretty print JSON with timing
    elapsed = result.get("__meta__", {}).get("elapsed_sec")
    console.print(f"[bold green]SuzieQ Query Result[/bold green] (table={table} method={method})")
    if elapsed is not None:
        console.print(f"[dim]Elapsed: {elapsed}s[/dim]")
    console.print_json(data=result)



@app.command()
def serve(
    host: str = "0.0.0.0",
    port: int = 8000,
) -> None:
    """Start OLAV web API server.

    Args:
        host: Host to bind to
        port: Port to listen on
    """
    console.print(f"[bold blue]Starting OLAV API server on {host}:{port}[/bold blue]")

    # TODO: Implement FastAPI server
    console.print("[yellow]API server not yet implemented[/yellow]")
    console.print("Next steps:")
    console.print("1. Create FastAPI app with LangServe")
    console.print("2. Expose agent endpoints")
    console.print("3. Add WebSocket support for streaming")

    # Temporary keep-alive loop so container does not exit
    try:
        while True:
            time.sleep(300)
    except KeyboardInterrupt:
        console.print("[red]Shutting down placeholder server loop[/red]")


@app.command()
def version() -> None:
    """Display OLAV version information."""
    console.print(f"OLAV v{__version__}")
    console.print(f"Python Package Manager: uv")
    console.print(f"LLM Provider: {settings.llm_provider}")


def main() -> None:
    """CLI entry point."""
    app()


if __name__ == "__main__":
    main()
